{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Neural Network Framework (Keras)\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
    "\n",
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- [X] The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- [ ] Normalize the data (all features should have roughly the same scale)\n",
    "- [X] Import the type of model and layers that you will need from Keras.\n",
    "- [X] Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- [X] Since this is a regression model you will have a single output node in the final layer.\n",
    "- [X] Use activation functions that are appropriate for this task\n",
    "- [X] Compile your model\n",
    "- [X] Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- [X] Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- [ ] Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- [ ] Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- [ ] After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "from tensorflow.keras.datasets import boston_housing, fashion_mnist\n",
    "import pandas as pd\n",
    "\n",
    "(b_X_train, b_y_train), (b_X_test, b_y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "stop = EarlyStopping(monitor='val_mean_absolute_error', min_delta=0.5, patience=3)\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Dense(13, input_dim=13, activation='relu'),\n",
    "    Dense(13, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "\n",
    "b_history = model.fit(b_X_train, b_y_train, epochs=50, \n",
    "                    validation_data=(b_X_test, b_y_test),\n",
    "                    callbacks=[stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(b_history.history['loss'])\n",
    "plt.plot(b_history.history['val_loss'])\n",
    "plt.title('Boston Housing Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- [X] Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- [X] Make sure to one-hot encode your category labels\n",
    "- [X] The number of nodes in your output layer should equal the number of classes you want to predict for Fashion-MNIST.\n",
    "- [X] Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- [X] Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "(fmnist_X_train, fmnist_y_train), (fmnist_X_test, fmnist_y_test) = fashion_mnist.load_data()\n",
    "\n",
    "fmnist_X_train = fmnist_X_train.astype('float32') / 255.0\n",
    "fmnist_X_test = fmnist_X_test.astype('float32') / 255.0\n",
    "\n",
    "fmnist_y_train = keras.utils.to_categorical(fmnist_y_train, 10)\n",
    "fmnist_y_test = keras.utils.to_categorical(fmnist_y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=3)\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Dense(784, input_dim=784, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(392, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(196, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(98, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "fmnist_history = model.fit(fmnist_X_train, fmnist_y_train, epochs=50,\n",
    "                    validation_data=(fmnist_X_test, fmnist_y_test),\n",
    "                    callbacks=[stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fmnist_history.history['loss'])\n",
    "plt.plot(fmnist_history.history['val_loss'])\n",
    "plt.title('Fashion MNIST Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
