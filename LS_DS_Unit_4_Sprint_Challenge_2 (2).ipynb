{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Simple Perceptron](#Q2)\n",
    "    - Perceptron\n",
    "    - Multilayer Perceptron\n",
    "    - Analyze and Compare\n",
    "4. [Keras MMP](#Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Defining Neural Networks \n",
    "\n",
    "Write *your own* definitions for the following terms:\n",
    "\n",
    "- **Neuron:**\n",
    "A conceptual mathematical node that outputs the weighted sum of the inputs plus a bias, and usually passes that weighted sum through an activation function first.\n",
    "\n",
    "- **Input Layer:**\n",
    "A layer of neurons that takes in the data.\n",
    "\n",
    "- **Hidden Layer:**\n",
    "A layer of neurons in between the input and output layers.\n",
    "\n",
    "- **Output Layer:**\n",
    "A layer of neurons that spits out prediction data.\n",
    "\n",
    "- **Activation Function:**\n",
    "A function to transform a value, usually to normalize it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain how back propagation works as if you were explaining it to a five year-old. Use your own words, but feel free to reference external materials for this question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say you're rolling a ball down a hill. But, it doesn't go where it should. You subtract where it is from  where it should be and add that to the actual position to get it where it's supposed to be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember our Simple Perceptron Class from Monday. In a simple prediction describe the process of making a prediction. How do you go from inputs to predicted output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dot product of the input vector and the perceptron's weight vector, pass that through an activation function, and then output the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q2\"></a>\n",
    "## 2. Simple Perceptron\n",
    "\n",
    "In this question, you will build two neural networks using Tensorflow Keras. After you build these two models, compare the results of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Our Dataset\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(-3, 3, 50),\n",
    "                     np.linspace(-3, 3, 50))\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "\"Use this X & y in the following 2 models\"\n",
    "X = rng.randn(300, 2)\n",
    "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
    "             dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Perceptron\n",
    "Construct a simple perceptron using Keras. You model should have 1 dense layer with a single neuron and a sigmoid activation function. Your model should be called `model1` and make sure to save the results of your fit statement to a variable called `h1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 0s 632us/sample - loss: 0.5298 - accuracy: 0.4533\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 0s 47us/sample - loss: 0.5293 - accuracy: 0.4600\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 0s 33us/sample - loss: 0.5288 - accuracy: 0.4633\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 0s 36us/sample - loss: 0.5283 - accuracy: 0.4667\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 0s 33us/sample - loss: 0.5277 - accuracy: 0.4700\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 0s 37us/sample - loss: 0.5272 - accuracy: 0.4733\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 0s 37us/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.5261 - accuracy: 0.4733\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 0s 33us/sample - loss: 0.5256 - accuracy: 0.4733\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 0s 37us/sample - loss: 0.5250 - accuracy: 0.4733\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model1 = Sequential([Dense(1, input_dim=2, activation='sigmoid')])\n",
    "\n",
    "model1.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "h1 = model1.fit(X, y, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron\n",
    "Now construct a multi-layer perceptron using. Here are some architecture suggestions: \n",
    "- 2 Hidden Layers\n",
    "- 5-32 Neurons in the Hidden Layers\n",
    "- Your pick of activation function and optimizer\n",
    "- Incorporate the Callback function below into your model\n",
    "\n",
    "Your model should be called `model2` and make sure to save the results of your fit statement to a variable called `h2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, model, logs={}): \n",
    "        if(logs.get('accuracy') > .99999):   \n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples\n",
      "Epoch 1/50\n",
      "300/300 [==============================] - 0s 765us/sample - loss: 0.4994 - accuracy: 0.4833\n",
      "Epoch 2/50\n",
      "300/300 [==============================] - 0s 53us/sample - loss: 0.4930 - accuracy: 0.6000\n",
      "Epoch 3/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.4862 - accuracy: 0.6233\n",
      "Epoch 4/50\n",
      "300/300 [==============================] - 0s 36us/sample - loss: 0.4792 - accuracy: 0.6267\n",
      "Epoch 5/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.4731 - accuracy: 0.6300\n",
      "Epoch 6/50\n",
      "300/300 [==============================] - 0s 47us/sample - loss: 0.4663 - accuracy: 0.6333\n",
      "Epoch 7/50\n",
      "300/300 [==============================] - 0s 43us/sample - loss: 0.4604 - accuracy: 0.6333\n",
      "Epoch 8/50\n",
      "300/300 [==============================] - 0s 47us/sample - loss: 0.4536 - accuracy: 0.6533\n",
      "Epoch 9/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.4463 - accuracy: 0.6533\n",
      "Epoch 10/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.4395 - accuracy: 0.6633\n",
      "Epoch 11/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.4330 - accuracy: 0.6667\n",
      "Epoch 12/50\n",
      "300/300 [==============================] - 0s 40us/sample - loss: 0.4263 - accuracy: 0.6700\n",
      "Epoch 13/50\n",
      "300/300 [==============================] - 0s 37us/sample - loss: 0.4199 - accuracy: 0.6800\n",
      "Epoch 14/50\n",
      "300/300 [==============================] - 0s 37us/sample - loss: 0.4133 - accuracy: 0.6767\n",
      "Epoch 15/50\n",
      "300/300 [==============================] - 0s 33us/sample - loss: 0.4061 - accuracy: 0.6667\n",
      "Epoch 16/50\n",
      "300/300 [==============================] - 0s 33us/sample - loss: 0.3986 - accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "stop = EarlyStopping(monitor='accuracy', min_delta=0.001, patience=3)\n",
    "\n",
    "model2 = Sequential([\n",
    "    Dense(2, input_dim=2, activation='relu'),  # input\n",
    "    Dense(32, activation='relu'),  # hidden\n",
    "    Dense(10, activation='relu'),  # hidden\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model2.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "h2 = model2.fit(X, y, epochs=50, callbacks=[stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze and Compare\n",
    "\n",
    "**Before you Start**: You will need to install an additional library for this next segment. Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
    "\n",
    "\n",
    "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\thepi\\.virtualenvs\\ds-unit-4-sprint-2-neural-networks-3fz2g-xz\\lib\\site-packages\\mlxtend\\plotting\\decision_regions.py:249: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
      "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do Not change anything in this cell\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# create a mesh to plot in\n",
    "x_min, x_max = X[:, 0].min() - .2, X[:, 0].max() + .2\n",
    "y_min, y_max = X[:, 1].min() - .2, X[:, 1].max() + .2\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "\n",
    "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
    "    \n",
    "    ax = plt.subplot(1,2, grd)\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
    "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
    "    plt.title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does the Perceptron (`model1`) only achieve ~70% accuracy? What is the architectural property of the Multi-Layer Perceptron that allows it more accurately learn the relationship between X and y? \n",
    "\n",
    "Why might this property be useful in more complex data such as images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XOR is inherently non-linear. It is because of this that a single perceptron, which by itself can only predict linear functions, cannot accurately predict the outcomes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras MMP <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>209</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "92    52    1   2       138   223    0        1      169      0      0.0   \n",
       "69    62    0   0       124   209    0        1      163      0      0.0   \n",
       "274   47    1   0       110   275    0        0      118      1      1.0   \n",
       "87    46    1   1       101   197    1        1      156      0      0.0   \n",
       "201   60    1   0       125   258    0        0      141      1      2.8   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "92       2   4     2       1  \n",
       "69       2   0     2       1  \n",
       "274      1   1     2       0  \n",
       "87       2   0     3       1  \n",
       "201      1   1     3       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[52.,  1.,  2., ...,  2.,  4.,  2.],\n",
       "       [62.,  0.,  0., ...,  2.,  0.,  2.],\n",
       "       [47.,  1.,  0., ...,  1.,  1.,  2.],\n",
       "       ...,\n",
       "       [35.,  0.,  0., ...,  2.,  0.,  2.],\n",
       "       [39.,  0.,  2., ...,  1.,  0.,  2.],\n",
       "       [64.,  1.,  0., ...,  0.,  1.,  2.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'target'\n",
    "\n",
    "X = df.drop(target, axis=1).values\n",
    "y = df[['target']].values\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303 samples\n",
      "303/303 [==============================] - 0s 923us/sample - loss: 0.4554 - accuracy: 0.5446\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential([\n",
    "    Flatten(),\n",
    "    Dense(13, input_dim=13, activation='relu'),\n",
    "    Dense(30, activation='relu'),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model3.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "h3 = model3.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 2ms/sample - loss: 1.4480 - accuracy: 0.4876\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.9073 - accuracy: 0.5413\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.7030 - accuracy: 0.5372\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.7124 - accuracy: 0.5083\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.6844 - accuracy: 0.5246\n",
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 35.7778 - accuracy: 0.4752\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 18.7476 - accuracy: 0.4752\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.3173 - accuracy: 0.4752\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 1.8214 - accuracy: 0.5372\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.7960 - accuracy: 0.5413\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.1427 - accuracy: 0.5165\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.7249 - accuracy: 0.6157\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.8069 - accuracy: 0.6116\n",
      "61/61 [==============================] - 0s 997us/sample - loss: 0.7192 - accuracy: 0.6393\n",
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 3.1445 - accuracy: 0.5579\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.8674 - accuracy: 0.4959\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6869 - accuracy: 0.6198\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5788 - accuracy: 0.7190\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.5954 - accuracy: 0.7025\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.8789 - accuracy: 0.5246\n",
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 2ms/sample - loss: 16.7667 - accuracy: 0.5597\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 39us/sample - loss: 3.5945 - accuracy: 0.4650\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.8722 - accuracy: 0.4856\n",
      "Epoch 4/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.3362 - accuracy: 0.6132\n",
      "Epoch 5/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.9887 - accuracy: 0.5967\n",
      "Epoch 6/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.9181 - accuracy: 0.6337\n",
      "Epoch 7/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.8158 - accuracy: 0.6091\n",
      "Epoch 8/50\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.7578 - accuracy: 0.6420\n",
      "Epoch 9/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.7448 - accuracy: 0.6420\n",
      "Epoch 10/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.7293 - accuracy: 0.6420\n",
      "Epoch 11/50\n",
      "243/243 [==============================] - 0s 54us/sample - loss: 0.6639 - accuracy: 0.6255\n",
      "Epoch 12/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.6569 - accuracy: 0.6543\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.7924 - accuracy: 0.5833\n",
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 1.2429 - accuracy: 0.5267\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 66us/sample - loss: 0.7332 - accuracy: 0.5391\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 0.6813 - accuracy: 0.5802\n",
      "Epoch 4/50\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.6573 - accuracy: 0.6008\n",
      "Epoch 5/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.6466 - accuracy: 0.6255\n",
      "Epoch 6/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.6338 - accuracy: 0.6379\n",
      "Epoch 7/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.6259 - accuracy: 0.6543\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.5605 - accuracy: 0.7333\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 1s 3ms/sample - loss: 5.6774 - accuracy: 0.4545\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 48us/sample - loss: 1.8458 - accuracy: 0.3802\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 1.1066 - accuracy: 0.4711\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 152us/sample - loss: 0.8911 - accuracy: 0.4628\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 87us/sample - loss: 0.7990 - accuracy: 0.5165\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.7767 - accuracy: 0.5207\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.7258 - accuracy: 0.5455\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 0.7121 - accuracy: 0.5826\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 0.7067 - accuracy: 0.6033\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.5250 - accuracy: 0.7213\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 1s 3ms/sample - loss: 19.1304 - accuracy: 0.4752\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 6.8314 - accuracy: 0.4711\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 1.0245 - accuracy: 0.5289\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.8465 - accuracy: 0.6033\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.8173 - accuracy: 0.5868\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.7651 - accuracy: 0.5826\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.7836 - accuracy: 0.5744\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 1.0220 - accuracy: 0.5082\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 1s 3ms/sample - loss: 0.8466 - accuracy: 0.4835\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6929 - accuracy: 0.6074\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.6756 - accuracy: 0.5702\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 181us/sample - loss: 0.6248 - accuracy: 0.6736\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.6039 - accuracy: 0.6983\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 0.5998 - accuracy: 0.6736\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.7566 - accuracy: 0.5902\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 1s 3ms/sample - loss: 1.1606 - accuracy: 0.5144\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.6953 - accuracy: 0.6132\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.6839 - accuracy: 0.6173\n",
      "Epoch 4/50\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.6275 - accuracy: 0.6379\n",
      "Epoch 5/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.6128 - accuracy: 0.6502\n",
      "Epoch 6/50\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.6191 - accuracy: 0.6831\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.7621 - accuracy: 0.5667\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 1s 3ms/sample - loss: 1.7975 - accuracy: 0.5309\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 53us/sample - loss: 0.7325 - accuracy: 0.6173\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.6895 - accuracy: 0.6049\n",
      "Epoch 4/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.6718 - accuracy: 0.6008\n",
      "Epoch 5/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.6423 - accuracy: 0.6420\n",
      "Epoch 6/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.6274 - accuracy: 0.6296\n",
      "Epoch 7/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.6367 - accuracy: 0.6461\n",
      "60/60 [==============================] - 0s 3ms/sample - loss: 0.5105 - accuracy: 0.7667\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 2.3564 - accuracy: 0.5165\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.6923 - accuracy: 0.5496\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.6921 - accuracy: 0.5496\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.6926 - accuracy: 0.5246\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 2ms/sample - loss: 6.2473 - accuracy: 0.5496\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6931 - accuracy: 0.5248\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.6931 - accuracy: 0.5248\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.6923 - accuracy: 0.6230\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 6.7981 - accuracy: 0.5537\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6716 - accuracy: 0.5579\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6737 - accuracy: 0.5785\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.7049 - accuracy: 0.5574\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 1.6210 - accuracy: 0.5679\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.6780 - accuracy: 0.5597\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.6653 - accuracy: 0.5597\n",
      "Epoch 4/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.6661 - accuracy: 0.5597\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.6971 - accuracy: 0.4833\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 13.1511 - accuracy: 0.4609\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.7015 - accuracy: 0.5267\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.6742 - accuracy: 0.5226\n",
      "Epoch 4/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.6711 - accuracy: 0.5350\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.5862 - accuracy: 0.6833\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 3.1961 - accuracy: 0.5372\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.1769 - accuracy: 0.5372\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 48us/sample - loss: 3.1578 - accuracy: 0.5331\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.1382 - accuracy: 0.5331\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.1190 - accuracy: 0.5331\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.0995 - accuracy: 0.5289\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.0800 - accuracy: 0.5289\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.0603 - accuracy: 0.5289\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.0413 - accuracy: 0.5331\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.0214 - accuracy: 0.5289\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.0017 - accuracy: 0.5289\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.9821 - accuracy: 0.5289\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.9624 - accuracy: 0.5289\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.9425 - accuracy: 0.5289\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 2.9228 - accuracy: 0.5331\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.9041 - accuracy: 0.5331\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.8849 - accuracy: 0.5289\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.8657 - accuracy: 0.5289\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.8469 - accuracy: 0.5289\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.8284 - accuracy: 0.5289\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.8099 - accuracy: 0.5248\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 2.7918 - accuracy: 0.5207\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.7734 - accuracy: 0.5207\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.7556 - accuracy: 0.5207\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.7376 - accuracy: 0.5248\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.7197 - accuracy: 0.5289\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.7017 - accuracy: 0.5289\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.6842 - accuracy: 0.5289\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.6673 - accuracy: 0.5248\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.6502 - accuracy: 0.5248\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.6330 - accuracy: 0.5289\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.6166 - accuracy: 0.5248\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.6005 - accuracy: 0.5207\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 2.5849 - accuracy: 0.5248\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.5686 - accuracy: 0.5248\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.5531 - accuracy: 0.5248\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.5383 - accuracy: 0.5413\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.5233 - accuracy: 0.5455\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.5084 - accuracy: 0.5455\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.4936 - accuracy: 0.5455\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.4796 - accuracy: 0.5413\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.4661 - accuracy: 0.5372\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.4520 - accuracy: 0.5413\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.4385 - accuracy: 0.5455\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.4255 - accuracy: 0.5455\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.4130 - accuracy: 0.5455\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.4000 - accuracy: 0.5413\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 37us/sample - loss: 2.3873 - accuracy: 0.5413\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.3758 - accuracy: 0.5413\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.3640 - accuracy: 0.5455\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 2.3696 - accuracy: 0.5246\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 3.7732 - accuracy: 0.4752\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.7568 - accuracy: 0.4752\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.7402 - accuracy: 0.4752\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.7238 - accuracy: 0.4752\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.7071 - accuracy: 0.4752\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.6902 - accuracy: 0.4752\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.6731 - accuracy: 0.4752\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.6556 - accuracy: 0.4752\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.6384 - accuracy: 0.4752\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.6207 - accuracy: 0.4752\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.6032 - accuracy: 0.4752\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.5855 - accuracy: 0.4752\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.5677 - accuracy: 0.4752\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.5500 - accuracy: 0.4752\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.5316 - accuracy: 0.4752\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.5134 - accuracy: 0.4752\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 3.4952 - accuracy: 0.4752\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.4771 - accuracy: 0.4752\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.4589 - accuracy: 0.4752\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.4405 - accuracy: 0.4752\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.4215 - accuracy: 0.4752\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.4026 - accuracy: 0.4752\n",
      "Epoch 23/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.3835 - accuracy: 0.4752\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.3645 - accuracy: 0.4752\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 3.3454 - accuracy: 0.4752\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 3.3263 - accuracy: 0.4752\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.3072 - accuracy: 0.4752\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.2880 - accuracy: 0.4752\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.2686 - accuracy: 0.4752\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.2489 - accuracy: 0.4752\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.2294 - accuracy: 0.4752\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.2096 - accuracy: 0.4752\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.1897 - accuracy: 0.4752\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.1698 - accuracy: 0.4752\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 47us/sample - loss: 3.1497 - accuracy: 0.4752\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.1294 - accuracy: 0.4752\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.1089 - accuracy: 0.4752\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 3.0885 - accuracy: 0.4752\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.0683 - accuracy: 0.4752\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.0484 - accuracy: 0.4752\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 3.0282 - accuracy: 0.4752\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 3.0076 - accuracy: 0.4752\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.9873 - accuracy: 0.4752\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 52us/sample - loss: 2.9666 - accuracy: 0.4752\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 2.9462 - accuracy: 0.4752\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 2.9257 - accuracy: 0.4752\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.9046 - accuracy: 0.4752\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 2.8836 - accuracy: 0.4752\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 2.8627 - accuracy: 0.4752\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.8420 - accuracy: 0.4752\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 3.6380 - accuracy: 0.3770\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 29.5804 - accuracy: 0.5620\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 29.5547 - accuracy: 0.5620\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 29.5287 - accuracy: 0.5620\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 29.5029 - accuracy: 0.5620\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 29.4768 - accuracy: 0.5620\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 29.4503 - accuracy: 0.5620\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 29.4245 - accuracy: 0.5620\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 29.3974 - accuracy: 0.5620\n",
      "Epoch 9/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 29.3704 - accuracy: 0.5620\n",
      "Epoch 10/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 29.3431 - accuracy: 0.5620\n",
      "Epoch 11/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 29.3161 - accuracy: 0.5620\n",
      "Epoch 12/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 29.2891 - accuracy: 0.5620\n",
      "Epoch 13/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 29.2623 - accuracy: 0.5620\n",
      "Epoch 14/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 29.2349 - accuracy: 0.5620\n",
      "Epoch 15/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 29.2074 - accuracy: 0.5620\n",
      "Epoch 16/50\n",
      "242/242 [==============================] - ETA: 0s - loss: 31.5046 - accuracy: 0.562 - 0s 37us/sample - loss: 29.1793 - accuracy: 0.5620\n",
      "Epoch 17/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 29.1521 - accuracy: 0.5620\n",
      "Epoch 18/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 29.1238 - accuracy: 0.5620\n",
      "Epoch 19/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 29.0954 - accuracy: 0.5620\n",
      "Epoch 20/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 29.0669 - accuracy: 0.5620\n",
      "Epoch 21/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 29.0385 - accuracy: 0.5620\n",
      "Epoch 22/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 29.0097 - accuracy: 0.5620\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 41us/sample - loss: 28.9813 - accuracy: 0.5620\n",
      "Epoch 24/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 28.9527 - accuracy: 0.5620\n",
      "Epoch 25/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 28.9236 - accuracy: 0.5620\n",
      "Epoch 26/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 28.8940 - accuracy: 0.5620\n",
      "Epoch 27/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 28.8647 - accuracy: 0.5620\n",
      "Epoch 28/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 28.8353 - accuracy: 0.5620\n",
      "Epoch 29/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 28.8061 - accuracy: 0.5620\n",
      "Epoch 30/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 28.7762 - accuracy: 0.5620\n",
      "Epoch 31/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 28.7463 - accuracy: 0.5620\n",
      "Epoch 32/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 28.7163 - accuracy: 0.5620\n",
      "Epoch 33/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 28.6864 - accuracy: 0.5620\n",
      "Epoch 34/50\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 28.6562 - accuracy: 0.5620\n",
      "Epoch 35/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 28.6260 - accuracy: 0.5620\n",
      "Epoch 36/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 28.5953 - accuracy: 0.5620\n",
      "Epoch 37/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 28.5645 - accuracy: 0.5620\n",
      "Epoch 38/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 28.5345 - accuracy: 0.5620\n",
      "Epoch 39/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 28.5040 - accuracy: 0.5620\n",
      "Epoch 40/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 28.4732 - accuracy: 0.5620\n",
      "Epoch 41/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 28.4426 - accuracy: 0.5620\n",
      "Epoch 42/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 28.4115 - accuracy: 0.5620\n",
      "Epoch 43/50\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 28.3800 - accuracy: 0.5620\n",
      "Epoch 44/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 28.3484 - accuracy: 0.5620\n",
      "Epoch 45/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 28.3167 - accuracy: 0.5620\n",
      "Epoch 46/50\n",
      "242/242 [==============================] - 0s 39us/sample - loss: 28.2857 - accuracy: 0.5620\n",
      "Epoch 47/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 28.2534 - accuracy: 0.5620\n",
      "Epoch 48/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 28.2219 - accuracy: 0.5620\n",
      "Epoch 49/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 28.1895 - accuracy: 0.5620\n",
      "Epoch 50/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 28.1573 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 32.6958 - accuracy: 0.4754\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 21.1213 - accuracy: 0.4403\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 21.0879 - accuracy: 0.4403\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 21.0537 - accuracy: 0.4403\n",
      "Epoch 4/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 21.0189 - accuracy: 0.4403\n",
      "Epoch 5/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 20.9834 - accuracy: 0.4403\n",
      "Epoch 6/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 20.9477 - accuracy: 0.4403\n",
      "Epoch 7/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 20.9116 - accuracy: 0.4403\n",
      "Epoch 8/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 20.8753 - accuracy: 0.4403\n",
      "Epoch 9/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 20.8392 - accuracy: 0.4403\n",
      "Epoch 10/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 20.8030 - accuracy: 0.4403\n",
      "Epoch 11/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 20.7662 - accuracy: 0.4403\n",
      "Epoch 12/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 20.7294 - accuracy: 0.4403\n",
      "Epoch 13/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 20.6919 - accuracy: 0.4403\n",
      "Epoch 14/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 20.6547 - accuracy: 0.4403\n",
      "Epoch 15/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 20.6166 - accuracy: 0.4403\n",
      "Epoch 16/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 20.5782 - accuracy: 0.4403\n",
      "Epoch 17/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 20.5402 - accuracy: 0.4403\n",
      "Epoch 18/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 20.5022 - accuracy: 0.4403\n",
      "Epoch 19/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 20.4630 - accuracy: 0.4403\n",
      "Epoch 20/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 20.4238 - accuracy: 0.4403\n",
      "Epoch 21/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 20.3849 - accuracy: 0.4403\n",
      "Epoch 22/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 20.3449 - accuracy: 0.4403\n",
      "Epoch 23/50\n",
      "243/243 [==============================] - 0s 181us/sample - loss: 20.3058 - accuracy: 0.4403\n",
      "Epoch 24/50\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 20.2658 - accuracy: 0.4403\n",
      "Epoch 25/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 20.2254 - accuracy: 0.4403\n",
      "Epoch 26/50\n",
      "243/243 [==============================] - 0s 74us/sample - loss: 20.1854 - accuracy: 0.4403\n",
      "Epoch 27/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 20.1451 - accuracy: 0.4403\n",
      "Epoch 28/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 20.1041 - accuracy: 0.4403\n",
      "Epoch 29/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 20.0629 - accuracy: 0.4403\n",
      "Epoch 30/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 20.0222 - accuracy: 0.4403\n",
      "Epoch 31/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 19.9803 - accuracy: 0.4403\n",
      "Epoch 32/50\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 19.9386 - accuracy: 0.4403\n",
      "Epoch 33/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 19.8972 - accuracy: 0.4403\n",
      "Epoch 34/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 19.8552 - accuracy: 0.4403\n",
      "Epoch 35/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 19.8130 - accuracy: 0.4403\n",
      "Epoch 36/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 19.7706 - accuracy: 0.4403\n",
      "Epoch 37/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 19.7278 - accuracy: 0.4403\n",
      "Epoch 38/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 19.6852 - accuracy: 0.4403\n",
      "Epoch 39/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 19.6429 - accuracy: 0.4403\n",
      "Epoch 40/50\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 19.5995 - accuracy: 0.4403\n",
      "Epoch 41/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 19.5562 - accuracy: 0.4403\n",
      "Epoch 42/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 19.5131 - accuracy: 0.4403\n",
      "Epoch 43/50\n",
      "243/243 [==============================] - 0s 107us/sample - loss: 19.4682 - accuracy: 0.4403\n",
      "Epoch 44/50\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 19.4240 - accuracy: 0.4403\n",
      "Epoch 45/50\n",
      "243/243 [==============================] - 0s 74us/sample - loss: 19.3792 - accuracy: 0.4403\n",
      "Epoch 46/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 19.3345 - accuracy: 0.4403\n",
      "Epoch 47/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 19.2898 - accuracy: 0.4403\n",
      "Epoch 48/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 19.2444 - accuracy: 0.4403\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 45us/sample - loss: 19.1989 - accuracy: 0.4403\n",
      "Epoch 50/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 19.1528 - accuracy: 0.4403\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 18.3086 - accuracy: 0.5167\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 2ms/sample - loss: 2.3492 - accuracy: 0.5597\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 2.3446 - accuracy: 0.5597\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 2.1236 - accuracy: 0.5333\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.8251 - accuracy: 0.6157\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6623 - accuracy: 0.6818\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.6315 - accuracy: 0.6488\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6086 - accuracy: 0.6942\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6188 - accuracy: 0.6736\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.6346 - accuracy: 0.6393\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 5.6978 - accuracy: 0.4504\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 0.7779 - accuracy: 0.5413\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.7176 - accuracy: 0.5620\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6538 - accuracy: 0.6405\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6540 - accuracy: 0.6529\n",
      "61/61 [==============================] - 0s 997us/sample - loss: 0.6760 - accuracy: 0.5902\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.8656 - accuracy: 0.5537\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6819 - accuracy: 0.6364\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6454 - accuracy: 0.6653\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6279 - accuracy: 0.6653\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6125 - accuracy: 0.7066\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.5961 - accuracy: 0.7066\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 50us/sample - loss: 0.5870 - accuracy: 0.7107\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.7360 - accuracy: 0.5082\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 15.0676 - accuracy: 0.5597\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 10.1195 - accuracy: 0.5597\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 7.2019 - accuracy: 0.5597\n",
      "Epoch 4/50\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 4.8931 - accuracy: 0.5556\n",
      "Epoch 5/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 2.6444 - accuracy: 0.4856\n",
      "Epoch 6/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 1.8017 - accuracy: 0.3909\n",
      "Epoch 7/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.5479 - accuracy: 0.3539\n",
      "Epoch 8/50\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 1.4229 - accuracy: 0.3745\n",
      "Epoch 9/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 1.3374 - accuracy: 0.3498\n",
      "Epoch 10/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.2715 - accuracy: 0.3909\n",
      "Epoch 11/50\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 1.2037 - accuracy: 0.3992\n",
      "Epoch 12/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 1.1353 - accuracy: 0.4115\n",
      "Epoch 13/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 1.0927 - accuracy: 0.3868\n",
      "Epoch 14/50\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 1.0442 - accuracy: 0.3827\n",
      "Epoch 15/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.9928 - accuracy: 0.4198\n",
      "Epoch 16/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.9604 - accuracy: 0.4444\n",
      "Epoch 17/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.9224 - accuracy: 0.4444\n",
      "Epoch 18/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.8966 - accuracy: 0.4486\n",
      "Epoch 19/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.8713 - accuracy: 0.4568\n",
      "Epoch 20/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.8420 - accuracy: 0.4815\n",
      "Epoch 21/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.8230 - accuracy: 0.5062\n",
      "Epoch 22/50\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 0.8009 - accuracy: 0.4856\n",
      "Epoch 23/50\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.7871 - accuracy: 0.4938\n",
      "Epoch 24/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.7663 - accuracy: 0.5103\n",
      "Epoch 25/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.7586 - accuracy: 0.5350\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.7861 - accuracy: 0.5000\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 8.0085 - accuracy: 0.4733\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 2.5239 - accuracy: 0.4691\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - 0s 62us/sample - loss: 1.0257 - accuracy: 0.5761\n",
      "Epoch 4/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.8924 - accuracy: 0.5802\n",
      "Epoch 5/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.8197 - accuracy: 0.6008\n",
      "Epoch 6/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.7665 - accuracy: 0.6091\n",
      "Epoch 7/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.7219 - accuracy: 0.5967\n",
      "Epoch 8/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.6934 - accuracy: 0.5967\n",
      "Epoch 9/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.6849 - accuracy: 0.6008\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.6683 - accuracy: 0.5500\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4505 - accuracy: 0.5496\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "61/61 [==============================] - 0s 948us/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4752 - accuracy: 0.5248\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4752 - accuracy: 0.5248\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.3770 - accuracy: 0.6230\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 3ms/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.5597 - accuracy: 0.4403\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.5597 - accuracy: 0.4403\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.4833 - accuracy: 0.5167\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.4217 - accuracy: 0.5885\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.3902 - accuracy: 0.6091\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.3775 - accuracy: 0.6214\n",
      "Epoch 4/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.3588 - accuracy: 0.6708\n",
      "Epoch 5/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.3607 - accuracy: 0.6420\n",
      "60/60 [==============================] - 0s 989us/sample - loss: 0.2775 - accuracy: 0.7500\n",
      "Loss: mean_absolute_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "61/61 [==============================] - 0s 931us/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_absolute_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.4752 - accuracy: 0.5248\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 50us/sample - loss: 0.4752 - accuracy: 0.5248\n",
      "61/61 [==============================] - 0s 891us/sample - loss: 0.3770 - accuracy: 0.6230\n",
      "Loss: mean_absolute_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 1s 3ms/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "61/61 [==============================] - 0s 981us/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_absolute_error; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 1s 3ms/sample - loss: 0.5597 - accuracy: 0.4403\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.5597 - accuracy: 0.4403\n",
      "60/60 [==============================] - 0s 3ms/sample - loss: 0.4833 - accuracy: 0.5167\n",
      "Loss: mean_absolute_error; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 1s 3ms/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "60/60 [==============================] - 0s 998us/sample - loss: 0.6167 - accuracy: 0.3833\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 913us/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 43us/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 2ms/sample - loss: 0.5251 - accuracy: 0.4752\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5248 - accuracy: 0.4752\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.6230 - accuracy: 0.3770\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 970us/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.5167 - accuracy: 0.4833\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 919us/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 70us/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.6167 - accuracy: 0.3833\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.5360 - accuracy: 0.4298\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.5357 - accuracy: 0.4298\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.5585 - accuracy: 0.3770\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.5591 - accuracy: 0.4380\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5591 - accuracy: 0.4380\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.4775 - accuracy: 0.5246\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.5167 - accuracy: 0.4833\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.4709 - accuracy: 0.5267\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.4709 - accuracy: 0.5267\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.3827 - accuracy: 0.6167\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.5495 - accuracy: 0.4504\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.5443 - accuracy: 0.4504\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.4738 - accuracy: 0.4754\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 989us/sample - loss: 0.4812 - accuracy: 0.4793\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4559 - accuracy: 0.5579\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4433 - accuracy: 0.6033\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4378 - accuracy: 0.6074\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.4446 - accuracy: 0.6393\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 977us/sample - loss: 0.5878 - accuracy: 0.4008\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5155 - accuracy: 0.4835\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4214 - accuracy: 0.6033\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4061 - accuracy: 0.6198\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.3986 - accuracy: 0.6322\n",
      "61/61 [==============================] - 0s 965us/sample - loss: 0.4671 - accuracy: 0.5082\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 932us/sample - loss: 0.4094 - accuracy: 0.5802\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.3809 - accuracy: 0.6173\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.3797 - accuracy: 0.6584\n",
      "60/60 [==============================] - 0s 981us/sample - loss: 0.3995 - accuracy: 0.5833\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 944us/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.6167 - accuracy: 0.3833\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4512 - accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4202 - accuracy: 0.4835\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.3803 - accuracy: 0.5124\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.3502 - accuracy: 0.5248\n",
      "Epoch 5/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.2899 - accuracy: 0.5950\n",
      "Epoch 6/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.2556 - accuracy: 0.6364\n",
      "Epoch 7/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.2408 - accuracy: 0.6240\n",
      "Epoch 8/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.2802 - accuracy: 0.5868\n",
      "61/61 [==============================] - 0s 981us/sample - loss: 0.1771 - accuracy: 0.7213\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.3864 - accuracy: 0.5372\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4118 - accuracy: 0.4876\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.3135 - accuracy: 0.6230\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 2ms/sample - loss: 0.4071 - accuracy: 0.5579\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 0.3099 - accuracy: 0.4835\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.2461 - accuracy: 0.5826\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.2469 - accuracy: 0.6033\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.3112 - accuracy: 0.5082\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.3924 - accuracy: 0.5350\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.2857 - accuracy: 0.6543\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.2645 - accuracy: 0.6543\n",
      "Epoch 4/50\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.2564 - accuracy: 0.6543\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.3601 - accuracy: 0.5667\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.4732 - accuracy: 0.5267\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.4712 - accuracy: 0.5267\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.3767 - accuracy: 0.6167\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 1s 3ms/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 1s 3ms/sample - loss: 0.2607 - accuracy: 0.5248\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.2371 - accuracy: 0.6157\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.2325 - accuracy: 0.6405\n",
      "61/61 [==============================] - 0s 959us/sample - loss: 0.2158 - accuracy: 0.6066\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.2798 - accuracy: 0.6074\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.1956 - accuracy: 0.7025\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 0.1978 - accuracy: 0.7066\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.2818 - accuracy: 0.5574\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 1s 3ms/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.3274 - accuracy: 0.6132\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.2662 - accuracy: 0.6173\n",
      "Epoch 4/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.2348 - accuracy: 0.6420\n",
      "Epoch 5/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.2241 - accuracy: 0.6584\n",
      "Epoch 6/50\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 0.2119 - accuracy: 0.6872\n",
      "Epoch 7/50\n",
      "243/243 [==============================] - 0s 74us/sample - loss: 0.2287 - accuracy: 0.6667\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.2766 - accuracy: 0.5667\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 1s 3ms/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 57us/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.6167 - accuracy: 0.3833\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 883us/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "61/61 [==============================] - 0s 990us/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 2ms/sample - loss: 0.5248 - accuracy: 0.4752\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.5248 - accuracy: 0.4752\n",
      "61/61 [==============================] - 0s 2ms/sample - loss: 0.6230 - accuracy: 0.3770\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.4692 - accuracy: 0.4527\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.4397 - accuracy: 0.5597\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4394 - accuracy: 0.5597\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.5153 - accuracy: 0.4833\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.4732 - accuracy: 0.5267\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4732 - accuracy: 0.5267\n",
      "60/60 [==============================] - 0s 981us/sample - loss: 0.3833 - accuracy: 0.6167\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.5494 - accuracy: 0.4504\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.5494 - accuracy: 0.4504\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.5245 - accuracy: 0.4754\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 2ms/sample - loss: 0.4752 - accuracy: 0.5248\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.4752 - accuracy: 0.5248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.3770 - accuracy: 0.6230\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4612 - accuracy: 0.4835\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 0.4609 - accuracy: 0.4835\n",
      "61/61 [==============================] - 0s 2ms/sample - loss: 0.4505 - accuracy: 0.4918\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.5593 - accuracy: 0.4403\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.5593 - accuracy: 0.4403\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.4831 - accuracy: 0.5167\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 78us/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.6167 - accuracy: 0.3833\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.3984 - accuracy: 0.4050\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.2450 - accuracy: 0.5702\n",
      "Epoch 3/50\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.2171 - accuracy: 0.6405\n",
      "Epoch 4/50\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.2171 - accuracy: 0.6570\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.1875 - accuracy: 0.7705\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/50\n",
      "242/242 [==============================] - 0s 985us/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "Epoch 2/50\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "61/61 [==============================] - 0s 981us/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.5167 - accuracy: 0.4833\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.3680 - accuracy: 0.5062\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.3214 - accuracy: 0.5350\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - 0s 39us/sample - loss: 0.2822 - accuracy: 0.5514\n",
      "Epoch 4/50\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.2717 - accuracy: 0.5720\n",
      "Epoch 5/50\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.2737 - accuracy: 0.5473\n",
      "60/60 [==============================] - 0s 964us/sample - loss: 0.2530 - accuracy: 0.5833\n",
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/sample - loss: 7.3182 - accuracy: 0.4504\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 1.7938 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 1.2753 - accuracy: 0.4669\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 0.9312 - accuracy: 0.5289\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 0.8454 - accuracy: 0.5785\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 0.8449 - accuracy: 0.4917\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.7071 - accuracy: 0.6230\n",
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/sample - loss: 2.9203 - accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 0.7537 - accuracy: 0.3843\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.7083 - accuracy: 0.3926\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.7048 - accuracy: 0.4091\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.7042 - accuracy: 0.5246\n",
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/sample - loss: 11.2378 - accuracy: 0.4380\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 4.2338 - accuracy: 0.4380\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 1.2368 - accuracy: 0.4421\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 0.7631 - accuracy: 0.5579\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 0.7575 - accuracy: 0.5579\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.7505 - accuracy: 0.4754\n",
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 2ms/sample - loss: 1.6720 - accuracy: 0.5638\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 57us/sample - loss: 0.9357 - accuracy: 0.6461\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 0s 57us/sample - loss: 0.7591 - accuracy: 0.6708\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - 0s 74us/sample - loss: 0.6537 - accuracy: 0.7243\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 0.6038 - accuracy: 0.7490\n",
      "Epoch 6/100\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.5923 - accuracy: 0.6955\n",
      "Epoch 7/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.6230 - accuracy: 0.6996\n",
      "60/60 [==============================] - 0s 2ms/sample - loss: 0.7646 - accuracy: 0.6167\n",
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 1.3056 - accuracy: 0.6008\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.0545 - accuracy: 0.6173\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.8369 - accuracy: 0.6255\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.7363 - accuracy: 0.6296\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.6969 - accuracy: 0.6132\n",
      "Epoch 6/100\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 0.6397 - accuracy: 0.6008\n",
      "Epoch 7/100\n",
      "243/243 [==============================] - 0s 57us/sample - loss: 0.6186 - accuracy: 0.6626\n",
      "Epoch 8/100\n",
      "243/243 [==============================] - 0s 57us/sample - loss: 0.5913 - accuracy: 0.6831\n",
      "Epoch 9/100\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 0.5877 - accuracy: 0.6872\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.5053 - accuracy: 0.8167\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 5ms/sample - loss: 1.0957 - accuracy: 0.6281\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 0.7269 - accuracy: 0.6901\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 0.7265 - accuracy: 0.6240\n",
      "61/61 [==============================] - 0s 2ms/sample - loss: 0.5947 - accuracy: 0.6721\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/sample - loss: 4.3725 - accuracy: 0.4421\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 49us/sample - loss: 0.9986 - accuracy: 0.4793\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.7071 - accuracy: 0.5909\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 0.6798 - accuracy: 0.6364\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 0.7277 - accuracy: 0.6281\n",
      "61/61 [==============================] - 0s 2ms/sample - loss: 0.6025 - accuracy: 0.6066\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/sample - loss: 5.9117 - accuracy: 0.5785\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6758 - accuracy: 0.6818\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6190 - accuracy: 0.7107\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.5967 - accuracy: 0.7149\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6003 - accuracy: 0.6983\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.9247 - accuracy: 0.5246\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 1s 3ms/sample - loss: 4.6651 - accuracy: 0.5638\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.7363 - accuracy: 0.6708\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.6238 - accuracy: 0.6996\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.6265 - accuracy: 0.7078\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.7868 - accuracy: 0.6000\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 1s 3ms/sample - loss: 12.2769 - accuracy: 0.5226\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.2698 - accuracy: 0.6255\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.3890 - accuracy: 0.6091\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 0.9582 - accuracy: 0.6173\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 0.8525 - accuracy: 0.5967\n",
      "Epoch 6/100\n",
      "243/243 [==============================] - 0s 57us/sample - loss: 0.9901 - accuracy: 0.5885\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.7212 - accuracy: 0.6833\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 2.4237 - accuracy: 0.5455\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6860 - accuracy: 0.5331\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6574 - accuracy: 0.6033\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.6540 - accuracy: 0.6364\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.5691 - accuracy: 0.7049\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 2.5130 - accuracy: 0.5455\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6771 - accuracy: 0.6074\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6693 - accuracy: 0.6116\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.6696 - accuracy: 0.6066\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/sample - loss: 17.2376 - accuracy: 0.5455\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.6982 - accuracy: 0.5496\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 50us/sample - loss: 0.6930 - accuracy: 0.5496\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.7031 - accuracy: 0.4754\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 47.1509 - accuracy: 0.4609\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.6761 - accuracy: 0.5679\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.6630 - accuracy: 0.5967\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.6518 - accuracy: 0.6132\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.6533 - accuracy: 0.6173\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.7034 - accuracy: 0.6000\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 4.2142 - accuracy: 0.4568\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.7081 - accuracy: 0.4609\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.6954 - accuracy: 0.4691\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.6831 - accuracy: 0.5679\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.6703 - accuracy: 0.5885\n",
      "Epoch 6/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.7148 - accuracy: 0.5432\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.7080 - accuracy: 0.4667\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 5.6165 - accuracy: 0.4504\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 5.6024 - accuracy: 0.4504\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 5.5879 - accuracy: 0.4504\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 5.5732 - accuracy: 0.4504\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 5.5588 - accuracy: 0.4504\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 5.5441 - accuracy: 0.4504\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.5292 - accuracy: 0.4504\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 5.5142 - accuracy: 0.4504\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 70us/sample - loss: 5.4991 - accuracy: 0.4504\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 5.4839 - accuracy: 0.4504\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.4683 - accuracy: 0.4504\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 5.4527 - accuracy: 0.4504\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.4370 - accuracy: 0.4504\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.4215 - accuracy: 0.4504\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.4057 - accuracy: 0.4504\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.3896 - accuracy: 0.4504\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 39us/sample - loss: 5.3736 - accuracy: 0.4504\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 5.3576 - accuracy: 0.4504\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 5.3415 - accuracy: 0.4504\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.3253 - accuracy: 0.4504\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 5.3091 - accuracy: 0.4504\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 5.2923 - accuracy: 0.4504\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.2758 - accuracy: 0.4504\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.2590 - accuracy: 0.4504\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.2422 - accuracy: 0.4504\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 37us/sample - loss: 5.2250 - accuracy: 0.4504\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.2081 - accuracy: 0.4504\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.1910 - accuracy: 0.4504\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 5.1739 - accuracy: 0.4504\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 5.1567 - accuracy: 0.4504\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 5.1394 - accuracy: 0.4504\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 5.1221 - accuracy: 0.4504\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.1049 - accuracy: 0.4504\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.0876 - accuracy: 0.4504\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.0704 - accuracy: 0.4504\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 5.0529 - accuracy: 0.4504\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 5.0352 - accuracy: 0.4504\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 5.0177 - accuracy: 0.4504\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.0000 - accuracy: 0.4504\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.9826 - accuracy: 0.4504\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.9647 - accuracy: 0.4504\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.9464 - accuracy: 0.4504\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.9281 - accuracy: 0.4504\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.9102 - accuracy: 0.4504\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 4.8921 - accuracy: 0.4504\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.8739 - accuracy: 0.4504\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.8557 - accuracy: 0.4504\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 4.8373 - accuracy: 0.4504\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.8188 - accuracy: 0.4504\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.8004 - accuracy: 0.4504\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.7817 - accuracy: 0.4504\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.7631 - accuracy: 0.4504\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.7445 - accuracy: 0.4504\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.7255 - accuracy: 0.4504\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 46us/sample - loss: 4.7066 - accuracy: 0.4504\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.6876 - accuracy: 0.4504\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.6685 - accuracy: 0.4504\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.6496 - accuracy: 0.4504\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.6306 - accuracy: 0.4504\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.6117 - accuracy: 0.4504\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.5928 - accuracy: 0.4504\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.5740 - accuracy: 0.4504\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.5547 - accuracy: 0.4504\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.5355 - accuracy: 0.4504\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 4.4969 - accuracy: 0.46 - 0s 45us/sample - loss: 4.5160 - accuracy: 0.4504\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.4965 - accuracy: 0.4504\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.4768 - accuracy: 0.4504\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.4572 - accuracy: 0.4504\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.4373 - accuracy: 0.4504\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.4175 - accuracy: 0.4504\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.3977 - accuracy: 0.4504\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.3778 - accuracy: 0.4504\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 70us/sample - loss: 4.3578 - accuracy: 0.4504\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 4.3381 - accuracy: 0.4504\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 4.3180 - accuracy: 0.4504\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.2984 - accuracy: 0.4504\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.2785 - accuracy: 0.4504\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 70us/sample - loss: 4.2586 - accuracy: 0.4504\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.2385 - accuracy: 0.4504\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.2180 - accuracy: 0.4504\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 4.1977 - accuracy: 0.4504\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.1773 - accuracy: 0.4504\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.1569 - accuracy: 0.4504\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.1364 - accuracy: 0.4504\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 4.1164 - accuracy: 0.4504\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.0957 - accuracy: 0.4504\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.0755 - accuracy: 0.4504\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.0546 - accuracy: 0.4504\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 4.0337 - accuracy: 0.4504\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.0127 - accuracy: 0.4504\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.9919 - accuracy: 0.4504\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.9709 - accuracy: 0.4504\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 3.9497 - accuracy: 0.4504\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.9288 - accuracy: 0.4504\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.9075 - accuracy: 0.4504\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.8867 - accuracy: 0.4504\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 3.8654 - accuracy: 0.4504\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 3.8443 - accuracy: 0.4504\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.8230 - accuracy: 0.4504\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.8017 - accuracy: 0.4504\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 3.6907 - accuracy: 0.4754\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 16.7202 - accuracy: 0.4752\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 49us/sample - loss: 16.6747 - accuracy: 0.4752\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 16.6284 - accuracy: 0.4752\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 16.5813 - accuracy: 0.4752\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 16.5340 - accuracy: 0.4752\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 16.4867 - accuracy: 0.4752\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 16.4386 - accuracy: 0.4752\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 56us/sample - loss: 16.3896 - accuracy: 0.4752\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 16.3405 - accuracy: 0.4752\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 16.2917 - accuracy: 0.4752\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 16.2420 - accuracy: 0.4752\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 16.1912 - accuracy: 0.4752\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 16.1400 - accuracy: 0.4752\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 16.0895 - accuracy: 0.4752\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 16.0387 - accuracy: 0.4752\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 15.9879 - accuracy: 0.4752\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 15.9375 - accuracy: 0.4752\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 15.8853 - accuracy: 0.4752\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 15.8338 - accuracy: 0.4752\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 15.7818 - accuracy: 0.4752\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 15.7293 - accuracy: 0.4752\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 15.6753 - accuracy: 0.4752\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 15.6218 - accuracy: 0.4752\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 15.5682 - accuracy: 0.4752\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 15.5154 - accuracy: 0.4752\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 15.4615 - accuracy: 0.4752\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 15.4070 - accuracy: 0.4752\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 17.4950 - accuracy: 0.406 - 0s 49us/sample - loss: 15.3519 - accuracy: 0.4752\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 15.2974 - accuracy: 0.4752\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 15.2425 - accuracy: 0.4752\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 15.1884 - accuracy: 0.4752\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 15.1335 - accuracy: 0.4752\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 15.0783 - accuracy: 0.4752\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 15.0231 - accuracy: 0.4752\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 14.9671 - accuracy: 0.4752\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 14.9101 - accuracy: 0.4752\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 14.8538 - accuracy: 0.4752\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 14.7965 - accuracy: 0.4752\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 14.7390 - accuracy: 0.4752\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 14.6806 - accuracy: 0.4752\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 14.6220 - accuracy: 0.4752\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 14.5641 - accuracy: 0.4752\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 14.5063 - accuracy: 0.4752\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 14.4478 - accuracy: 0.4752\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 14.3893 - accuracy: 0.4752\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 14.3315 - accuracy: 0.4752\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 14.2723 - accuracy: 0.4752\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 14.2115 - accuracy: 0.4752\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 14.1525 - accuracy: 0.4752\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 14.0931 - accuracy: 0.4752\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 14.0324 - accuracy: 0.4752\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 13.9718 - accuracy: 0.4752\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 13.9114 - accuracy: 0.4752\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 13.8511 - accuracy: 0.4752\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 13.7898 - accuracy: 0.4752\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 13.7285 - accuracy: 0.4752\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 13.6667 - accuracy: 0.4752\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 13.6053 - accuracy: 0.4752\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 13.5443 - accuracy: 0.4752\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 13.4826 - accuracy: 0.4752\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 13.4206 - accuracy: 0.4752\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 13.3598 - accuracy: 0.4752\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 13.2980 - accuracy: 0.4752\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 13.2359 - accuracy: 0.4752\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 13.1748 - accuracy: 0.4752\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 13.1131 - accuracy: 0.4752\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 13.0514 - accuracy: 0.4752\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 12.9906 - accuracy: 0.4752\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 12.9291 - accuracy: 0.4752\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 12.8657 - accuracy: 0.4752\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 12.8018 - accuracy: 0.4752\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 12.7379 - accuracy: 0.4752\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 12.6746 - accuracy: 0.4752\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 12.6107 - accuracy: 0.4752\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 12.5464 - accuracy: 0.4752\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 12.4820 - accuracy: 0.4752\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 12.4177 - accuracy: 0.4752\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 12.3548 - accuracy: 0.4752\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 54us/sample - loss: 12.2918 - accuracy: 0.4752\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 12.2290 - accuracy: 0.4752\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 12.1644 - accuracy: 0.4752\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 12.1008 - accuracy: 0.4752\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 12.0369 - accuracy: 0.4752\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 11.9732 - accuracy: 0.4752\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 12.0777 - accuracy: 0.468 - 0s 45us/sample - loss: 11.9083 - accuracy: 0.4752\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 11.8437 - accuracy: 0.4752\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 11.7781 - accuracy: 0.4752\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 11.7128 - accuracy: 0.4752\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 11.6482 - accuracy: 0.4752\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 11.5821 - accuracy: 0.4752\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 11.5158 - accuracy: 0.4752\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 11.4493 - accuracy: 0.4752\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 11.3826 - accuracy: 0.4752\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 11.3174 - accuracy: 0.4752\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 11.2516 - accuracy: 0.4752\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 11.1858 - accuracy: 0.4752\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 95us/sample - loss: 11.1187 - accuracy: 0.4752\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 11.0513 - accuracy: 0.4752\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 10.9847 - accuracy: 0.4752\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 10.9187 - accuracy: 0.4752\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 12.4519 - accuracy: 0.3770\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 2.1147 - accuracy: 0.5207\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.1115 - accuracy: 0.5248\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 1.7625 - accuracy: 0.5902\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 1.3978 - accuracy: 0.4156\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.3945 - accuracy: 0.4156\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 1.5551 - accuracy: 0.4333\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 4.9493 - accuracy: 0.4733\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.9378 - accuracy: 0.4733\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.9259 - accuracy: 0.4733\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.9140 - accuracy: 0.4733\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 4.9020 - accuracy: 0.4733\n",
      "Epoch 6/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.8900 - accuracy: 0.4733\n",
      "Epoch 7/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.8776 - accuracy: 0.4733\n",
      "Epoch 8/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.8652 - accuracy: 0.4733\n",
      "Epoch 9/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.8527 - accuracy: 0.4733\n",
      "Epoch 10/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.8402 - accuracy: 0.4733\n",
      "Epoch 11/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.8276 - accuracy: 0.4733\n",
      "Epoch 12/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 4.8149 - accuracy: 0.4733\n",
      "Epoch 13/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.8019 - accuracy: 0.4733\n",
      "Epoch 14/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.7890 - accuracy: 0.4733\n",
      "Epoch 15/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.7760 - accuracy: 0.4733\n",
      "Epoch 16/100\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 4.7628 - accuracy: 0.4733\n",
      "Epoch 17/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.7493 - accuracy: 0.4733\n",
      "Epoch 18/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.7359 - accuracy: 0.4733\n",
      "Epoch 19/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.7225 - accuracy: 0.4733\n",
      "Epoch 20/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.7091 - accuracy: 0.4733\n",
      "Epoch 21/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 4.6956 - accuracy: 0.4733\n",
      "Epoch 22/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 4.6821 - accuracy: 0.4733\n",
      "Epoch 23/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 4.6684 - accuracy: 0.4733\n",
      "Epoch 24/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.6548 - accuracy: 0.4733\n",
      "Epoch 25/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.6408 - accuracy: 0.4733\n",
      "Epoch 26/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.6268 - accuracy: 0.4733\n",
      "Epoch 27/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.6127 - accuracy: 0.4733\n",
      "Epoch 28/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.5985 - accuracy: 0.4733\n",
      "Epoch 29/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.5843 - accuracy: 0.4733\n",
      "Epoch 30/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.5699 - accuracy: 0.4733\n",
      "Epoch 31/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.5559 - accuracy: 0.4733\n",
      "Epoch 32/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.5414 - accuracy: 0.4733\n",
      "Epoch 33/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.5269 - accuracy: 0.4733\n",
      "Epoch 34/100\n",
      "243/243 [==============================] - 0s 42us/sample - loss: 4.5124 - accuracy: 0.4733\n",
      "Epoch 35/100\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 4.4979 - accuracy: 0.4733\n",
      "Epoch 36/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.4830 - accuracy: 0.4733\n",
      "Epoch 37/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.4680 - accuracy: 0.4733\n",
      "Epoch 38/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.4528 - accuracy: 0.4733\n",
      "Epoch 39/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 4.4376 - accuracy: 0.4733\n",
      "Epoch 40/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.4223 - accuracy: 0.4733\n",
      "Epoch 41/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.4069 - accuracy: 0.4733\n",
      "Epoch 42/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.3916 - accuracy: 0.4733\n",
      "Epoch 43/100\n",
      "243/243 [==============================] - 0s 40us/sample - loss: 4.3758 - accuracy: 0.4733\n",
      "Epoch 44/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.3602 - accuracy: 0.4733\n",
      "Epoch 45/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.3446 - accuracy: 0.4733\n",
      "Epoch 46/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.3286 - accuracy: 0.4733\n",
      "Epoch 47/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.3126 - accuracy: 0.4733\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 45us/sample - loss: 4.2967 - accuracy: 0.4733\n",
      "Epoch 49/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.2808 - accuracy: 0.4733\n",
      "Epoch 50/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 4.2646 - accuracy: 0.4733\n",
      "Epoch 51/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.2485 - accuracy: 0.4733\n",
      "Epoch 52/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.2326 - accuracy: 0.4733\n",
      "Epoch 53/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.2165 - accuracy: 0.4733\n",
      "Epoch 54/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 4.2002 - accuracy: 0.4733\n",
      "Epoch 55/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.1840 - accuracy: 0.4733\n",
      "Epoch 56/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.1677 - accuracy: 0.4733\n",
      "Epoch 57/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.1511 - accuracy: 0.4733\n",
      "Epoch 58/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.1343 - accuracy: 0.4733\n",
      "Epoch 59/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 4.1177 - accuracy: 0.4733\n",
      "Epoch 60/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.1010 - accuracy: 0.4733\n",
      "Epoch 61/100\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 4.0842 - accuracy: 0.4733\n",
      "Epoch 62/100\n",
      "243/243 [==============================] - 0s 74us/sample - loss: 4.0673 - accuracy: 0.4733\n",
      "Epoch 63/100\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 4.0506 - accuracy: 0.4733\n",
      "Epoch 64/100\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 4.0333 - accuracy: 0.4733\n",
      "Epoch 65/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 4.0159 - accuracy: 0.4733\n",
      "Epoch 66/100\n",
      "243/243 [==============================] - 0s 66us/sample - loss: 3.9985 - accuracy: 0.4733\n",
      "Epoch 67/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.9813 - accuracy: 0.4733\n",
      "Epoch 68/100\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 3.9638 - accuracy: 0.4733\n",
      "Epoch 69/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.9463 - accuracy: 0.4733\n",
      "Epoch 70/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.9287 - accuracy: 0.4733\n",
      "Epoch 71/100\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 3.9109 - accuracy: 0.4733\n",
      "Epoch 72/100\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 3.8935 - accuracy: 0.4733\n",
      "Epoch 73/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 3.8758 - accuracy: 0.4733\n",
      "Epoch 74/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.8581 - accuracy: 0.4733\n",
      "Epoch 75/100\n",
      "243/243 [==============================] - 0s 35us/sample - loss: 3.8403 - accuracy: 0.4733\n",
      "Epoch 76/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 3.8221 - accuracy: 0.4733\n",
      "Epoch 77/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.8043 - accuracy: 0.4733\n",
      "Epoch 78/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.7863 - accuracy: 0.4733\n",
      "Epoch 79/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.7681 - accuracy: 0.4733\n",
      "Epoch 80/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.7501 - accuracy: 0.4733\n",
      "Epoch 81/100\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 3.7319 - accuracy: 0.4733\n",
      "Epoch 82/100\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 3.7135 - accuracy: 0.4733\n",
      "Epoch 83/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.6951 - accuracy: 0.4733\n",
      "Epoch 84/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.6770 - accuracy: 0.4733\n",
      "Epoch 85/100\n",
      "243/243 [==============================] - 0s 39us/sample - loss: 3.6586 - accuracy: 0.4733\n",
      "Epoch 86/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.6401 - accuracy: 0.4733\n",
      "Epoch 87/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.6212 - accuracy: 0.4733\n",
      "Epoch 88/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.6028 - accuracy: 0.4733\n",
      "Epoch 89/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.5843 - accuracy: 0.4733\n",
      "Epoch 90/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.5658 - accuracy: 0.4733\n",
      "Epoch 91/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.5472 - accuracy: 0.4733\n",
      "Epoch 92/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 3.5284 - accuracy: 0.4733\n",
      "Epoch 93/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.5099 - accuracy: 0.4733\n",
      "Epoch 94/100\n",
      "243/243 [==============================] - 0s 39us/sample - loss: 3.4908 - accuracy: 0.4733\n",
      "Epoch 95/100\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 3.4720 - accuracy: 0.4733\n",
      "Epoch 96/100\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 3.4532 - accuracy: 0.4733\n",
      "Epoch 97/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.4346 - accuracy: 0.4733\n",
      "Epoch 98/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.4160 - accuracy: 0.4733\n",
      "Epoch 99/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.3970 - accuracy: 0.4733\n",
      "Epoch 100/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 3.3779 - accuracy: 0.4733\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 4.1735 - accuracy: 0.3833\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 3.0958 - accuracy: 0.4959\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.6862 - accuracy: 0.4132\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.4707 - accuracy: 0.4132\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.2866 - accuracy: 0.4421\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.1423 - accuracy: 0.4752\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.0410 - accuracy: 0.4876\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.9773 - accuracy: 0.4959\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.9215 - accuracy: 0.4959\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.8841 - accuracy: 0.5124\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.8417 - accuracy: 0.5331\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.8108 - accuracy: 0.5579\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.7904 - accuracy: 0.5331\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.7696 - accuracy: 0.5868\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.7440 - accuracy: 0.5744\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.7282 - accuracy: 0.5909\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 111us/sample - loss: 0.7174 - accuracy: 0.6198\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.7044 - accuracy: 0.6281\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.6962 - accuracy: 0.5992\n",
      "61/61 [==============================] - 0s 2ms/sample - loss: 0.6625 - accuracy: 0.5902\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 2.6044 - accuracy: 0.5248\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 82us/sample - loss: 1.1682 - accuracy: 0.5248\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.8241 - accuracy: 0.5248\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 0.7612 - accuracy: 0.5331\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 62us/sample - loss: 0.7425 - accuracy: 0.5248\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 70us/sample - loss: 0.7317 - accuracy: 0.5289\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 0.7221 - accuracy: 0.5496\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.7187 - accuracy: 0.6066\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 5.1047 - accuracy: 0.4380\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 2.4258 - accuracy: 0.4380\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 1.2601 - accuracy: 0.4959\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.8065 - accuracy: 0.6405\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 0.6767 - accuracy: 0.7314\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6400 - accuracy: 0.7273\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.6290 - accuracy: 0.7231\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.6209 - accuracy: 0.7190\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.8503 - accuracy: 0.5082\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 1.2454 - accuracy: 0.5226\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.8891 - accuracy: 0.5432\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 0.7540 - accuracy: 0.5802\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.7214 - accuracy: 0.6008\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.6800 - accuracy: 0.6214\n",
      "Epoch 6/100\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.6454 - accuracy: 0.6502\n",
      "Epoch 7/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.6365 - accuracy: 0.6502\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.7602 - accuracy: 0.5333\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 3.7400 - accuracy: 0.4362\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.6071 - accuracy: 0.3868\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 1.9906 - accuracy: 0.3909\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 1.5468 - accuracy: 0.4321\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 1.2994 - accuracy: 0.4527\n",
      "Epoch 6/100\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 1.0811 - accuracy: 0.4938\n",
      "Epoch 7/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.9773 - accuracy: 0.5391\n",
      "Epoch 8/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.9019 - accuracy: 0.5473\n",
      "Epoch 9/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.8457 - accuracy: 0.5638\n",
      "Epoch 10/100\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 0.8065 - accuracy: 0.5926\n",
      "Epoch 11/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.7723 - accuracy: 0.5885\n",
      "Epoch 12/100\n",
      "243/243 [==============================] - 0s 60us/sample - loss: 0.7511 - accuracy: 0.5802\n",
      "Epoch 13/100\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.7309 - accuracy: 0.5761\n",
      "Epoch 14/100\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.7169 - accuracy: 0.5802\n",
      "Epoch 15/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.7029 - accuracy: 0.6049\n",
      "Epoch 16/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.6924 - accuracy: 0.6132\n",
      "Epoch 17/100\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 0.6803 - accuracy: 0.6173\n",
      "Epoch 18/100\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.6749 - accuracy: 0.6132\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.6363 - accuracy: 0.7500\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "61/61 [==============================] - 0s 948us/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.5248 - accuracy: 0.4752\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5248 - accuracy: 0.4752\n",
      "61/61 [==============================] - 0s 948us/sample - loss: 0.6230 - accuracy: 0.3770\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.3731 - accuracy: 0.6322\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.3655 - accuracy: 0.6322\n",
      "61/61 [==============================] - 0s 948us/sample - loss: 0.4585 - accuracy: 0.5574\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.5597 - accuracy: 0.4403\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.5597 - accuracy: 0.4403\n",
      "60/60 [==============================] - 0s 947us/sample - loss: 0.4833 - accuracy: 0.5167\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.4849 - accuracy: 0.5185\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.3997 - accuracy: 0.6379\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.3803 - accuracy: 0.6543\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - 0s 70us/sample - loss: 0.3785 - accuracy: 0.6502\n",
      "60/60 [==============================] - 0s 981us/sample - loss: 0.2932 - accuracy: 0.7667\n",
      "Loss: mean_absolute_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_absolute_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.5145 - accuracy: 0.4793\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.3835 - accuracy: 0.6240\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.3271 - accuracy: 0.6818\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.3612 - accuracy: 0.6405\n",
      "61/61 [==============================] - 0s 915us/sample - loss: 0.2860 - accuracy: 0.7049\n",
      "Loss: mean_absolute_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.3927 - accuracy: 0.6198\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 0.3654 - accuracy: 0.6570\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 0.3078 - accuracy: 0.7190\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.3248 - accuracy: 0.6860\n",
      "61/61 [==============================] - 0s 916us/sample - loss: 0.4650 - accuracy: 0.5410\n",
      "Loss: mean_absolute_error; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 1s 3ms/sample - loss: 0.4310 - accuracy: 0.5967\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.4027 - accuracy: 0.6049\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 41us/sample - loss: 0.4007 - accuracy: 0.5967\n",
      "60/60 [==============================] - 0s 981us/sample - loss: 0.4205 - accuracy: 0.6167\n",
      "Loss: mean_absolute_error; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 1s 3ms/sample - loss: 0.4626 - accuracy: 0.5432\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.3878 - accuracy: 0.6255\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4070 - accuracy: 0.5802\n",
      "60/60 [==============================] - 0s 931us/sample - loss: 0.3342 - accuracy: 0.7167\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 856us/sample - loss: 0.5100 - accuracy: 0.4917\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4097 - accuracy: 0.5909\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4119 - accuracy: 0.5950\n",
      "61/61 [==============================] - 0s 916us/sample - loss: 0.4233 - accuracy: 0.5738\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 898us/sample - loss: 0.4752 - accuracy: 0.5248\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4752 - accuracy: 0.5248\n",
      "61/61 [==============================] - 0s 965us/sample - loss: 0.3770 - accuracy: 0.6230\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 882us/sample - loss: 0.5608 - accuracy: 0.4380\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5271 - accuracy: 0.4793\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.4382 - accuracy: 0.5620\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.4382 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 965us/sample - loss: 0.5243 - accuracy: 0.4754\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 841us/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "60/60 [==============================] - 0s 964us/sample - loss: 0.5167 - accuracy: 0.4833\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 860us/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "60/60 [==============================] - 0s 997us/sample - loss: 0.6167 - accuracy: 0.3833\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 973us/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "61/61 [==============================] - 0s 916us/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 993us/sample - loss: 0.4743 - accuracy: 0.5248\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4743 - accuracy: 0.5248\n",
      "61/61 [==============================] - 0s 916us/sample - loss: 0.3809 - accuracy: 0.6230\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 981us/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 915us/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 993us/sample - loss: 0.5594 - accuracy: 0.4403\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.5594 - accuracy: 0.4403\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.4731 - accuracy: 0.5333\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 985us/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "60/60 [==============================] - 0s 930us/sample - loss: 0.6167 - accuracy: 0.3833\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 931us/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "61/61 [==============================] - 0s 932us/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 915us/sample - loss: 0.4752 - accuracy: 0.5248\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.4752 - accuracy: 0.5248\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.3770 - accuracy: 0.6230\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 907us/sample - loss: 0.4423 - accuracy: 0.5620\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4375 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 948us/sample - loss: 0.5234 - accuracy: 0.4754\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 907us/sample - loss: 0.5597 - accuracy: 0.4403\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.5585 - accuracy: 0.4403\n",
      "60/60 [==============================] - 0s 931us/sample - loss: 0.4844 - accuracy: 0.5167\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 954us/sample - loss: 0.4341 - accuracy: 0.5720\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4020 - accuracy: 0.6008\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.3928 - accuracy: 0.6173\n",
      "60/60 [==============================] - 0s 931us/sample - loss: 0.3424 - accuracy: 0.7500\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4553 - accuracy: 0.5124\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.3639 - accuracy: 0.5826\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.3321 - accuracy: 0.6074\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.3403 - accuracy: 0.6157\n",
      "61/61 [==============================] - 0s 899us/sample - loss: 0.2875 - accuracy: 0.6393\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.5171 - accuracy: 0.4380\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.3567 - accuracy: 0.4463\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.2442 - accuracy: 0.5826\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.2139 - accuracy: 0.6488\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.1986 - accuracy: 0.6983\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.1988 - accuracy: 0.7025\n",
      "61/61 [==============================] - 0s 932us/sample - loss: 0.1799 - accuracy: 0.7541\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 956us/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.2920 - accuracy: 0.5720\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.2364 - accuracy: 0.6379\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.2153 - accuracy: 0.6626\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.2220 - accuracy: 0.6708\n",
      "60/60 [==============================] - 0s 964us/sample - loss: 0.2753 - accuracy: 0.6500\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.3372 - accuracy: 0.5473\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.2479 - accuracy: 0.6337\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.2378 - accuracy: 0.6173\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.2215 - accuracy: 0.6420\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.2188 - accuracy: 0.6626\n",
      "60/60 [==============================] - 0s 930us/sample - loss: 0.1791 - accuracy: 0.7167\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/sample - loss: 0.3832 - accuracy: 0.5620\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.3484 - accuracy: 0.5455\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.3024 - accuracy: 0.6198\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.2898 - accuracy: 0.6364\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.2864 - accuracy: 0.6529\n",
      "61/61 [==============================] - 0s 899us/sample - loss: 0.2342 - accuracy: 0.7049\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.2861 - accuracy: 0.5620\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.2670 - accuracy: 0.5289\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.2414 - accuracy: 0.5950\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.2216 - accuracy: 0.6694\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.2370 - accuracy: 0.5950\n",
      "61/61 [==============================] - 0s 915us/sample - loss: 0.2556 - accuracy: 0.6066\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.4944 - accuracy: 0.4711\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 899us/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 1s 2ms/sample - loss: 0.4328 - accuracy: 0.5597\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.3923 - accuracy: 0.5597\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 0s 193us/sample - loss: 0.2622 - accuracy: 0.5720\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.2257 - accuracy: 0.6379\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.2164 - accuracy: 0.6379\n",
      "60/60 [==============================] - 0s 914us/sample - loss: 0.2400 - accuracy: 0.5833\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 1s 2ms/sample - loss: 0.3858 - accuracy: 0.5226\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.3171 - accuracy: 0.5844\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.2690 - accuracy: 0.6296\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.2758 - accuracy: 0.6049\n",
      "60/60 [==============================] - 0s 910us/sample - loss: 0.2592 - accuracy: 0.5500\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 853us/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "61/61 [==============================] - 0s 932us/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 919us/sample - loss: 0.5248 - accuracy: 0.4752\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.5248 - accuracy: 0.4752\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.6230 - accuracy: 0.3770\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 866us/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 949us/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 837us/sample - loss: 0.4604 - accuracy: 0.4444\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.2831 - accuracy: 0.6049\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.2449 - accuracy: 0.6049\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.2698 - accuracy: 0.5391\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.2482 - accuracy: 0.6167\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 866us/sample - loss: 0.4775 - accuracy: 0.5185\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4733 - accuracy: 0.5267\n",
      "60/60 [==============================] - 0s 947us/sample - loss: 0.3833 - accuracy: 0.6167\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "61/61 [==============================] - 0s 965us/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/sample - loss: 0.4752 - accuracy: 0.5248\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.4752 - accuracy: 0.5248\n",
      "61/61 [==============================] - 0s 915us/sample - loss: 0.3770 - accuracy: 0.6230\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "61/61 [==============================] - 0s 932us/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 963us/sample - loss: 0.5417 - accuracy: 0.4403\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.5414 - accuracy: 0.4403\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.4438 - accuracy: 0.5167\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 989us/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "60/60 [==============================] - 0s 947us/sample - loss: 0.6167 - accuracy: 0.3833\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 940us/sample - loss: 0.5060 - accuracy: 0.4050\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.3105 - accuracy: 0.5124\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.2625 - accuracy: 0.5744\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.2569 - accuracy: 0.5909\n",
      "61/61 [==============================] - 0s 892us/sample - loss: 0.2464 - accuracy: 0.5902\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 954us/sample - loss: 0.4752 - accuracy: 0.5248\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4752 - accuracy: 0.5248\n",
      "61/61 [==============================] - 0s 924us/sample - loss: 0.3770 - accuracy: 0.6230\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 907us/sample - loss: 0.4467 - accuracy: 0.4669\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.4037 - accuracy: 0.4959\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.3649 - accuracy: 0.5041\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.3629 - accuracy: 0.4917\n",
      "61/61 [==============================] - 0s 948us/sample - loss: 0.4065 - accuracy: 0.4426\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 907us/sample - loss: 0.5597 - accuracy: 0.4403\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.5597 - accuracy: 0.4403\n",
      "60/60 [==============================] - 0s 930us/sample - loss: 0.4833 - accuracy: 0.5167\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - 0s 918us/sample - loss: 0.4733 - accuracy: 0.5267\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4733 - accuracy: 0.5267\n",
      "60/60 [==============================] - 0s 947us/sample - loss: 0.3833 - accuracy: 0.6167\n",
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 3.0225 - accuracy: 0.5165\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.5641 - accuracy: 0.5992\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.0786 - accuracy: 0.5826\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.8127 - accuracy: 0.6488\n",
      "Epoch 5/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.7558 - accuracy: 0.6116\n",
      "Epoch 6/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.7041 - accuracy: 0.6405\n",
      "Epoch 7/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6694 - accuracy: 0.6240\n",
      "Epoch 8/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6752 - accuracy: 0.6116\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.5062 - accuracy: 0.7377\n",
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 4.9774 - accuracy: 0.4504\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.5376 - accuracy: 0.4256\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.7420 - accuracy: 0.4298\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.4653 - accuracy: 0.4711\n",
      "Epoch 5/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.2175 - accuracy: 0.5455\n",
      "Epoch 6/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.0075 - accuracy: 0.5661\n",
      "Epoch 7/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.9066 - accuracy: 0.5826\n",
      "Epoch 8/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.8396 - accuracy: 0.5868\n",
      "Epoch 9/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.8143 - accuracy: 0.5744\n",
      "Epoch 10/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.8542 - accuracy: 0.5785\n",
      "61/61 [==============================] - 0s 998us/sample - loss: 0.9681 - accuracy: 0.6393\n",
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 2.1864 - accuracy: 0.5000\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.0043 - accuracy: 0.5041\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.8755 - accuracy: 0.5620\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.6551 - accuracy: 0.5702\n",
      "Epoch 5/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6103 - accuracy: 0.6281\n",
      "Epoch 6/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.5526 - accuracy: 0.7149\n",
      "Epoch 7/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.5432 - accuracy: 0.7397\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.7862 - accuracy: 0.5246\n",
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 2.4236 - accuracy: 0.5885\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 42us/sample - loss: 1.2406 - accuracy: 0.6091\n",
      "Epoch 3/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.0027 - accuracy: 0.6337\n",
      "Epoch 4/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.7440 - accuracy: 0.6584\n",
      "Epoch 5/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.6070 - accuracy: 0.6831\n",
      "Epoch 6/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.6144 - accuracy: 0.6667\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.7531 - accuracy: 0.6667\n",
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 2.1117 - accuracy: 0.6214\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.3476 - accuracy: 0.6255\n",
      "Epoch 3/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.9902 - accuracy: 0.5638\n",
      "Epoch 4/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.8342 - accuracy: 0.5062\n",
      "Epoch 5/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.9044 - accuracy: 0.5597\n",
      "60/60 [==============================] - 0s 997us/sample - loss: 0.8524 - accuracy: 0.6333\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 1s 3ms/sample - loss: 12.7961 - accuracy: 0.4504\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 2.2018 - accuracy: 0.4711\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.8375 - accuracy: 0.6198\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.7572 - accuracy: 0.6529\n",
      "Epoch 5/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.7298 - accuracy: 0.5992\n",
      "Epoch 6/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.7112 - accuracy: 0.6570\n",
      "Epoch 7/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6983 - accuracy: 0.6364\n",
      "Epoch 8/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.6825 - accuracy: 0.6198\n",
      "Epoch 9/150\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.6752 - accuracy: 0.6281\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.5039 - accuracy: 0.8361\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/sample - loss: 1.6067 - accuracy: 0.4711\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.9744 - accuracy: 0.4628\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.8032 - accuracy: 0.4669\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.7201 - accuracy: 0.5083\n",
      "Epoch 5/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6826 - accuracy: 0.5702\n",
      "Epoch 6/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6581 - accuracy: 0.6033\n",
      "Epoch 7/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6356 - accuracy: 0.6694\n",
      "Epoch 8/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6255 - accuracy: 0.6694\n",
      "Epoch 9/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6154 - accuracy: 0.6901\n",
      "Epoch 10/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6148 - accuracy: 0.6653\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.6065 - accuracy: 0.7049\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 1s 3ms/sample - loss: 9.8569 - accuracy: 0.4380\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.4121 - accuracy: 0.4380\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.8083 - accuracy: 0.6033\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.6875 - accuracy: 0.6570\n",
      "Epoch 5/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.6555 - accuracy: 0.6777\n",
      "Epoch 6/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.6146 - accuracy: 0.7025\n",
      "Epoch 7/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6083 - accuracy: 0.7025\n",
      "61/61 [==============================] - 0s 997us/sample - loss: 0.8378 - accuracy: 0.5082\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 1s 3ms/sample - loss: 9.6121 - accuracy: 0.5597\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 2.1755 - accuracy: 0.5267\n",
      "Epoch 3/150\n",
      "243/243 [==============================] - 0s 46us/sample - loss: 0.7117 - accuracy: 0.5309\n",
      "Epoch 4/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.6950 - accuracy: 0.5720\n",
      "Epoch 5/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.6959 - accuracy: 0.5556\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.8696 - accuracy: 0.5833\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 1s 3ms/sample - loss: 14.5924 - accuracy: 0.5267\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.8755 - accuracy: 0.5062\n",
      "Epoch 3/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.1172 - accuracy: 0.4074\n",
      "Epoch 4/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.9154 - accuracy: 0.4403\n",
      "Epoch 5/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.8300 - accuracy: 0.5062\n",
      "Epoch 6/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.8184 - accuracy: 0.4815\n",
      "Epoch 7/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.8040 - accuracy: 0.4733\n",
      "Epoch 8/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.7974 - accuracy: 0.5679\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 1.0252 - accuracy: 0.3667\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 7.9800 - accuracy: 0.5124\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6739 - accuracy: 0.5950\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6655 - accuracy: 0.6240\n",
      "61/61 [==============================] - 0s 997us/sample - loss: 0.6155 - accuracy: 0.6885\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 5.1213 - accuracy: 0.5289\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.7048 - accuracy: 0.5248\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6902 - accuracy: 0.5331\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6910 - accuracy: 0.5289\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.6916 - accuracy: 0.6230\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 4.9623 - accuracy: 0.5620\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6925 - accuracy: 0.5620\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6922 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.6936 - accuracy: 0.4754\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 6.6960 - accuracy: 0.5514\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.6894 - accuracy: 0.4609\n",
      "Epoch 3/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.6819 - accuracy: 0.6502\n",
      "60/60 [==============================] - 0s 998us/sample - loss: 0.6790 - accuracy: 0.6667\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 4.8715 - accuracy: 0.5185\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.6927 - accuracy: 0.5267\n",
      "Epoch 3/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.6924 - accuracy: 0.5267\n",
      "60/60 [==============================] - 0s 998us/sample - loss: 0.6801 - accuracy: 0.6167\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 10.5137 - accuracy: 0.5496\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.5044 - accuracy: 0.5496\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 10.8698 - accuracy: 0.5246\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 8.4416 - accuracy: 0.4752\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 38us/sample - loss: 8.4155 - accuracy: 0.4752\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 8.3894 - accuracy: 0.4752\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 8.3629 - accuracy: 0.4752\n",
      "Epoch 5/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.3359 - accuracy: 0.4752\n",
      "Epoch 6/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 8.3090 - accuracy: 0.4752\n",
      "Epoch 7/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 8.2822 - accuracy: 0.4752\n",
      "Epoch 8/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 8.2546 - accuracy: 0.4752\n",
      "Epoch 9/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.2271 - accuracy: 0.4752\n",
      "Epoch 10/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.1996 - accuracy: 0.4752\n",
      "Epoch 11/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 8.1710 - accuracy: 0.4752\n",
      "Epoch 12/150\n",
      "242/242 [==============================] - 0s 39us/sample - loss: 8.1426 - accuracy: 0.4752\n",
      "Epoch 13/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 8.1140 - accuracy: 0.4752\n",
      "Epoch 14/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 8.0851 - accuracy: 0.4752\n",
      "Epoch 15/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.0556 - accuracy: 0.4752\n",
      "Epoch 16/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.0260 - accuracy: 0.4752\n",
      "Epoch 17/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 37us/sample - loss: 7.9963 - accuracy: 0.4752\n",
      "Epoch 18/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 7.9667 - accuracy: 0.4752\n",
      "Epoch 19/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.9369 - accuracy: 0.4752\n",
      "Epoch 20/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.9067 - accuracy: 0.4752\n",
      "Epoch 21/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.8763 - accuracy: 0.4752\n",
      "Epoch 22/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.8454 - accuracy: 0.4752\n",
      "Epoch 23/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.8152 - accuracy: 0.4752\n",
      "Epoch 24/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.7850 - accuracy: 0.4752\n",
      "Epoch 25/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 7.7532 - accuracy: 0.4752\n",
      "Epoch 26/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.7213 - accuracy: 0.4752\n",
      "Epoch 27/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 7.6897 - accuracy: 0.4752\n",
      "Epoch 28/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.6579 - accuracy: 0.4752\n",
      "Epoch 29/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.6255 - accuracy: 0.4752\n",
      "Epoch 30/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.5937 - accuracy: 0.4752\n",
      "Epoch 31/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.5611 - accuracy: 0.4752\n",
      "Epoch 32/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.5284 - accuracy: 0.4752\n",
      "Epoch 33/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.4948 - accuracy: 0.4752\n",
      "Epoch 34/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.4614 - accuracy: 0.4752\n",
      "Epoch 35/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.4280 - accuracy: 0.4752\n",
      "Epoch 36/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 7.3949 - accuracy: 0.4752\n",
      "Epoch 37/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.3609 - accuracy: 0.4752\n",
      "Epoch 38/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 7.3270 - accuracy: 0.4752\n",
      "Epoch 39/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.2933 - accuracy: 0.4752\n",
      "Epoch 40/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.2590 - accuracy: 0.4752\n",
      "Epoch 41/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.2244 - accuracy: 0.4752\n",
      "Epoch 42/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.1896 - accuracy: 0.4752\n",
      "Epoch 43/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.1552 - accuracy: 0.4752\n",
      "Epoch 44/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.1202 - accuracy: 0.4752\n",
      "Epoch 45/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.0855 - accuracy: 0.4752\n",
      "Epoch 46/150\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 7.0500 - accuracy: 0.4752\n",
      "Epoch 47/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 7.0141 - accuracy: 0.4752\n",
      "Epoch 48/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 6.9790 - accuracy: 0.4752\n",
      "Epoch 49/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.9430 - accuracy: 0.4752\n",
      "Epoch 50/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 6.9072 - accuracy: 0.4752\n",
      "Epoch 51/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 6.8710 - accuracy: 0.4752\n",
      "Epoch 52/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.8344 - accuracy: 0.4752\n",
      "Epoch 53/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.7974 - accuracy: 0.4752\n",
      "Epoch 54/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 6.7608 - accuracy: 0.4752\n",
      "Epoch 55/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.7232 - accuracy: 0.4752\n",
      "Epoch 56/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 6.6858 - accuracy: 0.4752\n",
      "Epoch 57/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.6485 - accuracy: 0.4752\n",
      "Epoch 58/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.6114 - accuracy: 0.4752\n",
      "Epoch 59/150\n",
      "242/242 [==============================] - 0s 74us/sample - loss: 6.5741 - accuracy: 0.4752\n",
      "Epoch 60/150\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 6.5357 - accuracy: 0.4752\n",
      "Epoch 61/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 6.4982 - accuracy: 0.4752\n",
      "Epoch 62/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 6.4608 - accuracy: 0.4752\n",
      "Epoch 63/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.4221 - accuracy: 0.4752\n",
      "Epoch 64/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 6.3835 - accuracy: 0.4752\n",
      "Epoch 65/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.3445 - accuracy: 0.4752\n",
      "Epoch 66/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.3058 - accuracy: 0.4752\n",
      "Epoch 67/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.2668 - accuracy: 0.4752\n",
      "Epoch 68/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.2266 - accuracy: 0.4752\n",
      "Epoch 69/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.1866 - accuracy: 0.4752\n",
      "Epoch 70/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 6.1471 - accuracy: 0.4752\n",
      "Epoch 71/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 6.1067 - accuracy: 0.4752\n",
      "Epoch 72/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.0655 - accuracy: 0.4752\n",
      "Epoch 73/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.0251 - accuracy: 0.4752\n",
      "Epoch 74/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.9851 - accuracy: 0.4752\n",
      "Epoch 75/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.9445 - accuracy: 0.4752\n",
      "Epoch 76/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.9050 - accuracy: 0.4711\n",
      "Epoch 77/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.8641 - accuracy: 0.4711\n",
      "Epoch 78/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.8239 - accuracy: 0.4669\n",
      "Epoch 79/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.7831 - accuracy: 0.4669\n",
      "Epoch 80/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.7417 - accuracy: 0.4669\n",
      "Epoch 81/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.7005 - accuracy: 0.4669\n",
      "Epoch 82/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.6598 - accuracy: 0.4669\n",
      "Epoch 83/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.6186 - accuracy: 0.4669\n",
      "Epoch 84/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 5.5771 - accuracy: 0.4669\n",
      "Epoch 85/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.5350 - accuracy: 0.4669\n",
      "Epoch 86/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 5.4941 - accuracy: 0.4669\n",
      "Epoch 87/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 5.4546 - accuracy: 0.4669\n",
      "Epoch 88/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.4133 - accuracy: 0.4669\n",
      "Epoch 89/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.3723 - accuracy: 0.4669\n",
      "Epoch 90/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 5.3312 - accuracy: 0.4669\n",
      "Epoch 91/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.2908 - accuracy: 0.4669\n",
      "Epoch 92/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 5.2503 - accuracy: 0.4669\n",
      "Epoch 93/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 5.2089 - accuracy: 0.4669\n",
      "Epoch 94/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.1680 - accuracy: 0.4628\n",
      "Epoch 95/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 41us/sample - loss: 5.1274 - accuracy: 0.4628\n",
      "Epoch 96/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.0863 - accuracy: 0.4628\n",
      "Epoch 97/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.0455 - accuracy: 0.4628\n",
      "Epoch 98/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.0045 - accuracy: 0.4628\n",
      "Epoch 99/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.9642 - accuracy: 0.4628\n",
      "Epoch 100/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.9240 - accuracy: 0.4587\n",
      "Epoch 101/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.8840 - accuracy: 0.4587\n",
      "Epoch 102/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.8445 - accuracy: 0.4545\n",
      "Epoch 103/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.8048 - accuracy: 0.4545\n",
      "Epoch 104/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.7653 - accuracy: 0.4463\n",
      "Epoch 105/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.7260 - accuracy: 0.4421\n",
      "Epoch 106/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.6867 - accuracy: 0.4380\n",
      "Epoch 107/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.6477 - accuracy: 0.4380\n",
      "Epoch 108/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.6082 - accuracy: 0.4339\n",
      "Epoch 109/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.5698 - accuracy: 0.4339\n",
      "Epoch 110/150\n",
      "242/242 [==============================] - 0s 36us/sample - loss: 4.5316 - accuracy: 0.4298\n",
      "Epoch 111/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.4931 - accuracy: 0.4298\n",
      "Epoch 112/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.4549 - accuracy: 0.4298\n",
      "Epoch 113/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.4169 - accuracy: 0.4298\n",
      "Epoch 114/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.3791 - accuracy: 0.4256\n",
      "Epoch 115/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.3412 - accuracy: 0.4215\n",
      "Epoch 116/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.3038 - accuracy: 0.4174\n",
      "Epoch 117/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 4.2665 - accuracy: 0.4091\n",
      "Epoch 118/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.2299 - accuracy: 0.4091\n",
      "Epoch 119/150\n",
      "242/242 [==============================] - 0s 40us/sample - loss: 4.1942 - accuracy: 0.4008\n",
      "Epoch 120/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.1584 - accuracy: 0.4050\n",
      "Epoch 121/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.1224 - accuracy: 0.4050\n",
      "Epoch 122/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.0879 - accuracy: 0.3967\n",
      "Epoch 123/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.0518 - accuracy: 0.3967\n",
      "Epoch 124/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.0165 - accuracy: 0.3967\n",
      "Epoch 125/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.9812 - accuracy: 0.3926\n",
      "Epoch 126/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 3.9462 - accuracy: 0.3926\n",
      "Epoch 127/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.9112 - accuracy: 0.3884\n",
      "Epoch 128/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.8762 - accuracy: 0.3884\n",
      "Epoch 129/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.8428 - accuracy: 0.3926\n",
      "Epoch 130/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.8099 - accuracy: 0.3884\n",
      "Epoch 131/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 3.7769 - accuracy: 0.3884\n",
      "Epoch 132/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.7438 - accuracy: 0.3843\n",
      "Epoch 133/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.7106 - accuracy: 0.3843\n",
      "Epoch 134/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 3.6782 - accuracy: 0.3884\n",
      "Epoch 135/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.6454 - accuracy: 0.3884\n",
      "Epoch 136/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.6138 - accuracy: 0.3926\n",
      "Epoch 137/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 3.5836 - accuracy: 0.3884\n",
      "Epoch 138/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.5521 - accuracy: 0.3843\n",
      "Epoch 139/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.5220 - accuracy: 0.3802\n",
      "Epoch 140/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.4919 - accuracy: 0.3802\n",
      "Epoch 141/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.4634 - accuracy: 0.3843\n",
      "Epoch 142/150\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 3.4343 - accuracy: 0.3843\n",
      "Epoch 143/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.4058 - accuracy: 0.3843\n",
      "Epoch 144/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.3760 - accuracy: 0.3884\n",
      "Epoch 145/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.3469 - accuracy: 0.3884\n",
      "Epoch 146/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.3180 - accuracy: 0.3884\n",
      "Epoch 147/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.2900 - accuracy: 0.3884\n",
      "Epoch 148/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.2629 - accuracy: 0.3884\n",
      "Epoch 149/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.2360 - accuracy: 0.3884\n",
      "Epoch 150/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 3.2104 - accuracy: 0.3884\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 4.1162 - accuracy: 0.2951\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 11.9646 - accuracy: 0.5620\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 11.9426 - accuracy: 0.5620\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 11.9205 - accuracy: 0.5620\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 11.8982 - accuracy: 0.5620\n",
      "Epoch 5/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.8757 - accuracy: 0.5620\n",
      "Epoch 6/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.8526 - accuracy: 0.5620\n",
      "Epoch 7/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 11.8294 - accuracy: 0.5620\n",
      "Epoch 8/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.8059 - accuracy: 0.5620\n",
      "Epoch 9/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.7823 - accuracy: 0.5620\n",
      "Epoch 10/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.7585 - accuracy: 0.5620\n",
      "Epoch 11/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.7343 - accuracy: 0.5620\n",
      "Epoch 12/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 11.7098 - accuracy: 0.5620\n",
      "Epoch 13/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 11.6852 - accuracy: 0.5620\n",
      "Epoch 14/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.6604 - accuracy: 0.5620\n",
      "Epoch 15/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.6356 - accuracy: 0.5620\n",
      "Epoch 16/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.6108 - accuracy: 0.5620\n",
      "Epoch 17/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.5855 - accuracy: 0.5620\n",
      "Epoch 18/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 11.5603 - accuracy: 0.5620\n",
      "Epoch 19/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 11.5346 - accuracy: 0.5620\n",
      "Epoch 20/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.5087 - accuracy: 0.5620\n",
      "Epoch 21/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 37us/sample - loss: 11.4830 - accuracy: 0.5620\n",
      "Epoch 22/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 11.4562 - accuracy: 0.5620\n",
      "Epoch 23/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.4295 - accuracy: 0.5620\n",
      "Epoch 24/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 11.4023 - accuracy: 0.5620\n",
      "Epoch 25/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.3753 - accuracy: 0.5620\n",
      "Epoch 26/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 11.3484 - accuracy: 0.5620\n",
      "Epoch 27/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.3210 - accuracy: 0.5620\n",
      "Epoch 28/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.2940 - accuracy: 0.5620\n",
      "Epoch 29/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.2654 - accuracy: 0.5620\n",
      "Epoch 30/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 11.2369 - accuracy: 0.5620\n",
      "Epoch 31/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.2078 - accuracy: 0.5620\n",
      "Epoch 32/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.1786 - accuracy: 0.5620\n",
      "Epoch 33/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.1485 - accuracy: 0.5620\n",
      "Epoch 34/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.1187 - accuracy: 0.5620\n",
      "Epoch 35/150\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 11.0883 - accuracy: 0.5620\n",
      "Epoch 36/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 11.0581 - accuracy: 0.5620\n",
      "Epoch 37/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.0276 - accuracy: 0.5620\n",
      "Epoch 38/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 10.9962 - accuracy: 0.5620\n",
      "Epoch 39/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.9650 - accuracy: 0.5620\n",
      "Epoch 40/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.9335 - accuracy: 0.5620\n",
      "Epoch 41/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.9024 - accuracy: 0.5620\n",
      "Epoch 42/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.8711 - accuracy: 0.5620\n",
      "Epoch 43/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.8397 - accuracy: 0.5620\n",
      "Epoch 44/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 10.8080 - accuracy: 0.5620\n",
      "Epoch 45/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.7757 - accuracy: 0.5620\n",
      "Epoch 46/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 10.7423 - accuracy: 0.5620\n",
      "Epoch 47/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 10.7088 - accuracy: 0.5620\n",
      "Epoch 48/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.6760 - accuracy: 0.5620\n",
      "Epoch 49/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 10.6436 - accuracy: 0.5620\n",
      "Epoch 50/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 10.6107 - accuracy: 0.5620\n",
      "Epoch 51/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 10.5765 - accuracy: 0.5620\n",
      "Epoch 52/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.5423 - accuracy: 0.5620\n",
      "Epoch 53/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.5078 - accuracy: 0.5620\n",
      "Epoch 54/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 10.4737 - accuracy: 0.5620\n",
      "Epoch 55/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.4387 - accuracy: 0.5620\n",
      "Epoch 56/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 10.4040 - accuracy: 0.5620\n",
      "Epoch 57/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.3689 - accuracy: 0.5620\n",
      "Epoch 58/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.3338 - accuracy: 0.5620\n",
      "Epoch 59/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 10.2987 - accuracy: 0.5620\n",
      "Epoch 60/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.2631 - accuracy: 0.5620\n",
      "Epoch 61/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.2262 - accuracy: 0.5620\n",
      "Epoch 62/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.1890 - accuracy: 0.5620\n",
      "Epoch 63/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.1527 - accuracy: 0.5620\n",
      "Epoch 64/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.1159 - accuracy: 0.5620\n",
      "Epoch 65/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 10.0787 - accuracy: 0.5620\n",
      "Epoch 66/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.0409 - accuracy: 0.5620\n",
      "Epoch 67/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.0038 - accuracy: 0.5620\n",
      "Epoch 68/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.9658 - accuracy: 0.5620\n",
      "Epoch 69/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 9.9281 - accuracy: 0.5620\n",
      "Epoch 70/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 9.8904 - accuracy: 0.5620\n",
      "Epoch 71/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 9.8523 - accuracy: 0.5620\n",
      "Epoch 72/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.8149 - accuracy: 0.5620\n",
      "Epoch 73/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 9.7771 - accuracy: 0.5620\n",
      "Epoch 74/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 9.7383 - accuracy: 0.5620\n",
      "Epoch 75/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 9.7000 - accuracy: 0.5620\n",
      "Epoch 76/150\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 9.6616 - accuracy: 0.5620\n",
      "Epoch 77/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 9.6223 - accuracy: 0.5620\n",
      "Epoch 78/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.5837 - accuracy: 0.5620\n",
      "Epoch 79/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 9.5453 - accuracy: 0.5620\n",
      "Epoch 80/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 9.5059 - accuracy: 0.5620\n",
      "Epoch 81/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 9.4672 - accuracy: 0.5620\n",
      "Epoch 82/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 9.4281 - accuracy: 0.5620\n",
      "Epoch 83/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.3896 - accuracy: 0.5620\n",
      "Epoch 84/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.3499 - accuracy: 0.5620\n",
      "Epoch 85/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.3106 - accuracy: 0.5620\n",
      "Epoch 86/150\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 9.2714 - accuracy: 0.5620\n",
      "Epoch 87/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 9.2311 - accuracy: 0.5620\n",
      "Epoch 88/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.1911 - accuracy: 0.5620\n",
      "Epoch 89/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 9.1512 - accuracy: 0.5620\n",
      "Epoch 90/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 9.1107 - accuracy: 0.5620\n",
      "Epoch 91/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.0703 - accuracy: 0.5620\n",
      "Epoch 92/150\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 9.0300 - accuracy: 0.5620\n",
      "Epoch 93/150\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 8.9894 - accuracy: 0.5620\n",
      "Epoch 94/150\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 8.9492 - accuracy: 0.5620\n",
      "Epoch 95/150\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 8.9091 - accuracy: 0.5620\n",
      "Epoch 96/150\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 8.8697 - accuracy: 0.5620\n",
      "Epoch 97/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 8.8293 - accuracy: 0.5620\n",
      "Epoch 98/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 41us/sample - loss: 8.7887 - accuracy: 0.5620\n",
      "Epoch 99/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 8.7478 - accuracy: 0.5620\n",
      "Epoch 100/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 8.7068 - accuracy: 0.5620\n",
      "Epoch 101/150\n",
      "242/242 [==============================] - 0s 40us/sample - loss: 8.6661 - accuracy: 0.5620\n",
      "Epoch 102/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.6246 - accuracy: 0.5620\n",
      "Epoch 103/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.5836 - accuracy: 0.5620\n",
      "Epoch 104/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.5417 - accuracy: 0.5620\n",
      "Epoch 105/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.4998 - accuracy: 0.5620\n",
      "Epoch 106/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.4591 - accuracy: 0.5620\n",
      "Epoch 107/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.4180 - accuracy: 0.5620\n",
      "Epoch 108/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 8.3763 - accuracy: 0.5620\n",
      "Epoch 109/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 8.3351 - accuracy: 0.5620\n",
      "Epoch 110/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.2936 - accuracy: 0.5620\n",
      "Epoch 111/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 8.2524 - accuracy: 0.5620\n",
      "Epoch 112/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 8.2110 - accuracy: 0.5620\n",
      "Epoch 113/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 8.1694 - accuracy: 0.5620\n",
      "Epoch 114/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 8.1274 - accuracy: 0.5620\n",
      "Epoch 115/150\n",
      "242/242 [==============================] - 0s 74us/sample - loss: 8.0857 - accuracy: 0.5620\n",
      "Epoch 116/150\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 8.0440 - accuracy: 0.5620\n",
      "Epoch 117/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 8.0023 - accuracy: 0.5620\n",
      "Epoch 118/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.9602 - accuracy: 0.5620\n",
      "Epoch 119/150\n",
      "242/242 [==============================] - 0s 43us/sample - loss: 7.9176 - accuracy: 0.5620\n",
      "Epoch 120/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 7.8750 - accuracy: 0.5620\n",
      "Epoch 121/150\n",
      "242/242 [==============================] - 0s 70us/sample - loss: 7.8328 - accuracy: 0.5620\n",
      "Epoch 122/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 7.7906 - accuracy: 0.5620\n",
      "Epoch 123/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.7480 - accuracy: 0.5620\n",
      "Epoch 124/150\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 7.7052 - accuracy: 0.5620\n",
      "Epoch 125/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 7.6617 - accuracy: 0.5620\n",
      "Epoch 126/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.6187 - accuracy: 0.5620\n",
      "Epoch 127/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 7.5746 - accuracy: 0.5620\n",
      "Epoch 128/150\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 7.5327 - accuracy: 0.5620\n",
      "Epoch 129/150\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 7.4895 - accuracy: 0.5620\n",
      "Epoch 130/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 7.4459 - accuracy: 0.5620\n",
      "Epoch 131/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 7.4021 - accuracy: 0.5620\n",
      "Epoch 132/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 7.3584 - accuracy: 0.5620\n",
      "Epoch 133/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 7.3145 - accuracy: 0.5620\n",
      "Epoch 134/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 7.2705 - accuracy: 0.5620\n",
      "Epoch 135/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 7.2264 - accuracy: 0.5620\n",
      "Epoch 136/150\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 7.1836 - accuracy: 0.5620\n",
      "Epoch 137/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 7.1399 - accuracy: 0.5620\n",
      "Epoch 138/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.0958 - accuracy: 0.5620\n",
      "Epoch 139/150\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 7.0514 - accuracy: 0.5620\n",
      "Epoch 140/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 7.0069 - accuracy: 0.5620\n",
      "Epoch 141/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 6.9629 - accuracy: 0.5620\n",
      "Epoch 142/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 6.9180 - accuracy: 0.5620\n",
      "Epoch 143/150\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 6.8741 - accuracy: 0.5620\n",
      "Epoch 144/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 6.8299 - accuracy: 0.5620\n",
      "Epoch 145/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.7856 - accuracy: 0.5620\n",
      "Epoch 146/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 6.7406 - accuracy: 0.5620\n",
      "Epoch 147/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 6.6962 - accuracy: 0.5620\n",
      "Epoch 148/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.6522 - accuracy: 0.5620\n",
      "Epoch 149/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 6.6077 - accuracy: 0.5620\n",
      "Epoch 150/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 6.5625 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 8.5221 - accuracy: 0.4754\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 17.7402 - accuracy: 0.5597\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 17.7069 - accuracy: 0.5597\n",
      "Epoch 3/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 17.6732 - accuracy: 0.5597\n",
      "Epoch 4/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 17.6389 - accuracy: 0.5597\n",
      "Epoch 5/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 17.6048 - accuracy: 0.5597\n",
      "Epoch 6/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 17.5697 - accuracy: 0.5597\n",
      "Epoch 7/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 17.5351 - accuracy: 0.5597\n",
      "Epoch 8/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 17.5002 - accuracy: 0.5597\n",
      "Epoch 9/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 17.4641 - accuracy: 0.5597\n",
      "Epoch 10/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 17.4273 - accuracy: 0.5597\n",
      "Epoch 11/150\n",
      "243/243 [==============================] - 0s 38us/sample - loss: 17.3915 - accuracy: 0.5597\n",
      "Epoch 12/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 17.3546 - accuracy: 0.5597\n",
      "Epoch 13/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 17.3178 - accuracy: 0.5597\n",
      "Epoch 14/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 17.2811 - accuracy: 0.5597\n",
      "Epoch 15/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 17.2448 - accuracy: 0.5597\n",
      "Epoch 16/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 17.2086 - accuracy: 0.5597\n",
      "Epoch 17/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 17.1712 - accuracy: 0.5597\n",
      "Epoch 18/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 17.1337 - accuracy: 0.5597\n",
      "Epoch 19/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 17.0960 - accuracy: 0.5597\n",
      "Epoch 20/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 17.0581 - accuracy: 0.5597\n",
      "Epoch 21/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 17.0197 - accuracy: 0.5597\n",
      "Epoch 22/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 16.9814 - accuracy: 0.5597\n",
      "Epoch 23/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 16.9437 - accuracy: 0.5597\n",
      "Epoch 24/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 37us/sample - loss: 16.9054 - accuracy: 0.5597\n",
      "Epoch 25/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 16.8667 - accuracy: 0.5597\n",
      "Epoch 26/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 16.8277 - accuracy: 0.5597\n",
      "Epoch 27/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 16.7892 - accuracy: 0.5597\n",
      "Epoch 28/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 16.7502 - accuracy: 0.5597\n",
      "Epoch 29/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 16.7108 - accuracy: 0.5597\n",
      "Epoch 30/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 16.6721 - accuracy: 0.5597\n",
      "Epoch 31/150\n",
      "243/243 [==============================] - 0s 40us/sample - loss: 16.6324 - accuracy: 0.5597\n",
      "Epoch 32/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 16.5930 - accuracy: 0.5597\n",
      "Epoch 33/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 16.5532 - accuracy: 0.5597\n",
      "Epoch 34/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 16.5135 - accuracy: 0.5597\n",
      "Epoch 35/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 16.4738 - accuracy: 0.5597\n",
      "Epoch 36/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 16.4342 - accuracy: 0.5597\n",
      "Epoch 37/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 16.3942 - accuracy: 0.5597\n",
      "Epoch 38/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 16.3536 - accuracy: 0.5597\n",
      "Epoch 39/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 16.3135 - accuracy: 0.5597\n",
      "Epoch 40/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 16.2728 - accuracy: 0.5597\n",
      "Epoch 41/150\n",
      "243/243 [==============================] - 0s 62us/sample - loss: 16.2317 - accuracy: 0.5597\n",
      "Epoch 42/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 16.1912 - accuracy: 0.5597\n",
      "Epoch 43/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 16.1505 - accuracy: 0.5597\n",
      "Epoch 44/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 16.1092 - accuracy: 0.5597\n",
      "Epoch 45/150\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 16.0679 - accuracy: 0.5597\n",
      "Epoch 46/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 16.0267 - accuracy: 0.5597\n",
      "Epoch 47/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 15.9861 - accuracy: 0.5597\n",
      "Epoch 48/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 15.9438 - accuracy: 0.5597\n",
      "Epoch 49/150\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 15.9008 - accuracy: 0.5597\n",
      "Epoch 50/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 15.8588 - accuracy: 0.5597\n",
      "Epoch 51/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 15.8169 - accuracy: 0.5597\n",
      "Epoch 52/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 15.7748 - accuracy: 0.5597\n",
      "Epoch 53/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 15.7324 - accuracy: 0.5597\n",
      "Epoch 54/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 15.6900 - accuracy: 0.5597\n",
      "Epoch 55/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 15.6468 - accuracy: 0.5597\n",
      "Epoch 56/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 15.6033 - accuracy: 0.5597\n",
      "Epoch 57/150\n",
      "243/243 [==============================] - 0s 46us/sample - loss: 15.5606 - accuracy: 0.5597\n",
      "Epoch 58/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 15.5172 - accuracy: 0.5597\n",
      "Epoch 59/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 15.4747 - accuracy: 0.5597\n",
      "Epoch 60/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 15.4313 - accuracy: 0.5597\n",
      "Epoch 61/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 15.3875 - accuracy: 0.5597\n",
      "Epoch 62/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 15.3437 - accuracy: 0.5597\n",
      "Epoch 63/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 15.2992 - accuracy: 0.5597\n",
      "Epoch 64/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 15.2559 - accuracy: 0.5597\n",
      "Epoch 65/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 15.2119 - accuracy: 0.5597\n",
      "Epoch 66/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 15.1675 - accuracy: 0.5597\n",
      "Epoch 67/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 15.1230 - accuracy: 0.5597\n",
      "Epoch 68/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 15.0785 - accuracy: 0.5597\n",
      "Epoch 69/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 15.0344 - accuracy: 0.5597\n",
      "Epoch 70/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 14.9907 - accuracy: 0.5597\n",
      "Epoch 71/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 14.9458 - accuracy: 0.5597\n",
      "Epoch 72/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 14.9022 - accuracy: 0.5597\n",
      "Epoch 73/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 14.8588 - accuracy: 0.5597\n",
      "Epoch 74/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 14.8148 - accuracy: 0.5597\n",
      "Epoch 75/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 14.7705 - accuracy: 0.5597\n",
      "Epoch 76/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 14.7255 - accuracy: 0.5597\n",
      "Epoch 77/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 14.6811 - accuracy: 0.5597\n",
      "Epoch 78/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 14.6358 - accuracy: 0.5597\n",
      "Epoch 79/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 14.5907 - accuracy: 0.5597\n",
      "Epoch 80/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 14.5455 - accuracy: 0.5597\n",
      "Epoch 81/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 14.4998 - accuracy: 0.5597\n",
      "Epoch 82/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 14.4545 - accuracy: 0.5597\n",
      "Epoch 83/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 14.4092 - accuracy: 0.5597\n",
      "Epoch 84/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 14.3636 - accuracy: 0.5597\n",
      "Epoch 85/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 14.3178 - accuracy: 0.5597\n",
      "Epoch 86/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 14.2728 - accuracy: 0.5597\n",
      "Epoch 87/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 14.2276 - accuracy: 0.5597\n",
      "Epoch 88/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 14.1818 - accuracy: 0.5597\n",
      "Epoch 89/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 14.1366 - accuracy: 0.5597\n",
      "Epoch 90/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 14.0907 - accuracy: 0.5597\n",
      "Epoch 91/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 14.0466 - accuracy: 0.5597\n",
      "Epoch 92/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 14.0013 - accuracy: 0.5597\n",
      "Epoch 93/150\n",
      "243/243 [==============================] - 0s 57us/sample - loss: 13.9548 - accuracy: 0.5597\n",
      "Epoch 94/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 13.9085 - accuracy: 0.5597\n",
      "Epoch 95/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 13.8612 - accuracy: 0.5597\n",
      "Epoch 96/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 13.8144 - accuracy: 0.5597\n",
      "Epoch 97/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 13.7687 - accuracy: 0.5597\n",
      "Epoch 98/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 13.7231 - accuracy: 0.5597\n",
      "Epoch 99/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 13.6767 - accuracy: 0.5597\n",
      "Epoch 100/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 13.6300 - accuracy: 0.5597\n",
      "Epoch 101/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 49us/sample - loss: 13.5827 - accuracy: 0.5597\n",
      "Epoch 102/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 13.5351 - accuracy: 0.5597\n",
      "Epoch 103/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 13.4884 - accuracy: 0.5597\n",
      "Epoch 104/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 13.4402 - accuracy: 0.5597\n",
      "Epoch 105/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 13.3924 - accuracy: 0.5597\n",
      "Epoch 106/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 13.3454 - accuracy: 0.5597\n",
      "Epoch 107/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 13.2983 - accuracy: 0.5597\n",
      "Epoch 108/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 13.2512 - accuracy: 0.5597\n",
      "Epoch 109/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 13.2043 - accuracy: 0.5597\n",
      "Epoch 110/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 13.1570 - accuracy: 0.5597\n",
      "Epoch 111/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 13.1089 - accuracy: 0.5597\n",
      "Epoch 112/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 13.0615 - accuracy: 0.5597\n",
      "Epoch 113/150\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 13.0135 - accuracy: 0.5597\n",
      "Epoch 114/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 12.9655 - accuracy: 0.5597\n",
      "Epoch 115/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 12.9183 - accuracy: 0.5597\n",
      "Epoch 116/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 12.8709 - accuracy: 0.5597\n",
      "Epoch 117/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 12.8237 - accuracy: 0.5597\n",
      "Epoch 118/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 12.7760 - accuracy: 0.5597\n",
      "Epoch 119/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 12.7284 - accuracy: 0.5597\n",
      "Epoch 120/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 12.6794 - accuracy: 0.5597\n",
      "Epoch 121/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 12.6311 - accuracy: 0.5597\n",
      "Epoch 122/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 12.5834 - accuracy: 0.5597\n",
      "Epoch 123/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 12.5358 - accuracy: 0.5597\n",
      "Epoch 124/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 12.4875 - accuracy: 0.5597\n",
      "Epoch 125/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 12.4388 - accuracy: 0.5597\n",
      "Epoch 126/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 12.3902 - accuracy: 0.5597\n",
      "Epoch 127/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 12.3422 - accuracy: 0.5597\n",
      "Epoch 128/150\n",
      "243/243 [==============================] - 0s 57us/sample - loss: 12.2932 - accuracy: 0.5597\n",
      "Epoch 129/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 12.2444 - accuracy: 0.5597\n",
      "Epoch 130/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 12.1959 - accuracy: 0.5597\n",
      "Epoch 131/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 12.1474 - accuracy: 0.5597\n",
      "Epoch 132/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 12.0994 - accuracy: 0.5597\n",
      "Epoch 133/150\n",
      "243/243 [==============================] - 0s 57us/sample - loss: 12.0514 - accuracy: 0.5597\n",
      "Epoch 134/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 12.0033 - accuracy: 0.5597\n",
      "Epoch 135/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 11.9542 - accuracy: 0.5597\n",
      "Epoch 136/150\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 11.9061 - accuracy: 0.5597\n",
      "Epoch 137/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 11.8581 - accuracy: 0.5597\n",
      "Epoch 138/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 11.8094 - accuracy: 0.5597\n",
      "Epoch 139/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 11.7606 - accuracy: 0.5597\n",
      "Epoch 140/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 11.7115 - accuracy: 0.5597\n",
      "Epoch 141/150\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 11.6627 - accuracy: 0.5597\n",
      "Epoch 142/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 11.6148 - accuracy: 0.5597\n",
      "Epoch 143/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 11.5669 - accuracy: 0.5597\n",
      "Epoch 144/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 11.5187 - accuracy: 0.5597\n",
      "Epoch 145/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 11.4688 - accuracy: 0.5597\n",
      "Epoch 146/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 11.4195 - accuracy: 0.5597\n",
      "Epoch 147/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 11.3692 - accuracy: 0.5597\n",
      "Epoch 148/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 11.3202 - accuracy: 0.5597\n",
      "Epoch 149/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 11.2720 - accuracy: 0.5597\n",
      "Epoch 150/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 11.2224 - accuracy: 0.5597\n",
      "60/60 [==============================] - 0s 990us/sample - loss: 13.5675 - accuracy: 0.4833\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 5.9649 - accuracy: 0.5267\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.9454 - accuracy: 0.5267\n",
      "Epoch 3/150\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 5.9259 - accuracy: 0.5267\n",
      "Epoch 4/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.9063 - accuracy: 0.5267\n",
      "Epoch 5/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.8869 - accuracy: 0.5267\n",
      "Epoch 6/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.8674 - accuracy: 0.5267\n",
      "Epoch 7/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.8473 - accuracy: 0.5267\n",
      "Epoch 8/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.8272 - accuracy: 0.5267\n",
      "Epoch 9/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.8067 - accuracy: 0.5267\n",
      "Epoch 10/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 5.7865 - accuracy: 0.5267\n",
      "Epoch 11/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.7658 - accuracy: 0.5267\n",
      "Epoch 12/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.7453 - accuracy: 0.5267\n",
      "Epoch 13/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 5.7244 - accuracy: 0.5267\n",
      "Epoch 14/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.7034 - accuracy: 0.5267\n",
      "Epoch 15/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.6820 - accuracy: 0.5267\n",
      "Epoch 16/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.6608 - accuracy: 0.5267\n",
      "Epoch 17/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.6393 - accuracy: 0.5267\n",
      "Epoch 18/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.6180 - accuracy: 0.5267\n",
      "Epoch 19/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 5.5960 - accuracy: 0.5267\n",
      "Epoch 20/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 5.5742 - accuracy: 0.5267\n",
      "Epoch 21/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 5.5526 - accuracy: 0.5267\n",
      "Epoch 22/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.5313 - accuracy: 0.5267\n",
      "Epoch 23/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.5093 - accuracy: 0.5267\n",
      "Epoch 24/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.4877 - accuracy: 0.5267\n",
      "Epoch 25/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 5.4658 - accuracy: 0.5267\n",
      "Epoch 26/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 37us/sample - loss: 5.4436 - accuracy: 0.5267\n",
      "Epoch 27/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 5.4216 - accuracy: 0.5267\n",
      "Epoch 28/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 5.3998 - accuracy: 0.5267\n",
      "Epoch 29/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 5.3776 - accuracy: 0.5267\n",
      "Epoch 30/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.3558 - accuracy: 0.5267\n",
      "Epoch 31/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 5.3333 - accuracy: 0.5267\n",
      "Epoch 32/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.3104 - accuracy: 0.5267\n",
      "Epoch 33/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.2877 - accuracy: 0.5267\n",
      "Epoch 34/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 5.2653 - accuracy: 0.5267\n",
      "Epoch 35/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.2421 - accuracy: 0.5267\n",
      "Epoch 36/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 5.2195 - accuracy: 0.5267\n",
      "Epoch 37/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.1964 - accuracy: 0.5267\n",
      "Epoch 38/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.1730 - accuracy: 0.5267\n",
      "Epoch 39/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 5.1499 - accuracy: 0.5267\n",
      "Epoch 40/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 5.1265 - accuracy: 0.5267\n",
      "Epoch 41/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.1039 - accuracy: 0.5267\n",
      "Epoch 42/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.0807 - accuracy: 0.5267\n",
      "Epoch 43/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.0572 - accuracy: 0.5267\n",
      "Epoch 44/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 5.0340 - accuracy: 0.5267\n",
      "Epoch 45/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 5.0103 - accuracy: 0.5267\n",
      "Epoch 46/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.9867 - accuracy: 0.5267\n",
      "Epoch 47/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.9636 - accuracy: 0.5267\n",
      "Epoch 48/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.9398 - accuracy: 0.5267\n",
      "Epoch 49/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.9160 - accuracy: 0.5267\n",
      "Epoch 50/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.8925 - accuracy: 0.5267\n",
      "Epoch 51/150\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 4.8688 - accuracy: 0.5267\n",
      "Epoch 52/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.8446 - accuracy: 0.5267\n",
      "Epoch 53/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.8205 - accuracy: 0.5267\n",
      "Epoch 54/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.7963 - accuracy: 0.5267\n",
      "Epoch 55/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.7722 - accuracy: 0.5267\n",
      "Epoch 56/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.7478 - accuracy: 0.5267\n",
      "Epoch 57/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.7235 - accuracy: 0.5267\n",
      "Epoch 58/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.6989 - accuracy: 0.5267\n",
      "Epoch 59/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 4.6741 - accuracy: 0.5267\n",
      "Epoch 60/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 4.6494 - accuracy: 0.5267\n",
      "Epoch 61/150\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 4.6245 - accuracy: 0.5267\n",
      "Epoch 62/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.5997 - accuracy: 0.5267\n",
      "Epoch 63/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 4.5750 - accuracy: 0.5267\n",
      "Epoch 64/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 4.5502 - accuracy: 0.5267\n",
      "Epoch 65/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.5254 - accuracy: 0.5267\n",
      "Epoch 66/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.5005 - accuracy: 0.5267\n",
      "Epoch 67/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 4.4754 - accuracy: 0.5267\n",
      "Epoch 68/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.4512 - accuracy: 0.5267\n",
      "Epoch 69/150\n",
      "243/243 [==============================] - 0s 74us/sample - loss: 4.4259 - accuracy: 0.5267\n",
      "Epoch 70/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 4.4004 - accuracy: 0.5267\n",
      "Epoch 71/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 4.3754 - accuracy: 0.5267\n",
      "Epoch 72/150\n",
      "243/243 [==============================] - 0s 78us/sample - loss: 4.3500 - accuracy: 0.5267\n",
      "Epoch 73/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 4.3245 - accuracy: 0.5267\n",
      "Epoch 74/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.2993 - accuracy: 0.5267\n",
      "Epoch 75/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.2737 - accuracy: 0.5267\n",
      "Epoch 76/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 4.2479 - accuracy: 0.5267\n",
      "Epoch 77/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.2217 - accuracy: 0.5267\n",
      "Epoch 78/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.1963 - accuracy: 0.5267\n",
      "Epoch 79/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.1705 - accuracy: 0.5267\n",
      "Epoch 80/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.1447 - accuracy: 0.5267\n",
      "Epoch 81/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 4.1182 - accuracy: 0.5267\n",
      "Epoch 82/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 4.0920 - accuracy: 0.5267\n",
      "Epoch 83/150\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 4.0663 - accuracy: 0.5267\n",
      "Epoch 84/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 4.0400 - accuracy: 0.5267\n",
      "Epoch 85/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.0139 - accuracy: 0.5267\n",
      "Epoch 86/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.9877 - accuracy: 0.5267\n",
      "Epoch 87/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 3.9617 - accuracy: 0.5267\n",
      "Epoch 88/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.9353 - accuracy: 0.5267\n",
      "Epoch 89/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.9094 - accuracy: 0.5267\n",
      "Epoch 90/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.8830 - accuracy: 0.5267\n",
      "Epoch 91/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.8568 - accuracy: 0.5267\n",
      "Epoch 92/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.8306 - accuracy: 0.5267\n",
      "Epoch 93/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.8039 - accuracy: 0.5267\n",
      "Epoch 94/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.7774 - accuracy: 0.5267\n",
      "Epoch 95/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.7511 - accuracy: 0.5267\n",
      "Epoch 96/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.7243 - accuracy: 0.5267\n",
      "Epoch 97/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.6976 - accuracy: 0.5267\n",
      "Epoch 98/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.6708 - accuracy: 0.5267\n",
      "Epoch 99/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.6434 - accuracy: 0.5267\n",
      "Epoch 100/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.6167 - accuracy: 0.5267\n",
      "Epoch 101/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.5899 - accuracy: 0.5267\n",
      "Epoch 102/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.5630 - accuracy: 0.5267\n",
      "Epoch 103/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.5357 - accuracy: 0.5267\n",
      "Epoch 104/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 41us/sample - loss: 3.5085 - accuracy: 0.5267\n",
      "Epoch 105/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.4816 - accuracy: 0.5267\n",
      "Epoch 106/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.4542 - accuracy: 0.5267\n",
      "Epoch 107/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.4273 - accuracy: 0.5267\n",
      "Epoch 108/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.3997 - accuracy: 0.5267\n",
      "Epoch 109/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.3725 - accuracy: 0.5267\n",
      "Epoch 110/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.3453 - accuracy: 0.5267\n",
      "Epoch 111/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.3180 - accuracy: 0.5267\n",
      "Epoch 112/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.2901 - accuracy: 0.5267\n",
      "Epoch 113/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 3.2627 - accuracy: 0.5267\n",
      "Epoch 114/150\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 3.2354 - accuracy: 0.5267\n",
      "Epoch 115/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.2076 - accuracy: 0.5267\n",
      "Epoch 116/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.1798 - accuracy: 0.5267\n",
      "Epoch 117/150\n",
      "243/243 [==============================] - 0s 50us/sample - loss: 3.1524 - accuracy: 0.5267\n",
      "Epoch 118/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 3.1247 - accuracy: 0.5267\n",
      "Epoch 119/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.0968 - accuracy: 0.5267\n",
      "Epoch 120/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.0694 - accuracy: 0.5267\n",
      "Epoch 121/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.0421 - accuracy: 0.5267\n",
      "Epoch 122/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.0144 - accuracy: 0.5267\n",
      "Epoch 123/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.9861 - accuracy: 0.5267\n",
      "Epoch 124/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.9579 - accuracy: 0.5267\n",
      "Epoch 125/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.9300 - accuracy: 0.5267\n",
      "Epoch 126/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.9018 - accuracy: 0.5267\n",
      "Epoch 127/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 2.8735 - accuracy: 0.5267\n",
      "Epoch 128/150\n",
      "243/243 [==============================] - 0s 57us/sample - loss: 2.8453 - accuracy: 0.5267\n",
      "Epoch 129/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 2.8175 - accuracy: 0.5267\n",
      "Epoch 130/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.7892 - accuracy: 0.5267\n",
      "Epoch 131/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.7611 - accuracy: 0.5267\n",
      "Epoch 132/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.7330 - accuracy: 0.5267\n",
      "Epoch 133/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.7047 - accuracy: 0.5267\n",
      "Epoch 134/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 2.6762 - accuracy: 0.5267\n",
      "Epoch 135/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.6471 - accuracy: 0.5267\n",
      "Epoch 136/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 2.6185 - accuracy: 0.5267\n",
      "Epoch 137/150\n",
      "243/243 [==============================] - 0s 78us/sample - loss: 2.5901 - accuracy: 0.5267\n",
      "Epoch 138/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 2.5615 - accuracy: 0.5267\n",
      "Epoch 139/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 2.5327 - accuracy: 0.5267\n",
      "Epoch 140/150\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 2.5048 - accuracy: 0.5267\n",
      "Epoch 141/150\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 2.4765 - accuracy: 0.5267\n",
      "Epoch 142/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.4482 - accuracy: 0.5267\n",
      "Epoch 143/150\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 2.4200 - accuracy: 0.5267\n",
      "Epoch 144/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 2.3917 - accuracy: 0.5267\n",
      "Epoch 145/150\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 2.3627 - accuracy: 0.5267\n",
      "Epoch 146/150\n",
      "243/243 [==============================] - 0s 62us/sample - loss: 2.3342 - accuracy: 0.5267\n",
      "Epoch 147/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 2.3056 - accuracy: 0.5267\n",
      "Epoch 148/150\n",
      "243/243 [==============================] - 0s 62us/sample - loss: 2.2777 - accuracy: 0.5267\n",
      "Epoch 149/150\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 2.2493 - accuracy: 0.5267\n",
      "Epoch 150/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 2.2211 - accuracy: 0.5267\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 1.6698 - accuracy: 0.6167\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 2ms/sample - loss: 7.1771 - accuracy: 0.5496\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 1.9846 - accuracy: 0.4298\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 1.2945 - accuracy: 0.4215\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 1.0357 - accuracy: 0.4587\n",
      "Epoch 5/150\n",
      "242/242 [==============================] - 0s 70us/sample - loss: 0.8939 - accuracy: 0.4835\n",
      "Epoch 6/150\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 0.8242 - accuracy: 0.5248\n",
      "Epoch 7/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.7940 - accuracy: 0.5579\n",
      "Epoch 8/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.7432 - accuracy: 0.5537\n",
      "Epoch 9/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.7355 - accuracy: 0.6033\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.7028 - accuracy: 0.5082\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 1.7329 - accuracy: 0.5331\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.8979 - accuracy: 0.5455\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.8059 - accuracy: 0.5620\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.7594 - accuracy: 0.5950\n",
      "Epoch 5/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.7289 - accuracy: 0.6116\n",
      "Epoch 6/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.7102 - accuracy: 0.6074\n",
      "Epoch 7/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.7011 - accuracy: 0.5950\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.5172 - accuracy: 0.7705\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 11.8907 - accuracy: 0.5620\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.8709 - accuracy: 0.5620\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.7670 - accuracy: 0.6033\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6778 - accuracy: 0.6364\n",
      "Epoch 5/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6381 - accuracy: 0.6612\n",
      "Epoch 6/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6018 - accuracy: 0.7025\n",
      "Epoch 7/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5954 - accuracy: 0.7107\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.9216 - accuracy: 0.4754\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 24.4945 - accuracy: 0.5597\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 14.5206 - accuracy: 0.5597\n",
      "Epoch 3/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 37us/sample - loss: 10.0546 - accuracy: 0.5597\n",
      "Epoch 4/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 7.1094 - accuracy: 0.5597\n",
      "Epoch 5/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 4.6113 - accuracy: 0.5597\n",
      "Epoch 6/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.7681 - accuracy: 0.5350\n",
      "Epoch 7/150\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 2.1207 - accuracy: 0.4198\n",
      "Epoch 8/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.9178 - accuracy: 0.4074\n",
      "Epoch 9/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 1.7753 - accuracy: 0.4156\n",
      "Epoch 10/150\n",
      "243/243 [==============================] - 0s 36us/sample - loss: 1.6549 - accuracy: 0.4156\n",
      "Epoch 11/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 1.5513 - accuracy: 0.4156\n",
      "Epoch 12/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 1.4657 - accuracy: 0.4074\n",
      "Epoch 13/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 1.3886 - accuracy: 0.4198\n",
      "Epoch 14/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 1.3144 - accuracy: 0.4156\n",
      "Epoch 15/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 1.2490 - accuracy: 0.4198\n",
      "Epoch 16/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 1.1803 - accuracy: 0.4444\n",
      "Epoch 17/150\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 1.1363 - accuracy: 0.4444\n",
      "Epoch 18/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 1.0691 - accuracy: 0.4486\n",
      "Epoch 19/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 1.0219 - accuracy: 0.4691\n",
      "Epoch 20/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.9756 - accuracy: 0.4856\n",
      "Epoch 21/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.9346 - accuracy: 0.4979\n",
      "Epoch 22/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.9026 - accuracy: 0.5021\n",
      "Epoch 23/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.8765 - accuracy: 0.5062\n",
      "Epoch 24/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.8493 - accuracy: 0.5514\n",
      "Epoch 25/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.8228 - accuracy: 0.5432\n",
      "Epoch 26/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.7995 - accuracy: 0.5844\n",
      "Epoch 27/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.7806 - accuracy: 0.6008\n",
      "Epoch 28/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.7698 - accuracy: 0.6008\n",
      "Epoch 29/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.7553 - accuracy: 0.5967\n",
      "Epoch 30/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.7423 - accuracy: 0.5885\n",
      "Epoch 31/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.7390 - accuracy: 0.6296\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 1.0232 - accuracy: 0.4333\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 3.4106 - accuracy: 0.4650\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 2.0604 - accuracy: 0.4321\n",
      "Epoch 3/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 1.8451 - accuracy: 0.4444\n",
      "Epoch 4/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 1.7123 - accuracy: 0.4774\n",
      "Epoch 5/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.6179 - accuracy: 0.4650\n",
      "Epoch 6/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 1.5154 - accuracy: 0.4650\n",
      "Epoch 7/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 1.4459 - accuracy: 0.4774\n",
      "Epoch 8/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 1.3784 - accuracy: 0.4897\n",
      "Epoch 9/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 1.3272 - accuracy: 0.4856\n",
      "Epoch 10/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 1.2731 - accuracy: 0.4897\n",
      "Epoch 11/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 1.2356 - accuracy: 0.4979\n",
      "Epoch 12/150\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 1.2031 - accuracy: 0.4979\n",
      "Epoch 13/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.1742 - accuracy: 0.5185\n",
      "Epoch 14/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 1.1497 - accuracy: 0.5309\n",
      "Epoch 15/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 1.1263 - accuracy: 0.5267\n",
      "Epoch 16/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.1001 - accuracy: 0.5267\n",
      "Epoch 17/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 1.0730 - accuracy: 0.5021\n",
      "Epoch 18/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.0634 - accuracy: 0.5350\n",
      "60/60 [==============================] - 0s 997us/sample - loss: 1.2255 - accuracy: 0.5167\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4229 - accuracy: 0.5826\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4191 - accuracy: 0.5868\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.4123 - accuracy: 0.5902\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4752 - accuracy: 0.5248\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4237 - accuracy: 0.5868\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 0.4219 - accuracy: 0.5785\n",
      "61/61 [==============================] - 0s 997us/sample - loss: 0.3638 - accuracy: 0.6557\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.5515 - accuracy: 0.4403\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.4767 - accuracy: 0.5267\n",
      "Epoch 3/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.4597 - accuracy: 0.6214\n",
      "Epoch 4/150\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.4501 - accuracy: 0.6461\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.4361 - accuracy: 0.6667\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.4757 - accuracy: 0.5267\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.4305 - accuracy: 0.6091\n",
      "Epoch 3/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.4252 - accuracy: 0.5761\n",
      "60/60 [==============================] - 0s 997us/sample - loss: 0.4331 - accuracy: 0.6000\n",
      "Loss: mean_absolute_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.5467 - accuracy: 0.4504\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4610 - accuracy: 0.5579\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4080 - accuracy: 0.6405\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.3782 - accuracy: 0.6736\n",
      "Epoch 5/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.3651 - accuracy: 0.6736\n",
      "Epoch 6/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.3610 - accuracy: 0.6860\n",
      "61/61 [==============================] - 0s 965us/sample - loss: 0.3045 - accuracy: 0.7213\n",
      "Loss: mean_absolute_error; optimimer: nadam\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.5248 - accuracy: 0.4752\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.5248 - accuracy: 0.4752\n",
      "61/61 [==============================] - 0s 948us/sample - loss: 0.6230 - accuracy: 0.3770\n",
      "Loss: mean_absolute_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.5614 - accuracy: 0.4380\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.3958 - accuracy: 0.6033\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.3664 - accuracy: 0.6322\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.3334 - accuracy: 0.6653\n",
      "Epoch 5/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.3282 - accuracy: 0.6694\n",
      "61/61 [==============================] - 0s 932us/sample - loss: 0.4895 - accuracy: 0.5082\n",
      "Loss: mean_absolute_error; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 1s 2ms/sample - loss: 0.5596 - accuracy: 0.4280\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.4297 - accuracy: 0.5967\n",
      "Epoch 3/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.3813 - accuracy: 0.6502\n",
      "Epoch 4/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.3523 - accuracy: 0.6749\n",
      "Epoch 5/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.3448 - accuracy: 0.6708\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.3818 - accuracy: 0.6167\n",
      "Loss: mean_absolute_error; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 1s 3ms/sample - loss: 0.5273 - accuracy: 0.4733\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "60/60 [==============================] - 0s 964us/sample - loss: 0.6167 - accuracy: 0.3833\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 900us/sample - loss: 0.5501 - accuracy: 0.4504\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5498 - accuracy: 0.4504\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.5253 - accuracy: 0.4754\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 931us/sample - loss: 0.5248 - accuracy: 0.4752\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5248 - accuracy: 0.4752\n",
      "61/61 [==============================] - 0s 987us/sample - loss: 0.6230 - accuracy: 0.3770\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 882us/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "61/61 [==============================] - 0s 916us/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 882us/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "60/60 [==============================] - 0s 930us/sample - loss: 0.5167 - accuracy: 0.4833\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 870us/sample - loss: 0.4733 - accuracy: 0.5267\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4733 - accuracy: 0.5267\n",
      "60/60 [==============================] - 0s 951us/sample - loss: 0.3833 - accuracy: 0.6167\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "61/61 [==============================] - 0s 956us/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4236 - accuracy: 0.5702\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4233 - accuracy: 0.5702\n",
      "61/61 [==============================] - 0s 948us/sample - loss: 0.3862 - accuracy: 0.6557\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 997us/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 997us/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.4668 - accuracy: 0.5597\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4666 - accuracy: 0.5597\n",
      "60/60 [==============================] - 0s 927us/sample - loss: 0.5120 - accuracy: 0.4833\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "60/60 [==============================] - 0s 980us/sample - loss: 0.6167 - accuracy: 0.3833\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.5497 - accuracy: 0.4504\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.4480 - accuracy: 0.5661\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.3937 - accuracy: 0.6074\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.3891 - accuracy: 0.6240\n",
      "61/61 [==============================] - 0s 932us/sample - loss: 0.3639 - accuracy: 0.6393\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 927us/sample - loss: 0.4751 - accuracy: 0.5248\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.4419 - accuracy: 0.5455\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4061 - accuracy: 0.6116\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4025 - accuracy: 0.5992\n",
      "61/61 [==============================] - 0s 916us/sample - loss: 0.3709 - accuracy: 0.6230\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 944us/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "61/61 [==============================] - 0s 981us/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 902us/sample - loss: 0.4205 - accuracy: 0.5720\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.3771 - accuracy: 0.6461\n",
      "Epoch 3/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.3760 - accuracy: 0.6337\n",
      "60/60 [==============================] - 0s 985us/sample - loss: 0.4849 - accuracy: 0.5167\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 960us/sample - loss: 0.3627 - accuracy: 0.6502\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.3623 - accuracy: 0.6502\n",
      "60/60 [==============================] - 0s 947us/sample - loss: 0.3828 - accuracy: 0.6333\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4504 - accuracy: 0.5496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "61/61 [==============================] - 0s 932us/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.5248 - accuracy: 0.4752\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5248 - accuracy: 0.4752\n",
      "61/61 [==============================] - 0s 981us/sample - loss: 0.6230 - accuracy: 0.3770\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.5433 - accuracy: 0.4545\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4340 - accuracy: 0.5000\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4314 - accuracy: 0.5496\n",
      "61/61 [==============================] - 0s 932us/sample - loss: 0.5151 - accuracy: 0.4754\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.5322 - accuracy: 0.4486\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.3811 - accuracy: 0.4938\n",
      "Epoch 3/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.3401 - accuracy: 0.5514\n",
      "Epoch 4/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.4056 - accuracy: 0.5720\n",
      "60/60 [==============================] - 0s 947us/sample - loss: 0.4342 - accuracy: 0.5000\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 1s 2ms/sample - loss: 0.4733 - accuracy: 0.5267\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.4733 - accuracy: 0.5267\n",
      "60/60 [==============================] - 0s 931us/sample - loss: 0.3833 - accuracy: 0.6167\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.5041 - accuracy: 0.4752\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4475 - accuracy: 0.5041\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.3900 - accuracy: 0.5413\n",
      "Epoch 5/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.5059 - accuracy: 0.4091\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.3910 - accuracy: 0.5246\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.4116 - accuracy: 0.4669\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.2914 - accuracy: 0.5207\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.2322 - accuracy: 0.6240\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 0.2579 - accuracy: 0.6198\n",
      "61/61 [==============================] - 0s 932us/sample - loss: 0.2416 - accuracy: 0.6393\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.4108 - accuracy: 0.4959\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 0.3061 - accuracy: 0.5165\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.2566 - accuracy: 0.5868\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.2485 - accuracy: 0.6074\n",
      "61/61 [==============================] - 0s 932us/sample - loss: 0.2737 - accuracy: 0.5082\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 1s 2ms/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "60/60 [==============================] - 0s 931us/sample - loss: 0.5167 - accuracy: 0.4833\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 1s 2ms/sample - loss: 0.5265 - accuracy: 0.4733\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.3538 - accuracy: 0.5638\n",
      "Epoch 3/150\n",
      "243/243 [==============================] - 0s 57us/sample - loss: 0.2914 - accuracy: 0.6049\n",
      "Epoch 4/150\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.3005 - accuracy: 0.6132\n",
      "60/60 [==============================] - 0s 914us/sample - loss: 0.1989 - accuracy: 0.6833\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 853us/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "61/61 [==============================] - 0s 932us/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 870us/sample - loss: 0.5237 - accuracy: 0.4752\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5210 - accuracy: 0.4752\n",
      "61/61 [==============================] - 0s 981us/sample - loss: 0.6170 - accuracy: 0.3770\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 899us/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 886us/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "60/60 [==============================] - 0s 947us/sample - loss: 0.5167 - accuracy: 0.4833\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 858us/sample - loss: 0.4733 - accuracy: 0.5267\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4733 - accuracy: 0.5267\n",
      "60/60 [==============================] - 0s 931us/sample - loss: 0.3833 - accuracy: 0.6167\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 991us/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "61/61 [==============================] - 0s 932us/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 977us/sample - loss: 0.4561 - accuracy: 0.4752\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4556 - accuracy: 0.4752\n",
      "61/61 [==============================] - 0s 924us/sample - loss: 0.5306 - accuracy: 0.3770\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "61/61 [==============================] - 0s 932us/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.5597 - accuracy: 0.4403\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.5597 - accuracy: 0.4403\n",
      "60/60 [==============================] - 0s 964us/sample - loss: 0.4833 - accuracy: 0.5167\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 985us/sample - loss: 0.4733 - accuracy: 0.5267\n",
      "Epoch 2/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4733 - accuracy: 0.5267\n",
      "60/60 [==============================] - 0s 947us/sample - loss: 0.3833 - accuracy: 0.6167\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 933us/sample - loss: 0.3181 - accuracy: 0.5785\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.2778 - accuracy: 0.6322\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.2593 - accuracy: 0.6198\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.2508 - accuracy: 0.6281\n",
      "61/61 [==============================] - 0s 997us/sample - loss: 0.1654 - accuracy: 0.8033\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.2997 - accuracy: 0.5455\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.2403 - accuracy: 0.6033\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.2369 - accuracy: 0.5992\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.2094 - accuracy: 0.6885\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/150\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.5071 - accuracy: 0.4050\n",
      "Epoch 2/150\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.3392 - accuracy: 0.5372\n",
      "Epoch 3/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.3205 - accuracy: 0.5248\n",
      "Epoch 4/150\n",
      "242/242 [==============================] - 0s 53us/sample - loss: 0.2952 - accuracy: 0.5620\n",
      "Epoch 5/150\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.2759 - accuracy: 0.6074\n",
      "Epoch 6/150\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.2748 - accuracy: 0.5702\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.2764 - accuracy: 0.4918\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 967us/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "60/60 [==============================] - 0s 931us/sample - loss: 0.5167 - accuracy: 0.4833\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/150\n",
      "243/243 [==============================] - 0s 928us/sample - loss: 0.5081 - accuracy: 0.4691\n",
      "Epoch 2/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.3867 - accuracy: 0.4938\n",
      "Epoch 3/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.3310 - accuracy: 0.5185\n",
      "Epoch 4/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.3115 - accuracy: 0.5679\n",
      "Epoch 5/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.2987 - accuracy: 0.5844\n",
      "Epoch 6/150\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.2843 - accuracy: 0.5885\n",
      "Epoch 7/150\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.2821 - accuracy: 0.6008\n",
      "60/60 [==============================] - 0s 931us/sample - loss: 0.2169 - accuracy: 0.7167\n",
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.7840 - accuracy: 0.6074\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6794 - accuracy: 0.6074\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6625 - accuracy: 0.6198\n",
      "Epoch 4/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.6594 - accuracy: 0.6157\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.5750 - accuracy: 0.7049\n",
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 2.6192 - accuracy: 0.5041\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.0929 - accuracy: 0.5826\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.8082 - accuracy: 0.6198\n",
      "Epoch 4/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.8010 - accuracy: 0.6033\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.6651 - accuracy: 0.6557\n",
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 2.0891 - accuracy: 0.4421\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.0909 - accuracy: 0.4339\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.8577 - accuracy: 0.4256\n",
      "Epoch 4/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.7242 - accuracy: 0.4421\n",
      "Epoch 5/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6463 - accuracy: 0.6364\n",
      "Epoch 6/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6073 - accuracy: 0.6818\n",
      "Epoch 7/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.5969 - accuracy: 0.6860\n",
      "Epoch 8/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.5954 - accuracy: 0.6818\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.7244 - accuracy: 0.4754\n",
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 6.3956 - accuracy: 0.3868\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 4.1047 - accuracy: 0.4444\n",
      "Epoch 3/200\n",
      "243/243 [==============================] - 0s 58us/sample - loss: 2.0737 - accuracy: 0.4033\n",
      "Epoch 4/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.9064 - accuracy: 0.4691\n",
      "Epoch 5/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.2578 - accuracy: 0.5062\n",
      "Epoch 6/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.0972 - accuracy: 0.4486\n",
      "Epoch 7/200\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.8948 - accuracy: 0.5062\n",
      "Epoch 8/200\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.7802 - accuracy: 0.5267\n",
      "Epoch 9/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.7955 - accuracy: 0.4897\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.8200 - accuracy: 0.5500\n",
      "Loss: binary_crossentropy; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 13.7370 - accuracy: 0.5267\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 38us/sample - loss: 3.7592 - accuracy: 0.4897\n",
      "Epoch 3/200\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 2.1559 - accuracy: 0.4774\n",
      "Epoch 4/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.3799 - accuracy: 0.5391\n",
      "Epoch 5/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.0082 - accuracy: 0.5350\n",
      "Epoch 6/200\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.8384 - accuracy: 0.6008\n",
      "Epoch 7/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.8138 - accuracy: 0.6049\n",
      "Epoch 8/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.7467 - accuracy: 0.5967\n",
      "Epoch 9/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.7080 - accuracy: 0.6132\n",
      "Epoch 10/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.6738 - accuracy: 0.6461\n",
      "Epoch 11/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.6828 - accuracy: 0.6337\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.6074 - accuracy: 0.6833\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 1s 3ms/sample - loss: 8.0855 - accuracy: 0.5496\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 1.7267 - accuracy: 0.4669\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.9455 - accuracy: 0.4091\n",
      "Epoch 4/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 45us/sample - loss: 0.8885 - accuracy: 0.4835\n",
      "Epoch 5/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.7771 - accuracy: 0.5744\n",
      "Epoch 6/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.7258 - accuracy: 0.5331\n",
      "Epoch 7/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.7924 - accuracy: 0.5496\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.6537 - accuracy: 0.5902\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 1s 3ms/sample - loss: 1.9212 - accuracy: 0.5207\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.7777 - accuracy: 0.5083\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6993 - accuracy: 0.5496\n",
      "Epoch 4/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.7022 - accuracy: 0.5455\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.7541 - accuracy: 0.6066\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 1s 3ms/sample - loss: 1.4101 - accuracy: 0.5620\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.6901 - accuracy: 0.6240\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6439 - accuracy: 0.6157\n",
      "Epoch 4/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.5897 - accuracy: 0.7066\n",
      "Epoch 5/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.5753 - accuracy: 0.7107\n",
      "Epoch 6/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.6123 - accuracy: 0.6818\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.7042 - accuracy: 0.6066\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 1s 3ms/sample - loss: 1.6231 - accuracy: 0.5473\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.1431 - accuracy: 0.5597\n",
      "Epoch 3/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.9183 - accuracy: 0.5350\n",
      "Epoch 4/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.8429 - accuracy: 0.5185\n",
      "Epoch 5/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.7424 - accuracy: 0.5473\n",
      "Epoch 6/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.7334 - accuracy: 0.5597\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.6992 - accuracy: 0.6000\n",
      "Loss: binary_crossentropy; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 1s 3ms/sample - loss: 4.4141 - accuracy: 0.5267\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 1.3475 - accuracy: 0.5309\n",
      "Epoch 3/200\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.7035 - accuracy: 0.5638\n",
      "Epoch 4/200\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 0.6740 - accuracy: 0.5597\n",
      "Epoch 5/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.6605 - accuracy: 0.6132\n",
      "Epoch 6/200\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.6522 - accuracy: 0.5844\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.5727 - accuracy: 0.7000\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 38.6872 - accuracy: 0.4752\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6971 - accuracy: 0.5248\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6947 - accuracy: 0.5289\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.6922 - accuracy: 0.5246\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 21.0071 - accuracy: 0.4587\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6932 - accuracy: 0.5248\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6931 - accuracy: 0.5248\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.6927 - accuracy: 0.6230\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 5.0524 - accuracy: 0.5455\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.6886 - accuracy: 0.5620\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6873 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.7157 - accuracy: 0.4754\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 4.1129 - accuracy: 0.5679\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.7318 - accuracy: 0.5597\n",
      "Epoch 3/200\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.6891 - accuracy: 0.5597\n",
      "Epoch 4/200\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.6681 - accuracy: 0.5597\n",
      "Epoch 5/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.6633 - accuracy: 0.5597\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.7133 - accuracy: 0.4833\n",
      "Loss: binary_crossentropy; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.8165 - accuracy: 0.5144\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 36us/sample - loss: 0.6756 - accuracy: 0.5226\n",
      "Epoch 3/200\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.6777 - accuracy: 0.5350\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.6840 - accuracy: 0.6333\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 5.1006 - accuracy: 0.5496\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 5.0878 - accuracy: 0.5496\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 5.0749 - accuracy: 0.5496\n",
      "Epoch 4/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 5.0621 - accuracy: 0.5496\n",
      "Epoch 5/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 5.0490 - accuracy: 0.5496\n",
      "Epoch 6/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 5.0356 - accuracy: 0.5496\n",
      "Epoch 7/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 5.0222 - accuracy: 0.5496\n",
      "Epoch 8/200\n",
      "242/242 [==============================] - 0s 152us/sample - loss: 5.0086 - accuracy: 0.5496\n",
      "Epoch 9/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.9950 - accuracy: 0.5496\n",
      "Epoch 10/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.9813 - accuracy: 0.5496\n",
      "Epoch 11/200\n",
      "242/242 [==============================] - 0s 70us/sample - loss: 4.9677 - accuracy: 0.5496\n",
      "Epoch 12/200\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 4.9539 - accuracy: 0.5496\n",
      "Epoch 13/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.9398 - accuracy: 0.5496\n",
      "Epoch 14/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 4.9258 - accuracy: 0.5496\n",
      "Epoch 15/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 4.9117 - accuracy: 0.5496\n",
      "Epoch 16/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.8978 - accuracy: 0.5496\n",
      "Epoch 17/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.8835 - accuracy: 0.5496\n",
      "Epoch 18/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 4.8694 - accuracy: 0.5496\n",
      "Epoch 19/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 4.8552 - accuracy: 0.5496\n",
      "Epoch 20/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 4.8410 - accuracy: 0.5496\n",
      "Epoch 21/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.8267 - accuracy: 0.5496\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 45us/sample - loss: 4.8124 - accuracy: 0.5496\n",
      "Epoch 23/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.7979 - accuracy: 0.5496\n",
      "Epoch 24/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.7835 - accuracy: 0.5496\n",
      "Epoch 25/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.7691 - accuracy: 0.5496\n",
      "Epoch 26/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 4.7548 - accuracy: 0.5496\n",
      "Epoch 27/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.7401 - accuracy: 0.5496\n",
      "Epoch 28/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.7256 - accuracy: 0.5496\n",
      "Epoch 29/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.7110 - accuracy: 0.5496\n",
      "Epoch 30/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.6965 - accuracy: 0.5496\n",
      "Epoch 31/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.6818 - accuracy: 0.5496\n",
      "Epoch 32/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.6670 - accuracy: 0.5496\n",
      "Epoch 33/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.6520 - accuracy: 0.5496\n",
      "Epoch 34/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.6369 - accuracy: 0.5496\n",
      "Epoch 35/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.6216 - accuracy: 0.5496\n",
      "Epoch 36/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.6066 - accuracy: 0.5496\n",
      "Epoch 37/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.5916 - accuracy: 0.5496\n",
      "Epoch 38/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.5765 - accuracy: 0.5496\n",
      "Epoch 39/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.5607 - accuracy: 0.5496\n",
      "Epoch 40/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 4.5454 - accuracy: 0.5496\n",
      "Epoch 41/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 4.5302 - accuracy: 0.5496\n",
      "Epoch 42/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 4.5148 - accuracy: 0.5496\n",
      "Epoch 43/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.4996 - accuracy: 0.5496\n",
      "Epoch 44/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.4839 - accuracy: 0.5496\n",
      "Epoch 45/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.4684 - accuracy: 0.5496\n",
      "Epoch 46/200\n",
      "242/242 [==============================] - ETA: 0s - loss: 3.9565 - accuracy: 0.59 - 0s 41us/sample - loss: 4.4526 - accuracy: 0.5496\n",
      "Epoch 47/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 4.4371 - accuracy: 0.5496\n",
      "Epoch 48/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 4.4216 - accuracy: 0.5496\n",
      "Epoch 49/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 4.4054 - accuracy: 0.5496\n",
      "Epoch 50/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.3898 - accuracy: 0.5496\n",
      "Epoch 51/200\n",
      "242/242 [==============================] - 0s 39us/sample - loss: 4.3742 - accuracy: 0.5496\n",
      "Epoch 52/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.3586 - accuracy: 0.5496\n",
      "Epoch 53/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.3428 - accuracy: 0.5496\n",
      "Epoch 54/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.3271 - accuracy: 0.5496\n",
      "Epoch 55/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.3113 - accuracy: 0.5496\n",
      "Epoch 56/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.2953 - accuracy: 0.5496\n",
      "Epoch 57/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.2790 - accuracy: 0.5496\n",
      "Epoch 58/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 4.2630 - accuracy: 0.5496\n",
      "Epoch 59/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.2469 - accuracy: 0.5496\n",
      "Epoch 60/200\n",
      "242/242 [==============================] - 0s 36us/sample - loss: 4.2304 - accuracy: 0.5496\n",
      "Epoch 61/200\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 4.2142 - accuracy: 0.5496\n",
      "Epoch 62/200\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 4.1976 - accuracy: 0.5496\n",
      "Epoch 63/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 4.1813 - accuracy: 0.5496\n",
      "Epoch 64/200\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 4.1648 - accuracy: 0.5496\n",
      "Epoch 65/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 4.1482 - accuracy: 0.5496\n",
      "Epoch 66/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 4.1312 - accuracy: 0.5496\n",
      "Epoch 67/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 4.1142 - accuracy: 0.5496\n",
      "Epoch 68/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 4.0973 - accuracy: 0.5496\n",
      "Epoch 69/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.0802 - accuracy: 0.5496\n",
      "Epoch 70/200\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 4.0636 - accuracy: 0.5496\n",
      "Epoch 71/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 4.0469 - accuracy: 0.5496\n",
      "Epoch 72/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.0299 - accuracy: 0.5496\n",
      "Epoch 73/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.0130 - accuracy: 0.5496\n",
      "Epoch 74/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.9961 - accuracy: 0.5496\n",
      "Epoch 75/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.9792 - accuracy: 0.5496\n",
      "Epoch 76/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.9619 - accuracy: 0.5496\n",
      "Epoch 77/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.9450 - accuracy: 0.5496\n",
      "Epoch 78/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 3.9285 - accuracy: 0.5496\n",
      "Epoch 79/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.9117 - accuracy: 0.5496\n",
      "Epoch 80/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.8949 - accuracy: 0.5496\n",
      "Epoch 81/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 3.8779 - accuracy: 0.5496\n",
      "Epoch 82/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.8609 - accuracy: 0.5496\n",
      "Epoch 83/200\n",
      "242/242 [==============================] - 0s 36us/sample - loss: 3.8438 - accuracy: 0.5496\n",
      "Epoch 84/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 3.8268 - accuracy: 0.5496\n",
      "Epoch 85/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 3.8099 - accuracy: 0.5496\n",
      "Epoch 86/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.7928 - accuracy: 0.5496\n",
      "Epoch 87/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 3.7757 - accuracy: 0.5496\n",
      "Epoch 88/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 3.7583 - accuracy: 0.5496\n",
      "Epoch 89/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.7410 - accuracy: 0.5496\n",
      "Epoch 90/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.7236 - accuracy: 0.5496\n",
      "Epoch 91/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.7064 - accuracy: 0.5496\n",
      "Epoch 92/200\n",
      "242/242 [==============================] - 0s 46us/sample - loss: 3.6890 - accuracy: 0.5496\n",
      "Epoch 93/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.6720 - accuracy: 0.5496\n",
      "Epoch 94/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.6549 - accuracy: 0.5496\n",
      "Epoch 95/200\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 3.6378 - accuracy: 0.5496\n",
      "Epoch 96/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 3.6209 - accuracy: 0.5496\n",
      "Epoch 97/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.6038 - accuracy: 0.5496\n",
      "Epoch 98/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.5865 - accuracy: 0.5496\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 45us/sample - loss: 3.5688 - accuracy: 0.5496\n",
      "Epoch 100/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.5512 - accuracy: 0.5496\n",
      "Epoch 101/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 3.5337 - accuracy: 0.5496\n",
      "Epoch 102/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.5167 - accuracy: 0.5496\n",
      "Epoch 103/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.4994 - accuracy: 0.5496\n",
      "Epoch 104/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.4825 - accuracy: 0.5496\n",
      "Epoch 105/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.4658 - accuracy: 0.5496\n",
      "Epoch 106/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.4484 - accuracy: 0.5496\n",
      "Epoch 107/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.4313 - accuracy: 0.5496\n",
      "Epoch 108/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.4141 - accuracy: 0.5496\n",
      "Epoch 109/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 3.3973 - accuracy: 0.5496\n",
      "Epoch 110/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 3.3808 - accuracy: 0.5496\n",
      "Epoch 111/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.3638 - accuracy: 0.5496\n",
      "Epoch 112/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.3467 - accuracy: 0.5496\n",
      "Epoch 113/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.3300 - accuracy: 0.5455\n",
      "Epoch 114/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 3.3130 - accuracy: 0.5455\n",
      "Epoch 115/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.2960 - accuracy: 0.5455\n",
      "Epoch 116/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.2791 - accuracy: 0.5455\n",
      "Epoch 117/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.2623 - accuracy: 0.5455\n",
      "Epoch 118/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.2450 - accuracy: 0.5455\n",
      "Epoch 119/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.2287 - accuracy: 0.5455\n",
      "Epoch 120/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.2124 - accuracy: 0.5455\n",
      "Epoch 121/200\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 3.1957 - accuracy: 0.5455\n",
      "Epoch 122/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 3.1792 - accuracy: 0.5455\n",
      "Epoch 123/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.1623 - accuracy: 0.5455\n",
      "Epoch 124/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.1456 - accuracy: 0.5455\n",
      "Epoch 125/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.1292 - accuracy: 0.5455\n",
      "Epoch 126/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.1125 - accuracy: 0.5455\n",
      "Epoch 127/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.0962 - accuracy: 0.5455\n",
      "Epoch 128/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 3.0797 - accuracy: 0.5455\n",
      "Epoch 129/200\n",
      "242/242 [==============================] - 0s 148us/sample - loss: 3.0639 - accuracy: 0.5455\n",
      "Epoch 130/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.0480 - accuracy: 0.5455\n",
      "Epoch 131/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.0321 - accuracy: 0.5455\n",
      "Epoch 132/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 3.0161 - accuracy: 0.5455\n",
      "Epoch 133/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 2.9997 - accuracy: 0.5413\n",
      "Epoch 134/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 2.9834 - accuracy: 0.5413\n",
      "Epoch 135/200\n",
      "242/242 [==============================] - 0s 66us/sample - loss: 2.9674 - accuracy: 0.5413\n",
      "Epoch 136/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.9516 - accuracy: 0.5413\n",
      "Epoch 137/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.9358 - accuracy: 0.5413\n",
      "Epoch 138/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.9198 - accuracy: 0.5413\n",
      "Epoch 139/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.9041 - accuracy: 0.5413\n",
      "Epoch 140/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 2.8881 - accuracy: 0.5413\n",
      "Epoch 141/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 2.8726 - accuracy: 0.5413\n",
      "Epoch 142/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 2.8569 - accuracy: 0.5413\n",
      "Epoch 143/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.8410 - accuracy: 0.5413\n",
      "Epoch 144/200\n",
      "242/242 [==============================] - ETA: 0s - loss: 3.3949 - accuracy: 0.50 - 0s 45us/sample - loss: 2.8252 - accuracy: 0.5413\n",
      "Epoch 145/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.8095 - accuracy: 0.5413\n",
      "Epoch 146/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.7936 - accuracy: 0.5413\n",
      "Epoch 147/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.7784 - accuracy: 0.5413\n",
      "Epoch 148/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.7633 - accuracy: 0.5413\n",
      "Epoch 149/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.7476 - accuracy: 0.5413\n",
      "Epoch 150/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.7320 - accuracy: 0.5372\n",
      "Epoch 151/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.7165 - accuracy: 0.5372\n",
      "Epoch 152/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.7010 - accuracy: 0.5372\n",
      "Epoch 153/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.6857 - accuracy: 0.5372\n",
      "Epoch 154/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.6702 - accuracy: 0.5372\n",
      "Epoch 155/200\n",
      "242/242 [==============================] - 0s 157us/sample - loss: 2.6553 - accuracy: 0.5372\n",
      "Epoch 156/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.6400 - accuracy: 0.5372\n",
      "Epoch 157/200\n",
      "242/242 [==============================] - 0s 70us/sample - loss: 2.6252 - accuracy: 0.5372\n",
      "Epoch 158/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 2.6101 - accuracy: 0.5372\n",
      "Epoch 159/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 2.5948 - accuracy: 0.5372\n",
      "Epoch 160/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 2.5798 - accuracy: 0.5372\n",
      "Epoch 161/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.5649 - accuracy: 0.5413\n",
      "Epoch 162/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.5500 - accuracy: 0.5413\n",
      "Epoch 163/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.5354 - accuracy: 0.5413\n",
      "Epoch 164/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.5211 - accuracy: 0.5413\n",
      "Epoch 165/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.5066 - accuracy: 0.5413\n",
      "Epoch 166/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.4920 - accuracy: 0.5413\n",
      "Epoch 167/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.4773 - accuracy: 0.5413\n",
      "Epoch 168/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.4629 - accuracy: 0.5413\n",
      "Epoch 169/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.4489 - accuracy: 0.5372\n",
      "Epoch 170/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.4346 - accuracy: 0.5372\n",
      "Epoch 171/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.4206 - accuracy: 0.5372\n",
      "Epoch 172/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.4067 - accuracy: 0.5372\n",
      "Epoch 173/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.3925 - accuracy: 0.5372\n",
      "Epoch 174/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.3787 - accuracy: 0.5372\n",
      "Epoch 175/200\n",
      "242/242 [==============================] - 0s 47us/sample - loss: 2.3645 - accuracy: 0.5372\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 37us/sample - loss: 2.3502 - accuracy: 0.5372\n",
      "Epoch 177/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.3365 - accuracy: 0.5372\n",
      "Epoch 178/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.3228 - accuracy: 0.5372\n",
      "Epoch 179/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.3091 - accuracy: 0.5372\n",
      "Epoch 180/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.2958 - accuracy: 0.5372\n",
      "Epoch 181/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 2.2826 - accuracy: 0.5372\n",
      "Epoch 182/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.2693 - accuracy: 0.5372\n",
      "Epoch 183/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.2558 - accuracy: 0.5372\n",
      "Epoch 184/200\n",
      "242/242 [==============================] - 0s 43us/sample - loss: 2.2425 - accuracy: 0.5372\n",
      "Epoch 185/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 2.2297 - accuracy: 0.5372\n",
      "Epoch 186/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.2166 - accuracy: 0.5372\n",
      "Epoch 187/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.2033 - accuracy: 0.5331\n",
      "Epoch 188/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.1906 - accuracy: 0.5331\n",
      "Epoch 189/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.1783 - accuracy: 0.5331\n",
      "Epoch 190/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.1654 - accuracy: 0.5331\n",
      "Epoch 191/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.1530 - accuracy: 0.5331\n",
      "Epoch 192/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.1407 - accuracy: 0.5331\n",
      "Epoch 193/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.1283 - accuracy: 0.5331\n",
      "Epoch 194/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.1163 - accuracy: 0.5331\n",
      "Epoch 195/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.1042 - accuracy: 0.5289\n",
      "Epoch 196/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.0925 - accuracy: 0.5289\n",
      "Epoch 197/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.0810 - accuracy: 0.5289\n",
      "Epoch 198/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.0701 - accuracy: 0.5248\n",
      "Epoch 199/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.0590 - accuracy: 0.5248\n",
      "Epoch 200/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.0476 - accuracy: 0.5248\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 2.2645 - accuracy: 0.4590\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 4.6299 - accuracy: 0.4752\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.6129 - accuracy: 0.4752\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.5958 - accuracy: 0.4752\n",
      "Epoch 4/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.5785 - accuracy: 0.4752\n",
      "Epoch 5/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.5610 - accuracy: 0.4752\n",
      "Epoch 6/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.5440 - accuracy: 0.4752\n",
      "Epoch 7/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.5267 - accuracy: 0.4752\n",
      "Epoch 8/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.5091 - accuracy: 0.4752\n",
      "Epoch 9/200\n",
      "242/242 [==============================] - 0s 52us/sample - loss: 4.4912 - accuracy: 0.4752\n",
      "Epoch 10/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.4738 - accuracy: 0.4752\n",
      "Epoch 11/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.4561 - accuracy: 0.4752\n",
      "Epoch 12/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.4383 - accuracy: 0.4752\n",
      "Epoch 13/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.4203 - accuracy: 0.4752\n",
      "Epoch 14/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.4018 - accuracy: 0.4752\n",
      "Epoch 15/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.3831 - accuracy: 0.4752\n",
      "Epoch 16/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.3645 - accuracy: 0.4752\n",
      "Epoch 17/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.3460 - accuracy: 0.4752\n",
      "Epoch 18/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.3273 - accuracy: 0.4752\n",
      "Epoch 19/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.3086 - accuracy: 0.4752\n",
      "Epoch 20/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.2899 - accuracy: 0.4752\n",
      "Epoch 21/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.2712 - accuracy: 0.4752\n",
      "Epoch 22/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.2520 - accuracy: 0.4752\n",
      "Epoch 23/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.2326 - accuracy: 0.4752\n",
      "Epoch 24/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 4.2135 - accuracy: 0.4752\n",
      "Epoch 25/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.1941 - accuracy: 0.4752\n",
      "Epoch 26/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.1744 - accuracy: 0.4752\n",
      "Epoch 27/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.1544 - accuracy: 0.4752\n",
      "Epoch 28/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.1348 - accuracy: 0.4752\n",
      "Epoch 29/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 4.1152 - accuracy: 0.4752\n",
      "Epoch 30/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.0955 - accuracy: 0.4752\n",
      "Epoch 31/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.0756 - accuracy: 0.4752\n",
      "Epoch 32/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.0551 - accuracy: 0.4752\n",
      "Epoch 33/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 4.0350 - accuracy: 0.4752\n",
      "Epoch 34/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.0150 - accuracy: 0.4752\n",
      "Epoch 35/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.9949 - accuracy: 0.4752\n",
      "Epoch 36/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 3.9744 - accuracy: 0.4752\n",
      "Epoch 37/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.9538 - accuracy: 0.4752\n",
      "Epoch 38/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 3.9334 - accuracy: 0.4752\n",
      "Epoch 39/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.9129 - accuracy: 0.4752\n",
      "Epoch 40/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 3.8923 - accuracy: 0.4752\n",
      "Epoch 41/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.8716 - accuracy: 0.4752\n",
      "Epoch 42/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.8512 - accuracy: 0.4752\n",
      "Epoch 43/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 3.8300 - accuracy: 0.4752\n",
      "Epoch 44/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.8093 - accuracy: 0.4752\n",
      "Epoch 45/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.7880 - accuracy: 0.4752\n",
      "Epoch 46/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.7672 - accuracy: 0.4752\n",
      "Epoch 47/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.7459 - accuracy: 0.4752\n",
      "Epoch 48/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 3.7246 - accuracy: 0.4752\n",
      "Epoch 49/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.7034 - accuracy: 0.4752\n",
      "Epoch 50/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 3.6821 - accuracy: 0.4752\n",
      "Epoch 51/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.6605 - accuracy: 0.4752\n",
      "Epoch 52/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 37us/sample - loss: 3.6387 - accuracy: 0.4752\n",
      "Epoch 53/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.6169 - accuracy: 0.4752\n",
      "Epoch 54/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.5954 - accuracy: 0.4752\n",
      "Epoch 55/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 3.5734 - accuracy: 0.4752\n",
      "Epoch 56/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.5513 - accuracy: 0.4752\n",
      "Epoch 57/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.5292 - accuracy: 0.4752\n",
      "Epoch 58/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 3.5067 - accuracy: 0.4752\n",
      "Epoch 59/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.4844 - accuracy: 0.4752\n",
      "Epoch 60/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.4621 - accuracy: 0.4752\n",
      "Epoch 61/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.4397 - accuracy: 0.4752\n",
      "Epoch 62/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.4172 - accuracy: 0.4752\n",
      "Epoch 63/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.3949 - accuracy: 0.4752\n",
      "Epoch 64/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.3723 - accuracy: 0.4752\n",
      "Epoch 65/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.3497 - accuracy: 0.4752\n",
      "Epoch 66/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.3274 - accuracy: 0.4752\n",
      "Epoch 67/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.3048 - accuracy: 0.4752\n",
      "Epoch 68/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.2819 - accuracy: 0.4752\n",
      "Epoch 69/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 3.2589 - accuracy: 0.4752\n",
      "Epoch 70/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.2358 - accuracy: 0.4752\n",
      "Epoch 71/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.2129 - accuracy: 0.4752\n",
      "Epoch 72/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.1898 - accuracy: 0.4752\n",
      "Epoch 73/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.1668 - accuracy: 0.4752\n",
      "Epoch 74/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 3.1440 - accuracy: 0.4752\n",
      "Epoch 75/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 3.1209 - accuracy: 0.4752\n",
      "Epoch 76/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.0974 - accuracy: 0.4752\n",
      "Epoch 77/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.0739 - accuracy: 0.4752\n",
      "Epoch 78/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.0503 - accuracy: 0.4752\n",
      "Epoch 79/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.0268 - accuracy: 0.4752\n",
      "Epoch 80/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.0028 - accuracy: 0.4752\n",
      "Epoch 81/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 2.9786 - accuracy: 0.4752\n",
      "Epoch 82/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.9547 - accuracy: 0.4752\n",
      "Epoch 83/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.9306 - accuracy: 0.4752\n",
      "Epoch 84/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 2.9069 - accuracy: 0.4752\n",
      "Epoch 85/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.8827 - accuracy: 0.4752\n",
      "Epoch 86/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.8589 - accuracy: 0.4752\n",
      "Epoch 87/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.8353 - accuracy: 0.4752\n",
      "Epoch 88/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.8112 - accuracy: 0.4752\n",
      "Epoch 89/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.7872 - accuracy: 0.4752\n",
      "Epoch 90/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.7630 - accuracy: 0.4752\n",
      "Epoch 91/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 2.7387 - accuracy: 0.4752\n",
      "Epoch 92/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.7149 - accuracy: 0.4752\n",
      "Epoch 93/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.6907 - accuracy: 0.4752\n",
      "Epoch 94/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.6670 - accuracy: 0.4752\n",
      "Epoch 95/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.6429 - accuracy: 0.4752\n",
      "Epoch 96/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.6183 - accuracy: 0.4752\n",
      "Epoch 97/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.5940 - accuracy: 0.4752\n",
      "Epoch 98/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.5691 - accuracy: 0.4752\n",
      "Epoch 99/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.5446 - accuracy: 0.4752\n",
      "Epoch 100/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.5205 - accuracy: 0.4752\n",
      "Epoch 101/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.4964 - accuracy: 0.4752\n",
      "Epoch 102/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 2.4725 - accuracy: 0.4752\n",
      "Epoch 103/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.4485 - accuracy: 0.4752\n",
      "Epoch 104/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 2.4244 - accuracy: 0.4752\n",
      "Epoch 105/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.4003 - accuracy: 0.4752\n",
      "Epoch 106/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.3760 - accuracy: 0.4752\n",
      "Epoch 107/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.3513 - accuracy: 0.4752\n",
      "Epoch 108/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.3266 - accuracy: 0.4752\n",
      "Epoch 109/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.3026 - accuracy: 0.4752\n",
      "Epoch 110/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.2780 - accuracy: 0.4752\n",
      "Epoch 111/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.2536 - accuracy: 0.4752\n",
      "Epoch 112/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 2.2290 - accuracy: 0.4752\n",
      "Epoch 113/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.2044 - accuracy: 0.4752\n",
      "Epoch 114/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 2.1805 - accuracy: 0.4752\n",
      "Epoch 115/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.1565 - accuracy: 0.4752\n",
      "Epoch 116/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.1322 - accuracy: 0.4752\n",
      "Epoch 117/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.1080 - accuracy: 0.4752\n",
      "Epoch 118/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.0840 - accuracy: 0.4752\n",
      "Epoch 119/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 2.0600 - accuracy: 0.4752\n",
      "Epoch 120/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 2.0356 - accuracy: 0.4752\n",
      "Epoch 121/200\n",
      "242/242 [==============================] - 0s 40us/sample - loss: 2.0115 - accuracy: 0.4752\n",
      "Epoch 122/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.9879 - accuracy: 0.4752\n",
      "Epoch 123/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.9638 - accuracy: 0.4752\n",
      "Epoch 124/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.9402 - accuracy: 0.4752\n",
      "Epoch 125/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.9165 - accuracy: 0.4752\n",
      "Epoch 126/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.8929 - accuracy: 0.4752\n",
      "Epoch 127/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.8694 - accuracy: 0.4752\n",
      "Epoch 128/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.8460 - accuracy: 0.4752\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 37us/sample - loss: 1.8224 - accuracy: 0.4752\n",
      "Epoch 130/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.7993 - accuracy: 0.4752\n",
      "Epoch 131/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 1.7763 - accuracy: 0.4752\n",
      "Epoch 132/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 1.7540 - accuracy: 0.4752\n",
      "Epoch 133/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.7312 - accuracy: 0.4752\n",
      "Epoch 134/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.7087 - accuracy: 0.4752\n",
      "Epoch 135/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.6864 - accuracy: 0.4752\n",
      "Epoch 136/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.6640 - accuracy: 0.4752\n",
      "Epoch 137/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.6427 - accuracy: 0.4752\n",
      "Epoch 138/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.6208 - accuracy: 0.4752\n",
      "Epoch 139/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.5993 - accuracy: 0.4752\n",
      "Epoch 140/200\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 1.5782 - accuracy: 0.4752\n",
      "Epoch 141/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.5571 - accuracy: 0.4752\n",
      "Epoch 142/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 1.5363 - accuracy: 0.4752\n",
      "Epoch 143/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.5154 - accuracy: 0.4752\n",
      "Epoch 144/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.4948 - accuracy: 0.4752\n",
      "Epoch 145/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.4751 - accuracy: 0.4752\n",
      "Epoch 146/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.4556 - accuracy: 0.4752\n",
      "Epoch 147/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 1.4365 - accuracy: 0.4752\n",
      "Epoch 148/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.4173 - accuracy: 0.4752\n",
      "Epoch 149/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 1.3983 - accuracy: 0.4752\n",
      "Epoch 150/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.3794 - accuracy: 0.4752\n",
      "Epoch 151/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.3611 - accuracy: 0.4752\n",
      "Epoch 152/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.3432 - accuracy: 0.4752\n",
      "Epoch 153/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 1.3256 - accuracy: 0.4752\n",
      "Epoch 154/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 1.3086 - accuracy: 0.4752\n",
      "Epoch 155/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.2916 - accuracy: 0.4752\n",
      "Epoch 156/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.2752 - accuracy: 0.4752\n",
      "Epoch 157/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 1.2588 - accuracy: 0.4752\n",
      "Epoch 158/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.2433 - accuracy: 0.4752\n",
      "Epoch 159/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.2283 - accuracy: 0.4711\n",
      "Epoch 160/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 1.2134 - accuracy: 0.4711\n",
      "Epoch 161/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 1.1991 - accuracy: 0.4711\n",
      "Epoch 162/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.1846 - accuracy: 0.4711\n",
      "Epoch 163/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 1.1705 - accuracy: 0.4711\n",
      "Epoch 164/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 1.1575 - accuracy: 0.4711\n",
      "Epoch 165/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.1448 - accuracy: 0.4711\n",
      "Epoch 166/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.1320 - accuracy: 0.4711\n",
      "Epoch 167/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 1.1201 - accuracy: 0.4711\n",
      "Epoch 168/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.1083 - accuracy: 0.4669\n",
      "Epoch 169/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.0966 - accuracy: 0.4628\n",
      "Epoch 170/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 1.0853 - accuracy: 0.4587\n",
      "Epoch 171/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 1.0744 - accuracy: 0.4587\n",
      "Epoch 172/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 1.0644 - accuracy: 0.4587\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 1.4335 - accuracy: 0.3607\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 12.9252 - accuracy: 0.4380\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 12.8979 - accuracy: 0.4380\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 12.8700 - accuracy: 0.4380\n",
      "Epoch 4/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 12.8416 - accuracy: 0.4380\n",
      "Epoch 5/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 12.8131 - accuracy: 0.4380\n",
      "Epoch 6/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 12.7838 - accuracy: 0.4380\n",
      "Epoch 7/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 12.7542 - accuracy: 0.4380\n",
      "Epoch 8/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 12.7245 - accuracy: 0.4380\n",
      "Epoch 9/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 12.6945 - accuracy: 0.4380\n",
      "Epoch 10/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 12.6650 - accuracy: 0.4380\n",
      "Epoch 11/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 12.6345 - accuracy: 0.4380\n",
      "Epoch 12/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 12.6038 - accuracy: 0.4380\n",
      "Epoch 13/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 12.5731 - accuracy: 0.4380\n",
      "Epoch 14/200\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 12.5422 - accuracy: 0.4380\n",
      "Epoch 15/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 12.5112 - accuracy: 0.4380\n",
      "Epoch 16/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 12.4802 - accuracy: 0.4380\n",
      "Epoch 17/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 12.4492 - accuracy: 0.4380\n",
      "Epoch 18/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 12.4178 - accuracy: 0.4380\n",
      "Epoch 19/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 12.3863 - accuracy: 0.4380\n",
      "Epoch 20/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 12.3543 - accuracy: 0.4380\n",
      "Epoch 21/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 12.3222 - accuracy: 0.4380\n",
      "Epoch 22/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 12.2898 - accuracy: 0.4380\n",
      "Epoch 23/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 12.2578 - accuracy: 0.4380\n",
      "Epoch 24/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 12.2254 - accuracy: 0.4380\n",
      "Epoch 25/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 12.1927 - accuracy: 0.4380\n",
      "Epoch 26/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 12.1598 - accuracy: 0.4380\n",
      "Epoch 27/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 12.1278 - accuracy: 0.4380\n",
      "Epoch 28/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 12.0947 - accuracy: 0.4380\n",
      "Epoch 29/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 12.0609 - accuracy: 0.4380\n",
      "Epoch 30/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 12.0276 - accuracy: 0.4380\n",
      "Epoch 31/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 11.9945 - accuracy: 0.4380\n",
      "Epoch 32/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.9606 - accuracy: 0.4380\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 33us/sample - loss: 11.9269 - accuracy: 0.4339\n",
      "Epoch 34/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 11.8925 - accuracy: 0.4339\n",
      "Epoch 35/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.8584 - accuracy: 0.4339\n",
      "Epoch 36/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.8239 - accuracy: 0.4339\n",
      "Epoch 37/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 11.7898 - accuracy: 0.4339\n",
      "Epoch 38/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 11.7552 - accuracy: 0.4339\n",
      "Epoch 39/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 11.7200 - accuracy: 0.4339\n",
      "Epoch 40/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 11.6856 - accuracy: 0.4339\n",
      "Epoch 41/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.6508 - accuracy: 0.4339\n",
      "Epoch 42/200\n",
      "242/242 [==============================] - 0s 42us/sample - loss: 11.6158 - accuracy: 0.4339\n",
      "Epoch 43/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 11.5806 - accuracy: 0.4339\n",
      "Epoch 44/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 11.5459 - accuracy: 0.4339\n",
      "Epoch 45/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.5102 - accuracy: 0.4339\n",
      "Epoch 46/200\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 11.4746 - accuracy: 0.4339\n",
      "Epoch 47/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 11.4391 - accuracy: 0.4339\n",
      "Epoch 48/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 11.4043 - accuracy: 0.4339\n",
      "Epoch 49/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 11.3683 - accuracy: 0.4339\n",
      "Epoch 50/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 11.3326 - accuracy: 0.4339\n",
      "Epoch 51/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 11.2969 - accuracy: 0.4339\n",
      "Epoch 52/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 11.2605 - accuracy: 0.4339\n",
      "Epoch 53/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 11.2245 - accuracy: 0.4339\n",
      "Epoch 54/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 11.1882 - accuracy: 0.4339\n",
      "Epoch 55/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.1525 - accuracy: 0.4339\n",
      "Epoch 56/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 11.1169 - accuracy: 0.4339\n",
      "Epoch 57/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 11.0809 - accuracy: 0.4339\n",
      "Epoch 58/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 11.0444 - accuracy: 0.4339\n",
      "Epoch 59/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 11.0079 - accuracy: 0.4339\n",
      "Epoch 60/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.9715 - accuracy: 0.4339\n",
      "Epoch 61/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.9348 - accuracy: 0.4339\n",
      "Epoch 62/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 10.8988 - accuracy: 0.4339\n",
      "Epoch 63/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 10.8623 - accuracy: 0.4339\n",
      "Epoch 64/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 10.8252 - accuracy: 0.4339\n",
      "Epoch 65/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 10.7895 - accuracy: 0.4298\n",
      "Epoch 66/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 10.7529 - accuracy: 0.4298\n",
      "Epoch 67/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 10.7158 - accuracy: 0.4215\n",
      "Epoch 68/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.6795 - accuracy: 0.4174\n",
      "Epoch 69/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 10.6424 - accuracy: 0.4174\n",
      "Epoch 70/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 10.6051 - accuracy: 0.4174\n",
      "Epoch 71/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 10.5686 - accuracy: 0.4174\n",
      "Epoch 72/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 10.5316 - accuracy: 0.4132\n",
      "Epoch 73/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 10.4947 - accuracy: 0.4132\n",
      "Epoch 74/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.4579 - accuracy: 0.4132\n",
      "Epoch 75/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 10.4204 - accuracy: 0.4132\n",
      "Epoch 76/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 10.3830 - accuracy: 0.4132\n",
      "Epoch 77/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 10.3457 - accuracy: 0.4174\n",
      "Epoch 78/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 10.3084 - accuracy: 0.4215\n",
      "Epoch 79/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 10.2718 - accuracy: 0.4215\n",
      "Epoch 80/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 10.2343 - accuracy: 0.4215\n",
      "Epoch 81/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 10.1982 - accuracy: 0.4215\n",
      "Epoch 82/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.1621 - accuracy: 0.4215\n",
      "Epoch 83/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 10.1251 - accuracy: 0.4215\n",
      "Epoch 84/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 10.0881 - accuracy: 0.4215\n",
      "Epoch 85/200\n",
      "242/242 [==============================] - 0s 47us/sample - loss: 10.0507 - accuracy: 0.4215\n",
      "Epoch 86/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 10.0142 - accuracy: 0.4215\n",
      "Epoch 87/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 9.9770 - accuracy: 0.4215\n",
      "Epoch 88/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.9398 - accuracy: 0.4215\n",
      "Epoch 89/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 9.9024 - accuracy: 0.4215\n",
      "Epoch 90/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.8658 - accuracy: 0.4215\n",
      "Epoch 91/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.8289 - accuracy: 0.4215\n",
      "Epoch 92/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 9.7920 - accuracy: 0.4215\n",
      "Epoch 93/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.7550 - accuracy: 0.4215\n",
      "Epoch 94/200\n",
      "242/242 [==============================] - 0s 43us/sample - loss: 9.7183 - accuracy: 0.4215\n",
      "Epoch 95/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 9.6822 - accuracy: 0.4215\n",
      "Epoch 96/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 9.6454 - accuracy: 0.4215\n",
      "Epoch 97/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.6090 - accuracy: 0.4256\n",
      "Epoch 98/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 9.5721 - accuracy: 0.4256\n",
      "Epoch 99/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.5362 - accuracy: 0.4256\n",
      "Epoch 100/200\n",
      "242/242 [==============================] - ETA: 0s - loss: 6.7114 - accuracy: 0.53 - 0s 41us/sample - loss: 9.4992 - accuracy: 0.4256\n",
      "Epoch 101/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.4622 - accuracy: 0.4256\n",
      "Epoch 102/200\n",
      "242/242 [==============================] - 0s 58us/sample - loss: 9.4255 - accuracy: 0.4256\n",
      "Epoch 103/200\n",
      "242/242 [==============================] - 0s 43us/sample - loss: 9.3887 - accuracy: 0.4256\n",
      "Epoch 104/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 9.3532 - accuracy: 0.4215\n",
      "Epoch 105/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.3169 - accuracy: 0.4215\n",
      "Epoch 106/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.2807 - accuracy: 0.4215\n",
      "Epoch 107/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.2446 - accuracy: 0.4215\n",
      "Epoch 108/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 9.2085 - accuracy: 0.4215\n",
      "Epoch 109/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.1735 - accuracy: 0.4174\n",
      "Epoch 110/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 37us/sample - loss: 9.1383 - accuracy: 0.4174\n",
      "Epoch 111/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 9.1023 - accuracy: 0.4174\n",
      "Epoch 112/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 9.0670 - accuracy: 0.4174\n",
      "Epoch 113/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 9.0313 - accuracy: 0.4174\n",
      "Epoch 114/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 8.9955 - accuracy: 0.4174\n",
      "Epoch 115/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 8.9607 - accuracy: 0.4215\n",
      "Epoch 116/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 8.9250 - accuracy: 0.4215\n",
      "Epoch 117/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.8903 - accuracy: 0.4215\n",
      "Epoch 118/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 8.8570 - accuracy: 0.4174\n",
      "Epoch 119/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 8.8224 - accuracy: 0.4215\n",
      "Epoch 120/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 8.7888 - accuracy: 0.4215\n",
      "Epoch 121/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.7546 - accuracy: 0.4174\n",
      "Epoch 122/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.7201 - accuracy: 0.4174\n",
      "Epoch 123/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 8.6860 - accuracy: 0.4174\n",
      "Epoch 124/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 8.6518 - accuracy: 0.4174\n",
      "Epoch 125/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 8.6185 - accuracy: 0.4174\n",
      "Epoch 126/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 8.5847 - accuracy: 0.4174\n",
      "Epoch 127/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 8.5514 - accuracy: 0.4215\n",
      "Epoch 128/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 8.5175 - accuracy: 0.4174\n",
      "Epoch 129/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.4839 - accuracy: 0.4174\n",
      "Epoch 130/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 8.4504 - accuracy: 0.4174\n",
      "Epoch 131/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 8.4175 - accuracy: 0.4132\n",
      "Epoch 132/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.3856 - accuracy: 0.4132\n",
      "Epoch 133/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.3531 - accuracy: 0.4174\n",
      "Epoch 134/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 8.3208 - accuracy: 0.4174\n",
      "Epoch 135/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 8.2886 - accuracy: 0.4215\n",
      "Epoch 136/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 8.2569 - accuracy: 0.4215\n",
      "Epoch 137/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 8.2247 - accuracy: 0.4298\n",
      "Epoch 138/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 8.1926 - accuracy: 0.4298\n",
      "Epoch 139/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 8.1614 - accuracy: 0.4298\n",
      "Epoch 140/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 8.1299 - accuracy: 0.4298\n",
      "Epoch 141/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 8.0985 - accuracy: 0.4298\n",
      "Epoch 142/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.0673 - accuracy: 0.4215\n",
      "Epoch 143/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 8.0372 - accuracy: 0.4256\n",
      "Epoch 144/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.0060 - accuracy: 0.4256\n",
      "Epoch 145/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 7.9753 - accuracy: 0.4256\n",
      "Epoch 146/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 7.9442 - accuracy: 0.4256\n",
      "Epoch 147/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 7.9135 - accuracy: 0.4215\n",
      "Epoch 148/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 7.8836 - accuracy: 0.4215\n",
      "Epoch 149/200\n",
      "242/242 [==============================] - 0s 62us/sample - loss: 7.8536 - accuracy: 0.4215\n",
      "Epoch 150/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 7.8239 - accuracy: 0.4215\n",
      "Epoch 151/200\n",
      "242/242 [==============================] - 0s 177us/sample - loss: 7.7941 - accuracy: 0.4256\n",
      "Epoch 152/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 7.7646 - accuracy: 0.4256\n",
      "Epoch 153/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 7.7345 - accuracy: 0.4215\n",
      "Epoch 154/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 7.7047 - accuracy: 0.4215\n",
      "Epoch 155/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 7.6751 - accuracy: 0.4215\n",
      "Epoch 156/200\n",
      "242/242 [==============================] - 0s 161us/sample - loss: 7.6457 - accuracy: 0.4215\n",
      "Epoch 157/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 7.6166 - accuracy: 0.4174\n",
      "Epoch 158/200\n",
      "242/242 [==============================] - 0s 82us/sample - loss: 7.5879 - accuracy: 0.4174\n",
      "Epoch 159/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 7.5588 - accuracy: 0.4174\n",
      "Epoch 160/200\n",
      "242/242 [==============================] - 0s 74us/sample - loss: 7.5295 - accuracy: 0.4174\n",
      "Epoch 161/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.5009 - accuracy: 0.4132\n",
      "Epoch 162/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 7.4728 - accuracy: 0.4132\n",
      "Epoch 163/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 7.4444 - accuracy: 0.4132\n",
      "Epoch 164/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 7.4157 - accuracy: 0.4132\n",
      "Epoch 165/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 7.3880 - accuracy: 0.4050\n",
      "Epoch 166/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 7.3598 - accuracy: 0.4050\n",
      "Epoch 167/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.3319 - accuracy: 0.4050\n",
      "Epoch 168/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 7.3043 - accuracy: 0.4050\n",
      "Epoch 169/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.2775 - accuracy: 0.4050\n",
      "Epoch 170/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.2498 - accuracy: 0.4050\n",
      "Epoch 171/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 7.2220 - accuracy: 0.4050\n",
      "Epoch 172/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 7.1951 - accuracy: 0.4050\n",
      "Epoch 173/200\n",
      "242/242 [==============================] - 0s 38us/sample - loss: 7.1675 - accuracy: 0.4008\n",
      "Epoch 174/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 7.1404 - accuracy: 0.4008\n",
      "Epoch 175/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.1131 - accuracy: 0.4008\n",
      "Epoch 176/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.0855 - accuracy: 0.4008\n",
      "Epoch 177/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 7.0583 - accuracy: 0.4008\n",
      "Epoch 178/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.0317 - accuracy: 0.3967\n",
      "Epoch 179/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 7.0051 - accuracy: 0.3926\n",
      "Epoch 180/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 6.9789 - accuracy: 0.3926\n",
      "Epoch 181/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 6.9525 - accuracy: 0.3926\n",
      "Epoch 182/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.9259 - accuracy: 0.3926\n",
      "Epoch 183/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.8997 - accuracy: 0.3926\n",
      "Epoch 184/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.8746 - accuracy: 0.3926\n",
      "Epoch 185/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 6.8486 - accuracy: 0.3926\n",
      "Epoch 186/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.8232 - accuracy: 0.3926\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 37us/sample - loss: 6.7975 - accuracy: 0.3926\n",
      "Epoch 188/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.7719 - accuracy: 0.3926\n",
      "Epoch 189/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.7475 - accuracy: 0.3926\n",
      "Epoch 190/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.7225 - accuracy: 0.3926\n",
      "Epoch 191/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.6970 - accuracy: 0.3926\n",
      "Epoch 192/200\n",
      "242/242 [==============================] - 0s 38us/sample - loss: 6.6718 - accuracy: 0.3926\n",
      "Epoch 193/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 6.6467 - accuracy: 0.3926\n",
      "Epoch 194/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 6.6213 - accuracy: 0.3926\n",
      "Epoch 195/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.5963 - accuracy: 0.3926\n",
      "Epoch 196/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 6.5712 - accuracy: 0.3926\n",
      "Epoch 197/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.5454 - accuracy: 0.3926\n",
      "Epoch 198/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 6.5200 - accuracy: 0.3884\n",
      "Epoch 199/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 6.4950 - accuracy: 0.3884\n",
      "Epoch 200/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 6.4702 - accuracy: 0.3926\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 5.8158 - accuracy: 0.4754\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 3.5091 - accuracy: 0.4403\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.5022 - accuracy: 0.4403\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 3.2292 - accuracy: 0.5167\n",
      "Loss: binary_crossentropy; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 2ms/sample - loss: 3.0134 - accuracy: 0.5267\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 3.0015 - accuracy: 0.5267\n",
      "Epoch 3/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.9893 - accuracy: 0.5267\n",
      "Epoch 4/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.9771 - accuracy: 0.5267\n",
      "Epoch 5/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.9650 - accuracy: 0.5267\n",
      "Epoch 6/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.9529 - accuracy: 0.5267\n",
      "Epoch 7/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.9407 - accuracy: 0.5267\n",
      "Epoch 8/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.9285 - accuracy: 0.5267\n",
      "Epoch 9/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.9162 - accuracy: 0.5267\n",
      "Epoch 10/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.9042 - accuracy: 0.5267\n",
      "Epoch 11/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.8920 - accuracy: 0.5267\n",
      "Epoch 12/200\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 2.8799 - accuracy: 0.5267\n",
      "Epoch 13/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.8675 - accuracy: 0.5267\n",
      "Epoch 14/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.8553 - accuracy: 0.5267\n",
      "Epoch 15/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.8432 - accuracy: 0.5267\n",
      "Epoch 16/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.8310 - accuracy: 0.5267\n",
      "Epoch 17/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.8189 - accuracy: 0.5267\n",
      "Epoch 18/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.8072 - accuracy: 0.5267\n",
      "Epoch 19/200\n",
      "243/243 [==============================] - ETA: 0s - loss: 3.5013 - accuracy: 0.50 - 0s 37us/sample - loss: 2.7955 - accuracy: 0.5267\n",
      "Epoch 20/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.7839 - accuracy: 0.5267\n",
      "Epoch 21/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.7723 - accuracy: 0.5267\n",
      "Epoch 22/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.7607 - accuracy: 0.5267\n",
      "Epoch 23/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.7495 - accuracy: 0.5267\n",
      "Epoch 24/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.7380 - accuracy: 0.5267\n",
      "Epoch 25/200\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 2.7268 - accuracy: 0.5267\n",
      "Epoch 26/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.7154 - accuracy: 0.5267\n",
      "Epoch 27/200\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 2.7039 - accuracy: 0.5267\n",
      "Epoch 28/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.6925 - accuracy: 0.5267\n",
      "Epoch 29/200\n",
      "243/243 [==============================] - 0s 43us/sample - loss: 2.6811 - accuracy: 0.5267\n",
      "Epoch 30/200\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 2.6697 - accuracy: 0.5267\n",
      "Epoch 31/200\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 2.6586 - accuracy: 0.5267\n",
      "Epoch 32/200\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 2.6476 - accuracy: 0.5267\n",
      "Epoch 33/200\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 2.6365 - accuracy: 0.5267\n",
      "Epoch 34/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.6251 - accuracy: 0.5267\n",
      "Epoch 35/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.6140 - accuracy: 0.5267\n",
      "Epoch 36/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.6031 - accuracy: 0.5267\n",
      "Epoch 37/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.5926 - accuracy: 0.5267\n",
      "Epoch 38/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.5819 - accuracy: 0.5267\n",
      "Epoch 39/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.5713 - accuracy: 0.5267\n",
      "Epoch 40/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.5606 - accuracy: 0.5267\n",
      "Epoch 41/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.5500 - accuracy: 0.5267\n",
      "Epoch 42/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.5393 - accuracy: 0.5267\n",
      "Epoch 43/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.5285 - accuracy: 0.5267\n",
      "Epoch 44/200\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 2.5178 - accuracy: 0.5267\n",
      "Epoch 45/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.5073 - accuracy: 0.5267\n",
      "Epoch 46/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.4969 - accuracy: 0.5267\n",
      "Epoch 47/200\n",
      "243/243 [==============================] - 0s 46us/sample - loss: 2.4863 - accuracy: 0.5267\n",
      "Epoch 48/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.4759 - accuracy: 0.5267\n",
      "Epoch 49/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.4654 - accuracy: 0.5267\n",
      "Epoch 50/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.4550 - accuracy: 0.5267\n",
      "Epoch 51/200\n",
      "243/243 [==============================] - 0s 53us/sample - loss: 2.4447 - accuracy: 0.5267\n",
      "Epoch 52/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.4344 - accuracy: 0.5267\n",
      "Epoch 53/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.4240 - accuracy: 0.5267\n",
      "Epoch 54/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.4137 - accuracy: 0.5267\n",
      "Epoch 55/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.4035 - accuracy: 0.5267\n",
      "Epoch 56/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.3933 - accuracy: 0.5267\n",
      "Epoch 57/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.3831 - accuracy: 0.5267\n",
      "Epoch 58/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 2.3729 - accuracy: 0.5267\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 41us/sample - loss: 2.3629 - accuracy: 0.5267\n",
      "Epoch 60/200\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 2.3528 - accuracy: 0.5267\n",
      "Epoch 61/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 2.3428 - accuracy: 0.5267\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 2.0017 - accuracy: 0.6167\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 3.9121 - accuracy: 0.5868\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.7726 - accuracy: 0.5579\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 2.4784 - accuracy: 0.5620\n",
      "Epoch 4/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 2.2686 - accuracy: 0.5702\n",
      "Epoch 5/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.0980 - accuracy: 0.5413\n",
      "Epoch 6/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.9400 - accuracy: 0.5413\n",
      "Epoch 7/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.8238 - accuracy: 0.5372\n",
      "Epoch 8/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.7192 - accuracy: 0.5496\n",
      "Epoch 9/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.6501 - accuracy: 0.5620\n",
      "Epoch 10/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 1.5594 - accuracy: 0.5579\n",
      "Epoch 11/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 1.4927 - accuracy: 0.5702\n",
      "Epoch 12/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.4376 - accuracy: 0.5537\n",
      "Epoch 13/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.3759 - accuracy: 0.5537\n",
      "Epoch 14/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.3329 - accuracy: 0.5579\n",
      "Epoch 15/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 1.2917 - accuracy: 0.5537\n",
      "Epoch 16/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.2754 - accuracy: 0.5537\n",
      "Epoch 17/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.2217 - accuracy: 0.5620\n",
      "Epoch 18/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.1952 - accuracy: 0.5537\n",
      "Epoch 19/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.1678 - accuracy: 0.5744\n",
      "Epoch 20/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 1.1433 - accuracy: 0.5744\n",
      "Epoch 21/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.1195 - accuracy: 0.5620\n",
      "Epoch 22/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.1039 - accuracy: 0.5620\n",
      "Epoch 23/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.0860 - accuracy: 0.5620\n",
      "Epoch 24/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.0617 - accuracy: 0.5744\n",
      "Epoch 25/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 1.0424 - accuracy: 0.5744\n",
      "Epoch 26/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.0231 - accuracy: 0.5868\n",
      "Epoch 27/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.0117 - accuracy: 0.6033\n",
      "Epoch 28/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.0013 - accuracy: 0.5785\n",
      "Epoch 29/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.9879 - accuracy: 0.5950\n",
      "Epoch 30/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.9743 - accuracy: 0.6074\n",
      "Epoch 31/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.9598 - accuracy: 0.5702\n",
      "Epoch 32/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.9502 - accuracy: 0.6033\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.7343 - accuracy: 0.6230\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 18.3711 - accuracy: 0.5248\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 13.3052 - accuracy: 0.5248\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 10.0636 - accuracy: 0.5248\n",
      "Epoch 4/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 7.5026 - accuracy: 0.5248\n",
      "Epoch 5/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 5.2959 - accuracy: 0.5248\n",
      "Epoch 6/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 3.3215 - accuracy: 0.5289\n",
      "Epoch 7/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.7132 - accuracy: 0.5702\n",
      "Epoch 8/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.9934 - accuracy: 0.5620\n",
      "Epoch 9/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.8557 - accuracy: 0.5661\n",
      "Epoch 10/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.8312 - accuracy: 0.5702\n",
      "Epoch 11/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.8214 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.7247 - accuracy: 0.6721\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 14.8710 - accuracy: 0.4380\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 11.5053 - accuracy: 0.4380\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 9.9180 - accuracy: 0.4380\n",
      "Epoch 4/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 8.7576 - accuracy: 0.4380\n",
      "Epoch 5/200\n",
      "242/242 [==============================] - 0s 54us/sample - loss: 7.8065 - accuracy: 0.4380\n",
      "Epoch 6/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 6.9974 - accuracy: 0.4380\n",
      "Epoch 7/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 6.2582 - accuracy: 0.4380\n",
      "Epoch 8/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 5.5800 - accuracy: 0.4380\n",
      "Epoch 9/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.9705 - accuracy: 0.4380\n",
      "Epoch 10/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 4.4009 - accuracy: 0.4380\n",
      "Epoch 11/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.8607 - accuracy: 0.4380\n",
      "Epoch 12/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 3.3634 - accuracy: 0.4380\n",
      "Epoch 13/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 2.9080 - accuracy: 0.4380\n",
      "Epoch 14/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 2.4834 - accuracy: 0.4380\n",
      "Epoch 15/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 2.0909 - accuracy: 0.4380\n",
      "Epoch 16/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.7476 - accuracy: 0.4380\n",
      "Epoch 17/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 1.4483 - accuracy: 0.4380\n",
      "Epoch 18/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.2120 - accuracy: 0.4380\n",
      "Epoch 19/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 1.0309 - accuracy: 0.4380\n",
      "Epoch 20/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.9036 - accuracy: 0.4380\n",
      "Epoch 21/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.8223 - accuracy: 0.4380\n",
      "Epoch 22/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.7650 - accuracy: 0.4504\n",
      "Epoch 23/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.7254 - accuracy: 0.5248\n",
      "Epoch 24/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.7001 - accuracy: 0.6157\n",
      "Epoch 25/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6820 - accuracy: 0.6612\n",
      "Epoch 26/200\n",
      "242/242 [==============================] - 0s 49us/sample - loss: 0.6689 - accuracy: 0.6694\n",
      "Epoch 27/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.6586 - accuracy: 0.6488\n",
      "Epoch 28/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.6491 - accuracy: 0.6446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.6858 - accuracy: 0.5410\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 1.0574 - accuracy: 0.5679\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.9232 - accuracy: 0.5597\n",
      "Epoch 3/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.8688 - accuracy: 0.5638\n",
      "Epoch 4/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.8419 - accuracy: 0.5761\n",
      "Epoch 5/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.8274 - accuracy: 0.5638\n",
      "Epoch 6/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.8075 - accuracy: 0.5720\n",
      "Epoch 7/200\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 0.7949 - accuracy: 0.5597\n",
      "Epoch 8/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.7886 - accuracy: 0.5638\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.8373 - accuracy: 0.6000\n",
      "Loss: binary_crossentropy; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 1.4976 - accuracy: 0.4774\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.9251 - accuracy: 0.4979\n",
      "Epoch 3/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.8309 - accuracy: 0.5062\n",
      "Epoch 4/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.7881 - accuracy: 0.5226\n",
      "Epoch 5/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.7619 - accuracy: 0.5185\n",
      "Epoch 6/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.7454 - accuracy: 0.5309\n",
      "Epoch 7/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.7319 - accuracy: 0.5144\n",
      "Epoch 8/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.7192 - accuracy: 0.5720\n",
      "Epoch 9/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.7121 - accuracy: 0.5350\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.7421 - accuracy: 0.5167\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4388 - accuracy: 0.5744\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4328 - accuracy: 0.5785\n",
      "61/61 [==============================] - 0s 964us/sample - loss: 0.4310 - accuracy: 0.5738\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4420 - accuracy: 0.5579\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.3478 - accuracy: 0.6694\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.3196 - accuracy: 0.6818\n",
      "Epoch 4/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.3390 - accuracy: 0.6612\n",
      "61/61 [==============================] - 0s 916us/sample - loss: 0.3026 - accuracy: 0.6885\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4812 - accuracy: 0.5207\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 39us/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 916us/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.5597 - accuracy: 0.4403\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.5167 - accuracy: 0.4979\n",
      "Epoch 3/200\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.3953 - accuracy: 0.6008\n",
      "Epoch 4/200\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.3780 - accuracy: 0.6296\n",
      "Epoch 5/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.3812 - accuracy: 0.6173\n",
      "60/60 [==============================] - 0s 947us/sample - loss: 0.3939 - accuracy: 0.6167\n",
      "Loss: mean_absolute_error; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.5284 - accuracy: 0.4733\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.5268 - accuracy: 0.4733\n",
      "60/60 [==============================] - 0s 990us/sample - loss: 0.6167 - accuracy: 0.3833\n",
      "Loss: mean_absolute_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4497 - accuracy: 0.5496\n",
      "61/61 [==============================] - 0s 1ms/sample - loss: 0.4624 - accuracy: 0.5246\n",
      "Loss: mean_absolute_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.5191 - accuracy: 0.4587\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4941 - accuracy: 0.5455\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4738 - accuracy: 0.5248\n",
      "Epoch 4/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4663 - accuracy: 0.5248\n",
      "61/61 [==============================] - 0s 981us/sample - loss: 0.3971 - accuracy: 0.6230\n",
      "Loss: mean_absolute_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "61/61 [==============================] - 0s 916us/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_absolute_error; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 1s 2ms/sample - loss: 0.4969 - accuracy: 0.5267\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.4176 - accuracy: 0.5967\n",
      "Epoch 3/200\n",
      "243/243 [==============================] - 0s 42us/sample - loss: 0.3935 - accuracy: 0.6132\n",
      "Epoch 4/200\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.3728 - accuracy: 0.6337\n",
      "Epoch 5/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.3708 - accuracy: 0.6214\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.4056 - accuracy: 0.6000\n",
      "Loss: mean_absolute_error; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 1s 4ms/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "60/60 [==============================] - 0s 947us/sample - loss: 0.6167 - accuracy: 0.3833\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 841us/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "61/61 [==============================] - 0s 915us/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 887us/sample - loss: 0.4276 - accuracy: 0.5868\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4875 - accuracy: 0.5124\n",
      "61/61 [==============================] - 0s 899us/sample - loss: 0.3777 - accuracy: 0.6230\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 861us/sample - loss: 0.5667 - accuracy: 0.4380\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5620 - accuracy: 0.4380\n",
      "61/61 [==============================] - 0s 981us/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 874us/sample - loss: 0.5597 - accuracy: 0.4403\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 41us/sample - loss: 0.5597 - accuracy: 0.4403\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.4833 - accuracy: 0.5167\n",
      "Loss: mean_absolute_error; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 903us/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.5267 - accuracy: 0.4733\n",
      "60/60 [==============================] - 0s 1ms/sample - loss: 0.6167 - accuracy: 0.3833\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "61/61 [==============================] - 0s 989us/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.5248 - accuracy: 0.4752\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5248 - accuracy: 0.4752\n",
      "61/61 [==============================] - 0s 932us/sample - loss: 0.6230 - accuracy: 0.3770\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 948us/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "60/60 [==============================] - 0s 981us/sample - loss: 0.5167 - accuracy: 0.4833\n",
      "Loss: mean_absolute_error; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.4733 - accuracy: 0.5267\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4733 - accuracy: 0.5267\n",
      "60/60 [==============================] - 0s 965us/sample - loss: 0.3833 - accuracy: 0.6167\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 945us/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.5496 - accuracy: 0.4504\n",
      "61/61 [==============================] - 0s 932us/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 932us/sample - loss: 0.4752 - accuracy: 0.5248\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4752 - accuracy: 0.5248\n",
      "61/61 [==============================] - 0s 899us/sample - loss: 0.3770 - accuracy: 0.6230\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 903us/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 981us/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 895us/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "60/60 [==============================] - 0s 998us/sample - loss: 0.5167 - accuracy: 0.4833\n",
      "Loss: mean_absolute_error; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 891us/sample - loss: 0.4733 - accuracy: 0.5267\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4733 - accuracy: 0.5267\n",
      "60/60 [==============================] - 0s 930us/sample - loss: 0.3833 - accuracy: 0.6167\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.3554 - accuracy: 0.5289\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.2587 - accuracy: 0.6033\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.2398 - accuracy: 0.6405\n",
      "Epoch 4/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.2227 - accuracy: 0.6157\n",
      "Epoch 5/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.2154 - accuracy: 0.6446\n",
      "61/61 [==============================] - 0s 899us/sample - loss: 0.2035 - accuracy: 0.6557\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4752 - accuracy: 0.5248\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4752 - accuracy: 0.5248\n",
      "61/61 [==============================] - 0s 932us/sample - loss: 0.3770 - accuracy: 0.6230\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4517 - accuracy: 0.3926\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.2607 - accuracy: 0.5620\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.2311 - accuracy: 0.6488\n",
      "Epoch 4/200\n",
      "242/242 [==============================] - 0s 38us/sample - loss: 0.2083 - accuracy: 0.6694\n",
      "Epoch 5/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.1892 - accuracy: 0.7149\n",
      "Epoch 6/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.1881 - accuracy: 0.7190\n",
      "61/61 [==============================] - 0s 6ms/sample - loss: 0.2856 - accuracy: 0.4590\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.3707 - accuracy: 0.5021\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.2305 - accuracy: 0.6379\n",
      "Epoch 3/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.2096 - accuracy: 0.6831\n",
      "Epoch 4/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.1969 - accuracy: 0.6914\n",
      "Epoch 5/200\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.1925 - accuracy: 0.6872\n",
      "60/60 [==============================] - 0s 972us/sample - loss: 0.2509 - accuracy: 0.6333\n",
      "Loss: mean_squared_error; optimimer: adam\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.5130 - accuracy: 0.4115\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.4636 - accuracy: 0.5185\n",
      "Epoch 3/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4682 - accuracy: 0.5267\n",
      "60/60 [==============================] - 0s 930us/sample - loss: 0.3738 - accuracy: 0.6167\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.3439 - accuracy: 0.5289\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.2642 - accuracy: 0.6322\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.2661 - accuracy: 0.6198\n",
      "61/61 [==============================] - 0s 919us/sample - loss: 0.2917 - accuracy: 0.6066\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.5248 - accuracy: 0.4752\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.5248 - accuracy: 0.4752\n",
      "61/61 [==============================] - 0s 932us/sample - loss: 0.6230 - accuracy: 0.3770\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 1s 2ms/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 932us/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 1s 2ms/sample - loss: 0.3680 - accuracy: 0.5391\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 49us/sample - loss: 0.2258 - accuracy: 0.6502\n",
      "Epoch 3/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.2141 - accuracy: 0.6831\n",
      "Epoch 4/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.2080 - accuracy: 0.7160\n",
      "60/60 [==============================] - 0s 930us/sample - loss: 0.2692 - accuracy: 0.6000\n",
      "Loss: mean_squared_error; optimimer: nadam\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 1s 2ms/sample - loss: 0.4119 - accuracy: 0.5062\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 45us/sample - loss: 0.2683 - accuracy: 0.5350\n",
      "Epoch 3/200\n",
      "243/243 [==============================] - 0s 42us/sample - loss: 0.2280 - accuracy: 0.6461\n",
      "Epoch 4/200\n",
      "243/243 [==============================] - 0s 41us/sample - loss: 0.2300 - accuracy: 0.6461\n",
      "60/60 [==============================] - 0s 947us/sample - loss: 0.2235 - accuracy: 0.6667\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 849us/sample - loss: 0.4829 - accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 45us/sample - loss: 0.5102 - accuracy: 0.4504\n",
      "61/61 [==============================] - 0s 973us/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 868us/sample - loss: 0.4733 - accuracy: 0.5207\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.4752 - accuracy: 0.5248\n",
      "61/61 [==============================] - 0s 907us/sample - loss: 0.3770 - accuracy: 0.6230\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 872us/sample - loss: 0.4403 - accuracy: 0.5455\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4380 - accuracy: 0.5620\n",
      "61/61 [==============================] - 0s 916us/sample - loss: 0.5246 - accuracy: 0.4754\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 854us/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4403 - accuracy: 0.5597\n",
      "60/60 [==============================] - 0s 980us/sample - loss: 0.5167 - accuracy: 0.4833\n",
      "Loss: mean_squared_error; optimimer: sgd\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 825us/sample - loss: 0.4728 - accuracy: 0.5267\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.4825 - accuracy: 0.5062\n",
      "60/60 [==============================] - 0s 931us/sample - loss: 0.3833 - accuracy: 0.6167\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 997us/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4504 - accuracy: 0.5496\n",
      "61/61 [==============================] - 0s 917us/sample - loss: 0.4754 - accuracy: 0.5246\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.4830 - accuracy: 0.4752\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.4827 - accuracy: 0.4752\n",
      "61/61 [==============================] - 0s 899us/sample - loss: 0.5464 - accuracy: 0.3934\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 1ms/sample - loss: 0.5579 - accuracy: 0.4380\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.5578 - accuracy: 0.4380\n",
      "61/61 [==============================] - 0s 981us/sample - loss: 0.4718 - accuracy: 0.5246\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 1s 2ms/sample - loss: 0.5597 - accuracy: 0.4403\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.5597 - accuracy: 0.4403\n",
      "60/60 [==============================] - 0s 914us/sample - loss: 0.4833 - accuracy: 0.5167\n",
      "Loss: mean_squared_error; optimimer: adadelta\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 1ms/sample - loss: 0.4733 - accuracy: 0.5267\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 0.4733 - accuracy: 0.5267\n",
      "60/60 [==============================] - 0s 906us/sample - loss: 0.3833 - accuracy: 0.6167\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 929us/sample - loss: 0.5495 - accuracy: 0.4504\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.5232 - accuracy: 0.4091\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.3132 - accuracy: 0.4752\n",
      "Epoch 4/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.2679 - accuracy: 0.5537\n",
      "Epoch 5/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.2563 - accuracy: 0.5661\n",
      "Epoch 6/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.2463 - accuracy: 0.5868\n",
      "61/61 [==============================] - 0s 981us/sample - loss: 0.1806 - accuracy: 0.7377\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 903us/sample - loss: 0.5218 - accuracy: 0.4752\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 41us/sample - loss: 0.2472 - accuracy: 0.6322\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.2118 - accuracy: 0.6736\n",
      "Epoch 4/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.2092 - accuracy: 0.6736\n",
      "61/61 [==============================] - 0s 916us/sample - loss: 0.2251 - accuracy: 0.6230\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 242 samples\n",
      "Epoch 1/200\n",
      "242/242 [==============================] - 0s 914us/sample - loss: 0.3168 - accuracy: 0.5744\n",
      "Epoch 2/200\n",
      "242/242 [==============================] - 0s 37us/sample - loss: 0.2447 - accuracy: 0.6074\n",
      "Epoch 3/200\n",
      "242/242 [==============================] - 0s 33us/sample - loss: 0.2461 - accuracy: 0.6033\n",
      "61/61 [==============================] - 0s 948us/sample - loss: 0.2763 - accuracy: 0.5902\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 911us/sample - loss: 0.3220 - accuracy: 0.4280\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.2661 - accuracy: 0.5185\n",
      "Epoch 3/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.2393 - accuracy: 0.6049\n",
      "Epoch 4/200\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 0.2278 - accuracy: 0.6214\n",
      "Epoch 5/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.2271 - accuracy: 0.6379\n",
      "60/60 [==============================] - 0s 947us/sample - loss: 0.2730 - accuracy: 0.5500\n",
      "Loss: mean_squared_error; optimimer: adagrad\n",
      "Train on 243 samples\n",
      "Epoch 1/200\n",
      "243/243 [==============================] - 0s 944us/sample - loss: 0.3698 - accuracy: 0.5021\n",
      "Epoch 2/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.3016 - accuracy: 0.5185\n",
      "Epoch 3/200\n",
      "243/243 [==============================] - 0s 33us/sample - loss: 0.2783 - accuracy: 0.5597\n",
      "Epoch 4/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.2602 - accuracy: 0.5761\n",
      "Epoch 5/200\n",
      "243/243 [==============================] - 0s 37us/sample - loss: 0.2546 - accuracy: 0.5967\n",
      "60/60 [==============================] - 0s 947us/sample - loss: 0.1897 - accuracy: 0.7333\n",
      "Loss: mean_squared_error; optimimer: adam\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303 samples\n",
      "Epoch 1/100\n",
      "303/303 [==============================] - 0s 862us/sample - loss: 0.5446 - accuracy: 0.4554\n",
      "Epoch 2/100\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.4702 - accuracy: 0.5050\n",
      "Epoch 3/100\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.3562 - accuracy: 0.5479\n",
      "Epoch 4/100\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.2523 - accuracy: 0.6535\n",
      "Epoch 5/100\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.2391 - accuracy: 0.6634\n",
      "Epoch 6/100\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.2350 - accuracy: 0.6568\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "stop = EarlyStopping(monitor='loss', min_delta=.01)\n",
    "    \n",
    "def create_model(loss='mean_absolute_error', optimizer='adam'):\n",
    "    print(f'Loss: {loss}; optimimer: {optimizer}')\n",
    "    model = Sequential([\n",
    "        Dense(13, input_dim=13, activation='relu'),\n",
    "        Dense(30, activation='relu'),\n",
    "        Dense(25, activation='relu'),\n",
    "        Dense(10, activation='relu'),\n",
    "        Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "param_grid = {'loss': [\n",
    "                    'binary_crossentropy',\n",
    "                    'mean_absolute_error',\n",
    "                    'mean_squared_error'\n",
    "                      ],\n",
    "              'optimizer': ['adam', 'nadam', 'sgd', 'adadelta', 'adagrad'],\n",
    "              'epochs':[50, 100, 150, 200]\n",
    "              }\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y, callbacks=[stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.6471038162708282 using {'epochs': 100, 'loss': 'mean_squared_error', 'optimizer': 'adam'}\n",
      "Model Count: 60\n",
      "Means: 0.6010382413864136, Stdev: 0.07870379698420421 with: {'epochs': 50, 'loss': 'binary_crossentropy', 'optimizer': 'adam'}\n",
      "Means: 0.6306010842323303, Stdev: 0.09741438467103869 with: {'epochs': 50, 'loss': 'binary_crossentropy', 'optimizer': 'nadam'}\n",
      "Means: 0.5743169248104095, Stdev: 0.07111618811149333 with: {'epochs': 50, 'loss': 'binary_crossentropy', 'optimizer': 'sgd'}\n",
      "Means: 0.4854098320007324, Stdev: 0.057707505175594205 with: {'epochs': 50, 'loss': 'binary_crossentropy', 'optimizer': 'adadelta'}\n",
      "Means: 0.5575409889221191, Stdev: 0.0520744167548325 with: {'epochs': 50, 'loss': 'binary_crossentropy', 'optimizer': 'adagrad'}\n",
      "Means: 0.5779234826564789, Stdev: 0.09873568730575566 with: {'epochs': 50, 'loss': 'mean_absolute_error', 'optimizer': 'adam'}\n",
      "Means: 0.5144262075424194, Stdev: 0.07638659524390205 with: {'epochs': 50, 'loss': 'mean_absolute_error', 'optimizer': 'nadam'}\n",
      "Means: 0.4487431585788727, Stdev: 0.058444551175019614 with: {'epochs': 50, 'loss': 'mean_absolute_error', 'optimizer': 'sgd'}\n",
      "Means: 0.5052458882331848, Stdev: 0.07755971710899665 with: {'epochs': 50, 'loss': 'mean_absolute_error', 'optimizer': 'adadelta'}\n",
      "Means: 0.5179234921932221, Stdev: 0.08836060827949536 with: {'epochs': 50, 'loss': 'mean_absolute_error', 'optimizer': 'adagrad'}\n",
      "Means: 0.6071584582328796, Stdev: 0.07043255261506294 with: {'epochs': 50, 'loss': 'mean_squared_error', 'optimizer': 'adam'}\n",
      "Means: 0.517868846654892, Stdev: 0.0796371174311765 with: {'epochs': 50, 'loss': 'mean_squared_error', 'optimizer': 'nadam'}\n",
      "Means: 0.49540982842445375, Stdev: 0.07760128658358137 with: {'epochs': 50, 'loss': 'mean_squared_error', 'optimizer': 'sgd'}\n",
      "Means: 0.4980327785015106, Stdev: 0.07701727080082887 with: {'epochs': 50, 'loss': 'mean_squared_error', 'optimizer': 'adadelta'}\n",
      "Means: 0.5674316763877869, Stdev: 0.10850089198237882 with: {'epochs': 50, 'loss': 'mean_squared_error', 'optimizer': 'adagrad'}\n",
      "Means: 0.6112568199634552, Stdev: 0.11689716551056778 with: {'epochs': 100, 'loss': 'binary_crossentropy', 'optimizer': 'adam'}\n",
      "Means: 0.6173223972320556, Stdev: 0.057230522284470085 with: {'epochs': 100, 'loss': 'binary_crossentropy', 'optimizer': 'nadam'}\n",
      "Means: 0.5707103848457337, Stdev: 0.08951186514019448 with: {'epochs': 100, 'loss': 'binary_crossentropy', 'optimizer': 'sgd'}\n",
      "Means: 0.45185792446136475, Stdev: 0.07786960604113521 with: {'epochs': 100, 'loss': 'binary_crossentropy', 'optimizer': 'adadelta'}\n",
      "Means: 0.5976502776145936, Stdev: 0.08424301226553055 with: {'epochs': 100, 'loss': 'binary_crossentropy', 'optimizer': 'adagrad'}\n",
      "Means: 0.5386338710784913, Stdev: 0.1287941811713463 with: {'epochs': 100, 'loss': 'mean_absolute_error', 'optimizer': 'adam'}\n",
      "Means: 0.6109289586544037, Stdev: 0.09306460857714006 with: {'epochs': 100, 'loss': 'mean_absolute_error', 'optimizer': 'nadam'}\n",
      "Means: 0.5077595472335815, Stdev: 0.08336845103182773 with: {'epochs': 100, 'loss': 'mean_absolute_error', 'optimizer': 'sgd'}\n",
      "Means: 0.5079234898090362, Stdev: 0.07840225215451488 with: {'epochs': 100, 'loss': 'mean_absolute_error', 'optimizer': 'adadelta'}\n",
      "Means: 0.5680874228477478, Stdev: 0.10575872654369445 with: {'epochs': 100, 'loss': 'mean_absolute_error', 'optimizer': 'adagrad'}\n",
      "Means: 0.6471038162708282, Stdev: 0.095743656706184 with: {'epochs': 100, 'loss': 'mean_squared_error', 'optimizer': 'adam'}\n",
      "Means: 0.5840437114238739, Stdev: 0.07493765683310877 with: {'epochs': 100, 'loss': 'mean_squared_error', 'optimizer': 'nadam'}\n",
      "Means: 0.5220764994621276, Stdev: 0.0906770338665773 with: {'epochs': 100, 'loss': 'mean_squared_error', 'optimizer': 'sgd'}\n",
      "Means: 0.5045901477336884, Stdev: 0.07760127726998454 with: {'epochs': 100, 'loss': 'mean_squared_error', 'optimizer': 'adadelta'}\n",
      "Means: 0.5578142046928406, Stdev: 0.06886949712542172 with: {'epochs': 100, 'loss': 'mean_squared_error', 'optimizer': 'adagrad'}\n",
      "Means: 0.6403278708457947, Stdev: 0.06873301986490506 with: {'epochs': 150, 'loss': 'binary_crossentropy', 'optimizer': 'adam'}\n",
      "Means: 0.5998360633850097, Stdev: 0.161173623094848 with: {'epochs': 150, 'loss': 'binary_crossentropy', 'optimizer': 'nadam'}\n",
      "Means: 0.6140437185764313, Stdev: 0.07432650725463173 with: {'epochs': 150, 'loss': 'binary_crossentropy', 'optimizer': 'sgd'}\n",
      "Means: 0.479016387462616, Stdev: 0.10477411884310381 with: {'epochs': 150, 'loss': 'binary_crossentropy', 'optimizer': 'adadelta'}\n",
      "Means: 0.540819662809372, Stdev: 0.11851469233423445 with: {'epochs': 150, 'loss': 'binary_crossentropy', 'optimizer': 'adagrad'}\n",
      "Means: 0.5975956380367279, Stdev: 0.06803189005840365 with: {'epochs': 150, 'loss': 'mean_absolute_error', 'optimizer': 'adam'}\n",
      "Means: 0.521311467885971, Stdev: 0.13350219567904112 with: {'epochs': 150, 'loss': 'mean_absolute_error', 'optimizer': 'nadam'}\n",
      "Means: 0.49540982842445375, Stdev: 0.07760128658358137 with: {'epochs': 150, 'loss': 'mean_absolute_error', 'optimizer': 'sgd'}\n",
      "Means: 0.4946448028087616, Stdev: 0.0885540326551471 with: {'epochs': 150, 'loss': 'mean_absolute_error', 'optimizer': 'adadelta'}\n",
      "Means: 0.5873770356178284, Stdev: 0.05480916011993998 with: {'epochs': 150, 'loss': 'mean_absolute_error', 'optimizer': 'adagrad'}\n",
      "Means: 0.49874316453933715, Stdev: 0.07736855996379259 with: {'epochs': 150, 'loss': 'mean_squared_error', 'optimizer': 'adam'}\n",
      "Means: 0.5677595555782318, Stdev: 0.07876647983001354 with: {'epochs': 150, 'loss': 'mean_squared_error', 'optimizer': 'nadam'}\n",
      "Means: 0.5052458882331848, Stdev: 0.07755971710899665 with: {'epochs': 150, 'loss': 'mean_squared_error', 'optimizer': 'sgd'}\n",
      "Means: 0.5020764946937561, Stdev: 0.0777091843067777 with: {'epochs': 150, 'loss': 'mean_squared_error', 'optimizer': 'adadelta'}\n",
      "Means: 0.6367213070392609, Stdev: 0.12755022894277415 with: {'epochs': 150, 'loss': 'mean_squared_error', 'optimizer': 'adagrad'}\n",
      "Means: 0.613879781961441, Stdev: 0.08731368118432759 with: {'epochs': 200, 'loss': 'binary_crossentropy', 'optimizer': 'adam'}\n",
      "Means: 0.6206557393074036, Stdev: 0.04012342438510965 with: {'epochs': 200, 'loss': 'binary_crossentropy', 'optimizer': 'nadam'}\n",
      "Means: 0.547923481464386, Stdev: 0.0676734833725118 with: {'epochs': 200, 'loss': 'binary_crossentropy', 'optimizer': 'sgd'}\n",
      "Means: 0.48568305373191833, Stdev: 0.08314466370089327 with: {'epochs': 200, 'loss': 'binary_crossentropy', 'optimizer': 'adadelta'}\n",
      "Means: 0.590546441078186, Stdev: 0.05605384758566851 with: {'epochs': 200, 'loss': 'binary_crossentropy', 'optimizer': 'adagrad'}\n",
      "Means: 0.5475409805774689, Stdev: 0.10724717756703198 with: {'epochs': 200, 'loss': 'mean_absolute_error', 'optimizer': 'adam'}\n",
      "Means: 0.5310928821563721, Stdev: 0.08378965079474479 with: {'epochs': 200, 'loss': 'mean_absolute_error', 'optimizer': 'nadam'}\n",
      "Means: 0.5144262075424194, Stdev: 0.07638659524390205 with: {'epochs': 200, 'loss': 'mean_absolute_error', 'optimizer': 'sgd'}\n",
      "Means: 0.49540982842445375, Stdev: 0.07760128658358137 with: {'epochs': 200, 'loss': 'mean_absolute_error', 'optimizer': 'adadelta'}\n",
      "Means: 0.534754091501236, Stdev: 0.06953546797062192 with: {'epochs': 200, 'loss': 'mean_absolute_error', 'optimizer': 'adagrad'}\n",
      "Means: 0.5975409746170044, Stdev: 0.07052441392631759 with: {'epochs': 200, 'loss': 'mean_squared_error', 'optimizer': 'adam'}\n",
      "Means: 0.5451366186141968, Stdev: 0.10456315914512565 with: {'epochs': 200, 'loss': 'mean_squared_error', 'optimizer': 'nadam'}\n",
      "Means: 0.544590151309967, Stdev: 0.06367688980302419 with: {'epochs': 200, 'loss': 'mean_squared_error', 'optimizer': 'sgd'}\n",
      "Means: 0.5151912450790406, Stdev: 0.07113205038122712 with: {'epochs': 200, 'loss': 'mean_squared_error', 'optimizer': 'adadelta'}\n",
      "Means: 0.6468306064605713, Stdev: 0.07602419039629696 with: {'epochs': 200, 'loss': 'mean_squared_error', 'optimizer': 'adagrad'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "print(f'Model Count: {len(means)}')\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303 samples\n",
      "Epoch 1/50\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 1.7229 - accuracy: 0.5710\n",
      "Epoch 2/50\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 1.0828 - accuracy: 0.5710\n",
      "Epoch 3/50\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.9499 - accuracy: 0.5611\n",
      "Epoch 4/50\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.7824 - accuracy: 0.6469\n",
      "Epoch 5/50\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.7374 - accuracy: 0.6172\n",
      "Epoch 6/50\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.7608 - accuracy: 0.6238\n",
      "Epoch 7/50\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.7067 - accuracy: 0.6436\n",
      "Epoch 8/50\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6292 - accuracy: 0.6832\n",
      "Epoch 9/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6713 - accuracy: 0.6535\n",
      "Epoch 10/50\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6352 - accuracy: 0.6832\n",
      "Epoch 11/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6627 - accuracy: 0.6106\n",
      "Epoch 12/50\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6038 - accuracy: 0.7228\n",
      "Epoch 13/50\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.7219 - accuracy: 0.6403\n",
      "Epoch 14/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.7290 - accuracy: 0.6370\n",
      "Epoch 15/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6992 - accuracy: 0.6172\n",
      "Epoch 16/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.7093 - accuracy: 0.6535\n",
      "Epoch 17/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6641 - accuracy: 0.6601\n",
      "Epoch 18/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6342 - accuracy: 0.6634\n",
      "Epoch 19/50\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.7042 - accuracy: 0.6304\n",
      "Epoch 20/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6331 - accuracy: 0.6733\n",
      "Epoch 21/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6049 - accuracy: 0.6865\n",
      "Epoch 22/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.5964 - accuracy: 0.7096\n",
      "Epoch 23/50\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.5598 - accuracy: 0.7426\n",
      "Epoch 24/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.5884 - accuracy: 0.6931\n",
      "Epoch 25/50\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.5579 - accuracy: 0.7030\n",
      "Epoch 26/50\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6578 - accuracy: 0.6667\n",
      "Epoch 27/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6816 - accuracy: 0.6238\n",
      "Epoch 28/50\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.5387 - accuracy: 0.7261\n",
      "Epoch 29/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.5734 - accuracy: 0.6931\n",
      "Epoch 30/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.5718 - accuracy: 0.7129\n",
      "Epoch 31/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.5626 - accuracy: 0.7228\n",
      "Epoch 32/50\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.5878 - accuracy: 0.7063\n",
      "Epoch 33/50\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.5545 - accuracy: 0.7261\n",
      "Epoch 34/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.5833 - accuracy: 0.6700\n",
      "Epoch 35/50\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.5816 - accuracy: 0.7030\n",
      "Epoch 36/50\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.5723 - accuracy: 0.7063\n",
      "Epoch 37/50\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.5657 - accuracy: 0.7096\n",
      "Epoch 38/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.5830 - accuracy: 0.6865\n",
      "Epoch 39/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.5222 - accuracy: 0.7294\n",
      "Epoch 40/50\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.5752 - accuracy: 0.6832\n",
      "Epoch 41/50\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.5663 - accuracy: 0.7096\n",
      "Epoch 42/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.5463 - accuracy: 0.7426\n",
      "Epoch 43/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.5208 - accuracy: 0.7261\n",
      "Epoch 44/50\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.5693 - accuracy: 0.6700\n",
      "Epoch 45/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6573 - accuracy: 0.6634\n",
      "Epoch 46/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.5531 - accuracy: 0.7327\n",
      "Epoch 47/50\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.5384 - accuracy: 0.7459\n",
      "Epoch 48/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6287 - accuracy: 0.7063\n",
      "Epoch 49/50\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.5390 - accuracy: 0.7228\n",
      "Epoch 50/50\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.5096 - accuracy: 0.7492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e5e9032288>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(13, input_dim=13, activation='relu'),\n",
    "    Dense(30, activation='relu'),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
